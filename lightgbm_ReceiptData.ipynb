{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68dfeb60-bf7c-40c5-96d9-1e7100a5e3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trainの形状： (646, 43)  y_trainの形状： (646,)  X_testの形状： (278, 43)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.645979\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.607469\n",
      "[3]\ttrain's binary_logloss: 0.575587\n",
      "[4]\ttrain's binary_logloss: 0.54889\n",
      "[5]\ttrain's binary_logloss: 0.524775\n",
      "[6]\ttrain's binary_logloss: 0.505158\n",
      "[7]\ttrain's binary_logloss: 0.487333\n",
      "[8]\ttrain's binary_logloss: 0.473403\n",
      "[9]\ttrain's binary_logloss: 0.459756\n",
      "[10]\ttrain's binary_logloss: 0.447863\n",
      "[11]\ttrain's binary_logloss: 0.437382\n",
      "[12]\ttrain's binary_logloss: 0.42888\n",
      "[13]\ttrain's binary_logloss: 0.420697\n",
      "[14]\ttrain's binary_logloss: 0.413379\n",
      "[15]\ttrain's binary_logloss: 0.407086\n",
      "[16]\ttrain's binary_logloss: 0.400418\n",
      "[17]\ttrain's binary_logloss: 0.394532\n",
      "[18]\ttrain's binary_logloss: 0.389788\n",
      "[19]\ttrain's binary_logloss: 0.384675\n",
      "[20]\ttrain's binary_logloss: 0.380166\n",
      "[21]\ttrain's binary_logloss: 0.375858\n",
      "[22]\ttrain's binary_logloss: 0.371429\n",
      "[23]\ttrain's binary_logloss: 0.367647\n",
      "[24]\ttrain's binary_logloss: 0.362687\n",
      "[25]\ttrain's binary_logloss: 0.358916\n",
      "[26]\ttrain's binary_logloss: 0.3553\n",
      "[27]\ttrain's binary_logloss: 0.351454\n",
      "[28]\ttrain's binary_logloss: 0.347952\n",
      "[29]\ttrain's binary_logloss: 0.344491\n",
      "[30]\ttrain's binary_logloss: 0.341\n",
      "[31]\ttrain's binary_logloss: 0.338273\n",
      "[32]\ttrain's binary_logloss: 0.335374\n",
      "[33]\ttrain's binary_logloss: 0.332966\n",
      "[34]\ttrain's binary_logloss: 0.329758\n",
      "[35]\ttrain's binary_logloss: 0.327267\n",
      "[36]\ttrain's binary_logloss: 0.324796\n",
      "[37]\ttrain's binary_logloss: 0.322593\n",
      "[38]\ttrain's binary_logloss: 0.319497\n",
      "[39]\ttrain's binary_logloss: 0.316936\n",
      "[40]\ttrain's binary_logloss: 0.314706\n",
      "[41]\ttrain's binary_logloss: 0.312041\n",
      "[42]\ttrain's binary_logloss: 0.309377\n",
      "[43]\ttrain's binary_logloss: 0.307265\n",
      "[44]\ttrain's binary_logloss: 0.304797\n",
      "[45]\ttrain's binary_logloss: 0.302932\n",
      "[46]\ttrain's binary_logloss: 0.301226\n",
      "[47]\ttrain's binary_logloss: 0.299184\n",
      "[48]\ttrain's binary_logloss: 0.29694\n",
      "[49]\ttrain's binary_logloss: 0.295391\n",
      "[50]\ttrain's binary_logloss: 0.293026\n",
      "[51]\ttrain's binary_logloss: 0.291295\n",
      "[52]\ttrain's binary_logloss: 0.289817\n",
      "[53]\ttrain's binary_logloss: 0.28778\n",
      "[54]\ttrain's binary_logloss: 0.285807\n",
      "[55]\ttrain's binary_logloss: 0.283796\n",
      "[56]\ttrain's binary_logloss: 0.281902\n",
      "[57]\ttrain's binary_logloss: 0.280353\n",
      "[58]\ttrain's binary_logloss: 0.278133\n",
      "[59]\ttrain's binary_logloss: 0.276636\n",
      "[60]\ttrain's binary_logloss: 0.274882\n",
      "[61]\ttrain's binary_logloss: 0.272477\n",
      "[62]\ttrain's binary_logloss: 0.27115\n",
      "[63]\ttrain's binary_logloss: 0.268909\n",
      "[64]\ttrain's binary_logloss: 0.26711\n",
      "[65]\ttrain's binary_logloss: 0.265627\n",
      "[66]\ttrain's binary_logloss: 0.264103\n",
      "[67]\ttrain's binary_logloss: 0.262114\n",
      "[68]\ttrain's binary_logloss: 0.26011\n",
      "[69]\ttrain's binary_logloss: 0.258665\n",
      "[70]\ttrain's binary_logloss: 0.25738\n",
      "[71]\ttrain's binary_logloss: 0.255726\n",
      "[72]\ttrain's binary_logloss: 0.254223\n",
      "[73]\ttrain's binary_logloss: 0.252303\n",
      "[74]\ttrain's binary_logloss: 0.251051\n",
      "[75]\ttrain's binary_logloss: 0.249495\n",
      "[76]\ttrain's binary_logloss: 0.247928\n",
      "[77]\ttrain's binary_logloss: 0.246865\n",
      "[78]\ttrain's binary_logloss: 0.245542\n",
      "[79]\ttrain's binary_logloss: 0.24408\n",
      "[80]\ttrain's binary_logloss: 0.242746\n",
      "[81]\ttrain's binary_logloss: 0.241516\n",
      "[82]\ttrain's binary_logloss: 0.240294\n",
      "[83]\ttrain's binary_logloss: 0.238656\n",
      "[84]\ttrain's binary_logloss: 0.237595\n",
      "[85]\ttrain's binary_logloss: 0.236696\n",
      "[86]\ttrain's binary_logloss: 0.235792\n",
      "[87]\ttrain's binary_logloss: 0.234593\n",
      "[88]\ttrain's binary_logloss: 0.233253\n",
      "[89]\ttrain's binary_logloss: 0.232353\n",
      "[90]\ttrain's binary_logloss: 0.230887\n",
      "[91]\ttrain's binary_logloss: 0.229588\n",
      "[92]\ttrain's binary_logloss: 0.228103\n",
      "[93]\ttrain's binary_logloss: 0.227024\n",
      "[94]\ttrain's binary_logloss: 0.225505\n",
      "[95]\ttrain's binary_logloss: 0.224624\n",
      "[96]\ttrain's binary_logloss: 0.222889\n",
      "[97]\ttrain's binary_logloss: 0.221902\n",
      "[98]\ttrain's binary_logloss: 0.22063\n",
      "[99]\ttrain's binary_logloss: 0.218838\n",
      "[100]\ttrain's binary_logloss: 0.217476\n",
      "[101]\ttrain's binary_logloss: 0.21629\n",
      "[102]\ttrain's binary_logloss: 0.214851\n",
      "[103]\ttrain's binary_logloss: 0.213776\n",
      "[104]\ttrain's binary_logloss: 0.212298\n",
      "[105]\ttrain's binary_logloss: 0.211099\n",
      "[106]\ttrain's binary_logloss: 0.210155\n",
      "[107]\ttrain's binary_logloss: 0.209238\n",
      "[108]\ttrain's binary_logloss: 0.2083\n",
      "[109]\ttrain's binary_logloss: 0.207146\n",
      "[110]\ttrain's binary_logloss: 0.206077\n",
      "[111]\ttrain's binary_logloss: 0.204606\n",
      "[112]\ttrain's binary_logloss: 0.203562\n",
      "[113]\ttrain's binary_logloss: 0.202641\n",
      "[114]\ttrain's binary_logloss: 0.20154\n",
      "[115]\ttrain's binary_logloss: 0.200288\n",
      "[116]\ttrain's binary_logloss: 0.199032\n",
      "[117]\ttrain's binary_logloss: 0.197964\n",
      "[118]\ttrain's binary_logloss: 0.196656\n",
      "[119]\ttrain's binary_logloss: 0.195804\n",
      "[120]\ttrain's binary_logloss: 0.19452\n",
      "[121]\ttrain's binary_logloss: 0.193742\n",
      "[122]\ttrain's binary_logloss: 0.192721\n",
      "[123]\ttrain's binary_logloss: 0.191777\n",
      "[124]\ttrain's binary_logloss: 0.191043\n",
      "[125]\ttrain's binary_logloss: 0.190235\n",
      "[126]\ttrain's binary_logloss: 0.189519\n",
      "[127]\ttrain's binary_logloss: 0.188461\n",
      "[128]\ttrain's binary_logloss: 0.187743\n",
      "[129]\ttrain's binary_logloss: 0.186209\n",
      "[130]\ttrain's binary_logloss: 0.185589\n",
      "[131]\ttrain's binary_logloss: 0.184918\n",
      "[132]\ttrain's binary_logloss: 0.183813\n",
      "[133]\ttrain's binary_logloss: 0.182655\n",
      "[134]\ttrain's binary_logloss: 0.181989\n",
      "[135]\ttrain's binary_logloss: 0.181103\n",
      "[136]\ttrain's binary_logloss: 0.18046\n",
      "[137]\ttrain's binary_logloss: 0.179155\n",
      "[138]\ttrain's binary_logloss: 0.178649\n",
      "[139]\ttrain's binary_logloss: 0.177763\n",
      "[140]\ttrain's binary_logloss: 0.176758\n",
      "[141]\ttrain's binary_logloss: 0.175398\n",
      "[142]\ttrain's binary_logloss: 0.174555\n",
      "[143]\ttrain's binary_logloss: 0.173431\n",
      "[144]\ttrain's binary_logloss: 0.172795\n",
      "[145]\ttrain's binary_logloss: 0.171829\n",
      "[146]\ttrain's binary_logloss: 0.170794\n",
      "[147]\ttrain's binary_logloss: 0.16996\n",
      "[148]\ttrain's binary_logloss: 0.169299\n",
      "[149]\ttrain's binary_logloss: 0.168474\n",
      "[150]\ttrain's binary_logloss: 0.167255\n",
      "[151]\ttrain's binary_logloss: 0.166508\n",
      "[152]\ttrain's binary_logloss: 0.165976\n",
      "[153]\ttrain's binary_logloss: 0.165176\n",
      "[154]\ttrain's binary_logloss: 0.164243\n",
      "[155]\ttrain's binary_logloss: 0.163129\n",
      "[156]\ttrain's binary_logloss: 0.16261\n",
      "[157]\ttrain's binary_logloss: 0.161583\n",
      "[158]\ttrain's binary_logloss: 0.16081\n",
      "[159]\ttrain's binary_logloss: 0.159906\n",
      "[160]\ttrain's binary_logloss: 0.159349\n",
      "[161]\ttrain's binary_logloss: 0.158649\n",
      "[162]\ttrain's binary_logloss: 0.157701\n",
      "[163]\ttrain's binary_logloss: 0.15675\n",
      "[164]\ttrain's binary_logloss: 0.15578\n",
      "[165]\ttrain's binary_logloss: 0.154765\n",
      "[166]\ttrain's binary_logloss: 0.154205\n",
      "[167]\ttrain's binary_logloss: 0.153335\n",
      "[168]\ttrain's binary_logloss: 0.152659\n",
      "[169]\ttrain's binary_logloss: 0.151726\n",
      "[170]\ttrain's binary_logloss: 0.150959\n",
      "[171]\ttrain's binary_logloss: 0.150255\n",
      "[172]\ttrain's binary_logloss: 0.149312\n",
      "[173]\ttrain's binary_logloss: 0.148715\n",
      "[174]\ttrain's binary_logloss: 0.147935\n",
      "[175]\ttrain's binary_logloss: 0.147207\n",
      "[176]\ttrain's binary_logloss: 0.146467\n",
      "[177]\ttrain's binary_logloss: 0.145747\n",
      "[178]\ttrain's binary_logloss: 0.144968\n",
      "[179]\ttrain's binary_logloss: 0.143976\n",
      "[180]\ttrain's binary_logloss: 0.143349\n",
      "[181]\ttrain's binary_logloss: 0.142777\n",
      "[182]\ttrain's binary_logloss: 0.141895\n",
      "[183]\ttrain's binary_logloss: 0.14117\n",
      "[184]\ttrain's binary_logloss: 0.140235\n",
      "[185]\ttrain's binary_logloss: 0.139442\n",
      "[186]\ttrain's binary_logloss: 0.138812\n",
      "[187]\ttrain's binary_logloss: 0.138275\n",
      "[188]\ttrain's binary_logloss: 0.137689\n",
      "[189]\ttrain's binary_logloss: 0.137015\n",
      "[190]\ttrain's binary_logloss: 0.136435\n",
      "[191]\ttrain's binary_logloss: 0.135791\n",
      "[192]\ttrain's binary_logloss: 0.135149\n",
      "[193]\ttrain's binary_logloss: 0.134353\n",
      "[194]\ttrain's binary_logloss: 0.133886\n",
      "[195]\ttrain's binary_logloss: 0.133157\n",
      "[196]\ttrain's binary_logloss: 0.132694\n",
      "[197]\ttrain's binary_logloss: 0.13204\n",
      "[198]\ttrain's binary_logloss: 0.131377\n",
      "[199]\ttrain's binary_logloss: 0.130818\n",
      "[200]\ttrain's binary_logloss: 0.130261\n",
      "[201]\ttrain's binary_logloss: 0.129614\n",
      "[202]\ttrain's binary_logloss: 0.129119\n",
      "[203]\ttrain's binary_logloss: 0.128704\n",
      "[204]\ttrain's binary_logloss: 0.128289\n",
      "[205]\ttrain's binary_logloss: 0.127834\n",
      "[206]\ttrain's binary_logloss: 0.127428\n",
      "[207]\ttrain's binary_logloss: 0.126912\n",
      "[208]\ttrain's binary_logloss: 0.126199\n",
      "[209]\ttrain's binary_logloss: 0.125629\n",
      "[210]\ttrain's binary_logloss: 0.12503\n",
      "[211]\ttrain's binary_logloss: 0.124452\n",
      "[212]\ttrain's binary_logloss: 0.123912\n",
      "[213]\ttrain's binary_logloss: 0.123397\n",
      "[214]\ttrain's binary_logloss: 0.122826\n",
      "[215]\ttrain's binary_logloss: 0.122334\n",
      "[216]\ttrain's binary_logloss: 0.121682\n",
      "[217]\ttrain's binary_logloss: 0.121058\n",
      "[218]\ttrain's binary_logloss: 0.120728\n",
      "[219]\ttrain's binary_logloss: 0.120108\n",
      "[220]\ttrain's binary_logloss: 0.119467\n",
      "[221]\ttrain's binary_logloss: 0.119047\n",
      "[222]\ttrain's binary_logloss: 0.11837\n",
      "[223]\ttrain's binary_logloss: 0.117889\n",
      "[224]\ttrain's binary_logloss: 0.117508\n",
      "[225]\ttrain's binary_logloss: 0.116907\n",
      "[226]\ttrain's binary_logloss: 0.116397\n",
      "[227]\ttrain's binary_logloss: 0.115744\n",
      "[228]\ttrain's binary_logloss: 0.115241\n",
      "[229]\ttrain's binary_logloss: 0.114706\n",
      "[230]\ttrain's binary_logloss: 0.114348\n",
      "[231]\ttrain's binary_logloss: 0.113906\n",
      "[232]\ttrain's binary_logloss: 0.113534\n",
      "[233]\ttrain's binary_logloss: 0.113161\n",
      "[234]\ttrain's binary_logloss: 0.112658\n",
      "[235]\ttrain's binary_logloss: 0.11218\n",
      "[236]\ttrain's binary_logloss: 0.111752\n",
      "[237]\ttrain's binary_logloss: 0.111266\n",
      "[238]\ttrain's binary_logloss: 0.11082\n",
      "[239]\ttrain's binary_logloss: 0.110329\n",
      "[240]\ttrain's binary_logloss: 0.109861\n",
      "[241]\ttrain's binary_logloss: 0.109598\n",
      "[242]\ttrain's binary_logloss: 0.109082\n",
      "[243]\ttrain's binary_logloss: 0.108708\n",
      "[244]\ttrain's binary_logloss: 0.108284\n",
      "[245]\ttrain's binary_logloss: 0.107735\n",
      "[246]\ttrain's binary_logloss: 0.107267\n",
      "[247]\ttrain's binary_logloss: 0.106863\n",
      "[248]\ttrain's binary_logloss: 0.106298\n",
      "[249]\ttrain's binary_logloss: 0.105944\n",
      "[250]\ttrain's binary_logloss: 0.105679\n",
      "[251]\ttrain's binary_logloss: 0.105136\n",
      "[252]\ttrain's binary_logloss: 0.104807\n",
      "[253]\ttrain's binary_logloss: 0.10451\n",
      "[254]\ttrain's binary_logloss: 0.104076\n",
      "[255]\ttrain's binary_logloss: 0.103735\n",
      "[256]\ttrain's binary_logloss: 0.103418\n",
      "[257]\ttrain's binary_logloss: 0.103173\n",
      "[258]\ttrain's binary_logloss: 0.102829\n",
      "[259]\ttrain's binary_logloss: 0.102462\n",
      "[260]\ttrain's binary_logloss: 0.10204\n",
      "[261]\ttrain's binary_logloss: 0.101655\n",
      "[262]\ttrain's binary_logloss: 0.10139\n",
      "[263]\ttrain's binary_logloss: 0.100887\n",
      "[264]\ttrain's binary_logloss: 0.10056\n",
      "[265]\ttrain's binary_logloss: 0.100219\n",
      "[266]\ttrain's binary_logloss: 0.0998298\n",
      "[267]\ttrain's binary_logloss: 0.0996125\n",
      "[268]\ttrain's binary_logloss: 0.099272\n",
      "[269]\ttrain's binary_logloss: 0.0988129\n",
      "[270]\ttrain's binary_logloss: 0.0984263\n",
      "[271]\ttrain's binary_logloss: 0.0980475\n",
      "[272]\ttrain's binary_logloss: 0.0976559\n",
      "[273]\ttrain's binary_logloss: 0.0971706\n",
      "[274]\ttrain's binary_logloss: 0.0966521\n",
      "[275]\ttrain's binary_logloss: 0.0962974\n",
      "[276]\ttrain's binary_logloss: 0.0959101\n",
      "[277]\ttrain's binary_logloss: 0.0955168\n",
      "[278]\ttrain's binary_logloss: 0.09525\n",
      "[279]\ttrain's binary_logloss: 0.0949607\n",
      "[280]\ttrain's binary_logloss: 0.0945074\n",
      "[281]\ttrain's binary_logloss: 0.0942575\n",
      "[282]\ttrain's binary_logloss: 0.0940096\n",
      "[283]\ttrain's binary_logloss: 0.093557\n",
      "[284]\ttrain's binary_logloss: 0.093279\n",
      "[285]\ttrain's binary_logloss: 0.0929881\n",
      "[286]\ttrain's binary_logloss: 0.0925315\n",
      "[287]\ttrain's binary_logloss: 0.0922306\n",
      "[288]\ttrain's binary_logloss: 0.0919725\n",
      "[289]\ttrain's binary_logloss: 0.0917172\n",
      "[290]\ttrain's binary_logloss: 0.0912802\n",
      "[291]\ttrain's binary_logloss: 0.0910027\n",
      "[292]\ttrain's binary_logloss: 0.0905927\n",
      "[293]\ttrain's binary_logloss: 0.090328\n",
      "[294]\ttrain's binary_logloss: 0.0899746\n",
      "[295]\ttrain's binary_logloss: 0.0896888\n",
      "[296]\ttrain's binary_logloss: 0.0894817\n",
      "[297]\ttrain's binary_logloss: 0.0891636\n",
      "[298]\ttrain's binary_logloss: 0.0888349\n",
      "[299]\ttrain's binary_logloss: 0.0885953\n",
      "[300]\ttrain's binary_logloss: 0.088236\n",
      "[301]\ttrain's binary_logloss: 0.0879255\n",
      "[302]\ttrain's binary_logloss: 0.0875638\n",
      "[303]\ttrain's binary_logloss: 0.0872464\n",
      "[304]\ttrain's binary_logloss: 0.0869583\n",
      "[305]\ttrain's binary_logloss: 0.0865499\n",
      "[306]\ttrain's binary_logloss: 0.0862575\n",
      "[307]\ttrain's binary_logloss: 0.0859256\n",
      "[308]\ttrain's binary_logloss: 0.0856135\n",
      "[309]\ttrain's binary_logloss: 0.0852874\n",
      "[310]\ttrain's binary_logloss: 0.0849515\n",
      "[311]\ttrain's binary_logloss: 0.0845017\n",
      "[312]\ttrain's binary_logloss: 0.0842184\n",
      "[313]\ttrain's binary_logloss: 0.0838351\n",
      "[314]\ttrain's binary_logloss: 0.083489\n",
      "[315]\ttrain's binary_logloss: 0.0832336\n",
      "[316]\ttrain's binary_logloss: 0.0829025\n",
      "[317]\ttrain's binary_logloss: 0.0826862\n",
      "[318]\ttrain's binary_logloss: 0.0824436\n",
      "[319]\ttrain's binary_logloss: 0.0821922\n",
      "[320]\ttrain's binary_logloss: 0.0820017\n",
      "[321]\ttrain's binary_logloss: 0.0816868\n",
      "[322]\ttrain's binary_logloss: 0.0814244\n",
      "[323]\ttrain's binary_logloss: 0.0811457\n",
      "[324]\ttrain's binary_logloss: 0.0809554\n",
      "[325]\ttrain's binary_logloss: 0.0806175\n",
      "[326]\ttrain's binary_logloss: 0.080361\n",
      "[327]\ttrain's binary_logloss: 0.0799872\n",
      "[328]\ttrain's binary_logloss: 0.0796845\n",
      "[329]\ttrain's binary_logloss: 0.0794718\n",
      "[330]\ttrain's binary_logloss: 0.0791083\n",
      "[331]\ttrain's binary_logloss: 0.0789311\n",
      "[332]\ttrain's binary_logloss: 0.0787092\n",
      "[333]\ttrain's binary_logloss: 0.0784438\n",
      "[334]\ttrain's binary_logloss: 0.0782098\n",
      "[335]\ttrain's binary_logloss: 0.0778961\n",
      "[336]\ttrain's binary_logloss: 0.077684\n",
      "[337]\ttrain's binary_logloss: 0.0773722\n",
      "[338]\ttrain's binary_logloss: 0.0768648\n",
      "[339]\ttrain's binary_logloss: 0.0765069\n",
      "[340]\ttrain's binary_logloss: 0.0763368\n",
      "[341]\ttrain's binary_logloss: 0.0760971\n",
      "[342]\ttrain's binary_logloss: 0.075822\n",
      "[343]\ttrain's binary_logloss: 0.0755802\n",
      "[344]\ttrain's binary_logloss: 0.0752465\n",
      "[345]\ttrain's binary_logloss: 0.0749274\n",
      "[346]\ttrain's binary_logloss: 0.0746732\n",
      "[347]\ttrain's binary_logloss: 0.0742712\n",
      "[348]\ttrain's binary_logloss: 0.0739543\n",
      "[349]\ttrain's binary_logloss: 0.0736926\n",
      "[350]\ttrain's binary_logloss: 0.0734034\n",
      "[351]\ttrain's binary_logloss: 0.0731881\n",
      "[352]\ttrain's binary_logloss: 0.0729633\n",
      "[353]\ttrain's binary_logloss: 0.0727896\n",
      "[354]\ttrain's binary_logloss: 0.072562\n",
      "[355]\ttrain's binary_logloss: 0.0723966\n",
      "[356]\ttrain's binary_logloss: 0.0722166\n",
      "[357]\ttrain's binary_logloss: 0.0720762\n",
      "[358]\ttrain's binary_logloss: 0.0718436\n",
      "[359]\ttrain's binary_logloss: 0.0715495\n",
      "[360]\ttrain's binary_logloss: 0.0712312\n",
      "[361]\ttrain's binary_logloss: 0.0709383\n",
      "[362]\ttrain's binary_logloss: 0.0706654\n",
      "[363]\ttrain's binary_logloss: 0.0704478\n",
      "[364]\ttrain's binary_logloss: 0.0701822\n",
      "[365]\ttrain's binary_logloss: 0.0698736\n",
      "[366]\ttrain's binary_logloss: 0.0696692\n",
      "[367]\ttrain's binary_logloss: 0.0694489\n",
      "[368]\ttrain's binary_logloss: 0.0692292\n",
      "[369]\ttrain's binary_logloss: 0.0689507\n",
      "[370]\ttrain's binary_logloss: 0.0686758\n",
      "[371]\ttrain's binary_logloss: 0.068452\n",
      "[372]\ttrain's binary_logloss: 0.0683111\n",
      "[373]\ttrain's binary_logloss: 0.0681434\n",
      "[374]\ttrain's binary_logloss: 0.0679451\n",
      "[375]\ttrain's binary_logloss: 0.0678024\n",
      "[376]\ttrain's binary_logloss: 0.0676655\n",
      "[377]\ttrain's binary_logloss: 0.0675469\n",
      "[378]\ttrain's binary_logloss: 0.0673618\n",
      "[379]\ttrain's binary_logloss: 0.0670873\n",
      "[380]\ttrain's binary_logloss: 0.0668862\n",
      "[381]\ttrain's binary_logloss: 0.0666353\n",
      "[382]\ttrain's binary_logloss: 0.0664688\n",
      "[383]\ttrain's binary_logloss: 0.06623\n",
      "[384]\ttrain's binary_logloss: 0.0660523\n",
      "[385]\ttrain's binary_logloss: 0.0658824\n",
      "[386]\ttrain's binary_logloss: 0.0657147\n",
      "[387]\ttrain's binary_logloss: 0.0654769\n",
      "[388]\ttrain's binary_logloss: 0.065332\n",
      "[389]\ttrain's binary_logloss: 0.0649566\n",
      "[390]\ttrain's binary_logloss: 0.0647142\n",
      "[391]\ttrain's binary_logloss: 0.0645946\n",
      "[392]\ttrain's binary_logloss: 0.0644482\n",
      "[393]\ttrain's binary_logloss: 0.0642709\n",
      "[394]\ttrain's binary_logloss: 0.0641023\n",
      "[395]\ttrain's binary_logloss: 0.0638893\n",
      "[396]\ttrain's binary_logloss: 0.0636629\n",
      "[397]\ttrain's binary_logloss: 0.0635351\n",
      "[398]\ttrain's binary_logloss: 0.0633455\n",
      "[399]\ttrain's binary_logloss: 0.0630941\n",
      "[400]\ttrain's binary_logloss: 0.0629091\n",
      "[401]\ttrain's binary_logloss: 0.0626924\n",
      "[402]\ttrain's binary_logloss: 0.0625167\n",
      "[403]\ttrain's binary_logloss: 0.0622561\n",
      "[404]\ttrain's binary_logloss: 0.0619753\n",
      "[405]\ttrain's binary_logloss: 0.0618633\n",
      "[406]\ttrain's binary_logloss: 0.0617229\n",
      "[407]\ttrain's binary_logloss: 0.0615427\n",
      "[408]\ttrain's binary_logloss: 0.0612426\n",
      "[409]\ttrain's binary_logloss: 0.0610159\n",
      "[410]\ttrain's binary_logloss: 0.0608265\n",
      "[411]\ttrain's binary_logloss: 0.0606313\n",
      "[412]\ttrain's binary_logloss: 0.0604568\n",
      "[413]\ttrain's binary_logloss: 0.0603012\n",
      "[414]\ttrain's binary_logloss: 0.0601036\n",
      "[415]\ttrain's binary_logloss: 0.0599016\n",
      "[416]\ttrain's binary_logloss: 0.0597181\n",
      "[417]\ttrain's binary_logloss: 0.0595756\n",
      "[418]\ttrain's binary_logloss: 0.0594021\n",
      "[419]\ttrain's binary_logloss: 0.0592228\n",
      "[420]\ttrain's binary_logloss: 0.0590974\n",
      "[421]\ttrain's binary_logloss: 0.0589592\n",
      "[422]\ttrain's binary_logloss: 0.0587928\n",
      "[423]\ttrain's binary_logloss: 0.0585746\n",
      "[424]\ttrain's binary_logloss: 0.0584008\n",
      "[425]\ttrain's binary_logloss: 0.0581982\n",
      "[426]\ttrain's binary_logloss: 0.0579921\n",
      "[427]\ttrain's binary_logloss: 0.0578342\n",
      "[428]\ttrain's binary_logloss: 0.0577103\n",
      "[429]\ttrain's binary_logloss: 0.0575945\n",
      "[430]\ttrain's binary_logloss: 0.0573897\n",
      "[431]\ttrain's binary_logloss: 0.0572105\n",
      "[432]\ttrain's binary_logloss: 0.0570479\n",
      "[433]\ttrain's binary_logloss: 0.0567783\n",
      "[434]\ttrain's binary_logloss: 0.0566714\n",
      "[435]\ttrain's binary_logloss: 0.0565666\n",
      "[436]\ttrain's binary_logloss: 0.0563979\n",
      "[437]\ttrain's binary_logloss: 0.056224\n",
      "[438]\ttrain's binary_logloss: 0.0560582\n",
      "[439]\ttrain's binary_logloss: 0.0559133\n",
      "[440]\ttrain's binary_logloss: 0.0557307\n",
      "[441]\ttrain's binary_logloss: 0.055639\n",
      "[442]\ttrain's binary_logloss: 0.0554478\n",
      "[443]\ttrain's binary_logloss: 0.0553049\n",
      "[444]\ttrain's binary_logloss: 0.0551379\n",
      "[445]\ttrain's binary_logloss: 0.0549936\n",
      "[446]\ttrain's binary_logloss: 0.0548406\n",
      "[447]\ttrain's binary_logloss: 0.0546784\n",
      "[448]\ttrain's binary_logloss: 0.0545747\n",
      "[449]\ttrain's binary_logloss: 0.0544377\n",
      "[450]\ttrain's binary_logloss: 0.054326\n",
      "[451]\ttrain's binary_logloss: 0.0541696\n",
      "[452]\ttrain's binary_logloss: 0.0540874\n",
      "[453]\ttrain's binary_logloss: 0.0539605\n",
      "[454]\ttrain's binary_logloss: 0.0538119\n",
      "[455]\ttrain's binary_logloss: 0.0536672\n",
      "[456]\ttrain's binary_logloss: 0.0535799\n",
      "[457]\ttrain's binary_logloss: 0.0533833\n",
      "[458]\ttrain's binary_logloss: 0.0532557\n",
      "[459]\ttrain's binary_logloss: 0.0531591\n",
      "[460]\ttrain's binary_logloss: 0.0529716\n",
      "[461]\ttrain's binary_logloss: 0.0528433\n",
      "[462]\ttrain's binary_logloss: 0.0527358\n",
      "[463]\ttrain's binary_logloss: 0.0526425\n",
      "[464]\ttrain's binary_logloss: 0.0524576\n",
      "[465]\ttrain's binary_logloss: 0.0523841\n",
      "[466]\ttrain's binary_logloss: 0.0522507\n",
      "[467]\ttrain's binary_logloss: 0.0521395\n",
      "[468]\ttrain's binary_logloss: 0.051896\n",
      "[469]\ttrain's binary_logloss: 0.0517641\n",
      "[470]\ttrain's binary_logloss: 0.0516128\n",
      "[471]\ttrain's binary_logloss: 0.0514234\n",
      "[472]\ttrain's binary_logloss: 0.0512009\n",
      "[473]\ttrain's binary_logloss: 0.0510577\n",
      "[474]\ttrain's binary_logloss: 0.0509314\n",
      "[475]\ttrain's binary_logloss: 0.0507913\n",
      "[476]\ttrain's binary_logloss: 0.0507249\n",
      "[477]\ttrain's binary_logloss: 0.0505905\n",
      "[478]\ttrain's binary_logloss: 0.0504886\n",
      "[479]\ttrain's binary_logloss: 0.0503968\n",
      "[480]\ttrain's binary_logloss: 0.0501881\n",
      "[481]\ttrain's binary_logloss: 0.0500122\n",
      "[482]\ttrain's binary_logloss: 0.0497888\n",
      "[483]\ttrain's binary_logloss: 0.0496567\n",
      "[484]\ttrain's binary_logloss: 0.0495297\n",
      "[485]\ttrain's binary_logloss: 0.0493861\n",
      "[486]\ttrain's binary_logloss: 0.0492679\n",
      "[487]\ttrain's binary_logloss: 0.0491456\n",
      "[488]\ttrain's binary_logloss: 0.048953\n",
      "[489]\ttrain's binary_logloss: 0.0488285\n",
      "[490]\ttrain's binary_logloss: 0.0486891\n",
      "[491]\ttrain's binary_logloss: 0.0486347\n",
      "[492]\ttrain's binary_logloss: 0.0485155\n",
      "[493]\ttrain's binary_logloss: 0.0482789\n",
      "[494]\ttrain's binary_logloss: 0.0481425\n",
      "[495]\ttrain's binary_logloss: 0.047983\n",
      "[496]\ttrain's binary_logloss: 0.0478556\n",
      "[497]\ttrain's binary_logloss: 0.0476813\n",
      "[498]\ttrain's binary_logloss: 0.0475647\n",
      "[499]\ttrain's binary_logloss: 0.0475025\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "[0]\ttest-logloss:0.48809\n",
      "[1]\ttest-logloss:0.44679\n",
      "[2]\ttest-logloss:0.42412\n",
      "[3]\ttest-logloss:0.44016\n",
      "[4]\ttest-logloss:0.44331\n",
      "[5]\ttest-logloss:0.44183\n",
      "[6]\ttest-logloss:0.46534\n",
      "[7]\ttest-logloss:0.46678\n",
      "[8]\ttest-logloss:0.47348\n",
      "[9]\ttest-logloss:0.46493\n",
      "[10]\ttest-logloss:0.46420\n",
      "[11]\ttest-logloss:0.45894\n",
      "[12]\ttest-logloss:0.46860\n",
      "[13]\ttest-logloss:0.46470\n",
      "[14]\ttest-logloss:0.45878\n",
      "[15]\ttest-logloss:0.45910\n",
      "[16]\ttest-logloss:0.46146\n",
      "[17]\ttest-logloss:0.47669\n",
      "[18]\ttest-logloss:0.47311\n",
      "[19]\ttest-logloss:0.47043\n",
      "[20]\ttest-logloss:0.48647\n",
      "[21]\ttest-logloss:0.48392\n",
      "[22]\ttest-logloss:0.49170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trainの形状： (646, 43)  y_trainの形状： (646,)  X_testの形状： (278, 43)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.645979\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.607469\n",
      "[3]\ttrain's binary_logloss: 0.575587\n",
      "[4]\ttrain's binary_logloss: 0.54889\n",
      "[5]\ttrain's binary_logloss: 0.524775\n",
      "[6]\ttrain's binary_logloss: 0.505158\n",
      "[7]\ttrain's binary_logloss: 0.487333\n",
      "[8]\ttrain's binary_logloss: 0.473403\n",
      "[9]\ttrain's binary_logloss: 0.459756\n",
      "[10]\ttrain's binary_logloss: 0.447863\n",
      "[11]\ttrain's binary_logloss: 0.437382\n",
      "[12]\ttrain's binary_logloss: 0.42888\n",
      "[13]\ttrain's binary_logloss: 0.420697\n",
      "[14]\ttrain's binary_logloss: 0.413379\n",
      "[15]\ttrain's binary_logloss: 0.407086\n",
      "[16]\ttrain's binary_logloss: 0.400418\n",
      "[17]\ttrain's binary_logloss: 0.394532\n",
      "[18]\ttrain's binary_logloss: 0.389788\n",
      "[19]\ttrain's binary_logloss: 0.384675\n",
      "[20]\ttrain's binary_logloss: 0.380166\n",
      "[21]\ttrain's binary_logloss: 0.375858\n",
      "[22]\ttrain's binary_logloss: 0.371429\n",
      "[23]\ttrain's binary_logloss: 0.367647\n",
      "[24]\ttrain's binary_logloss: 0.362687\n",
      "[25]\ttrain's binary_logloss: 0.358916\n",
      "[26]\ttrain's binary_logloss: 0.3553\n",
      "[27]\ttrain's binary_logloss: 0.351454\n",
      "[28]\ttrain's binary_logloss: 0.347952\n",
      "[29]\ttrain's binary_logloss: 0.344491\n",
      "[30]\ttrain's binary_logloss: 0.341\n",
      "[31]\ttrain's binary_logloss: 0.338273\n",
      "[32]\ttrain's binary_logloss: 0.335374\n",
      "[33]\ttrain's binary_logloss: 0.332966\n",
      "[34]\ttrain's binary_logloss: 0.329758\n",
      "[35]\ttrain's binary_logloss: 0.327267\n",
      "[36]\ttrain's binary_logloss: 0.324796\n",
      "[37]\ttrain's binary_logloss: 0.322593\n",
      "[38]\ttrain's binary_logloss: 0.319497\n",
      "[39]\ttrain's binary_logloss: 0.316936\n",
      "[40]\ttrain's binary_logloss: 0.314706\n",
      "[41]\ttrain's binary_logloss: 0.312041\n",
      "[42]\ttrain's binary_logloss: 0.309377\n",
      "[43]\ttrain's binary_logloss: 0.307265\n",
      "[44]\ttrain's binary_logloss: 0.304797\n",
      "[45]\ttrain's binary_logloss: 0.302932\n",
      "[46]\ttrain's binary_logloss: 0.301226\n",
      "[47]\ttrain's binary_logloss: 0.299184\n",
      "[48]\ttrain's binary_logloss: 0.29694\n",
      "[49]\ttrain's binary_logloss: 0.295391\n",
      "[50]\ttrain's binary_logloss: 0.293026\n",
      "[51]\ttrain's binary_logloss: 0.291295\n",
      "[52]\ttrain's binary_logloss: 0.289817\n",
      "[53]\ttrain's binary_logloss: 0.28778\n",
      "[54]\ttrain's binary_logloss: 0.285807\n",
      "[55]\ttrain's binary_logloss: 0.283796\n",
      "[56]\ttrain's binary_logloss: 0.281902\n",
      "[57]\ttrain's binary_logloss: 0.280353\n",
      "[58]\ttrain's binary_logloss: 0.278133\n",
      "[59]\ttrain's binary_logloss: 0.276636\n",
      "[60]\ttrain's binary_logloss: 0.274882\n",
      "[61]\ttrain's binary_logloss: 0.272477\n",
      "[62]\ttrain's binary_logloss: 0.27115\n",
      "[63]\ttrain's binary_logloss: 0.268909\n",
      "[64]\ttrain's binary_logloss: 0.26711\n",
      "[65]\ttrain's binary_logloss: 0.265627\n",
      "[66]\ttrain's binary_logloss: 0.264103\n",
      "[67]\ttrain's binary_logloss: 0.262114\n",
      "[68]\ttrain's binary_logloss: 0.26011\n",
      "[69]\ttrain's binary_logloss: 0.258665\n",
      "[70]\ttrain's binary_logloss: 0.25738\n",
      "[71]\ttrain's binary_logloss: 0.255726\n",
      "[72]\ttrain's binary_logloss: 0.254223\n",
      "[73]\ttrain's binary_logloss: 0.252303\n",
      "[74]\ttrain's binary_logloss: 0.251051\n",
      "[75]\ttrain's binary_logloss: 0.249495\n",
      "[76]\ttrain's binary_logloss: 0.247928\n",
      "[77]\ttrain's binary_logloss: 0.246865\n",
      "[78]\ttrain's binary_logloss: 0.245542\n",
      "[79]\ttrain's binary_logloss: 0.24408\n",
      "[80]\ttrain's binary_logloss: 0.242746\n",
      "[81]\ttrain's binary_logloss: 0.241516\n",
      "[82]\ttrain's binary_logloss: 0.240294\n",
      "[83]\ttrain's binary_logloss: 0.238656\n",
      "[84]\ttrain's binary_logloss: 0.237595\n",
      "[85]\ttrain's binary_logloss: 0.236696\n",
      "[86]\ttrain's binary_logloss: 0.235792\n",
      "[87]\ttrain's binary_logloss: 0.234593\n",
      "[88]\ttrain's binary_logloss: 0.233253\n",
      "[89]\ttrain's binary_logloss: 0.232353\n",
      "[90]\ttrain's binary_logloss: 0.230887\n",
      "[91]\ttrain's binary_logloss: 0.229588\n",
      "[92]\ttrain's binary_logloss: 0.228103\n",
      "[93]\ttrain's binary_logloss: 0.227024\n",
      "[94]\ttrain's binary_logloss: 0.225505\n",
      "[95]\ttrain's binary_logloss: 0.224624\n",
      "[96]\ttrain's binary_logloss: 0.222889\n",
      "[97]\ttrain's binary_logloss: 0.221902\n",
      "[98]\ttrain's binary_logloss: 0.22063\n",
      "[99]\ttrain's binary_logloss: 0.218838\n",
      "[100]\ttrain's binary_logloss: 0.217476\n",
      "[101]\ttrain's binary_logloss: 0.21629\n",
      "[102]\ttrain's binary_logloss: 0.214851\n",
      "[103]\ttrain's binary_logloss: 0.213776\n",
      "[104]\ttrain's binary_logloss: 0.212298\n",
      "[105]\ttrain's binary_logloss: 0.211099\n",
      "[106]\ttrain's binary_logloss: 0.210155\n",
      "[107]\ttrain's binary_logloss: 0.209238\n",
      "[108]\ttrain's binary_logloss: 0.2083\n",
      "[109]\ttrain's binary_logloss: 0.207146\n",
      "[110]\ttrain's binary_logloss: 0.206077\n",
      "[111]\ttrain's binary_logloss: 0.204606\n",
      "[112]\ttrain's binary_logloss: 0.203562\n",
      "[113]\ttrain's binary_logloss: 0.202641\n",
      "[114]\ttrain's binary_logloss: 0.20154\n",
      "[115]\ttrain's binary_logloss: 0.200288\n",
      "[116]\ttrain's binary_logloss: 0.199032\n",
      "[117]\ttrain's binary_logloss: 0.197964\n",
      "[118]\ttrain's binary_logloss: 0.196656\n",
      "[119]\ttrain's binary_logloss: 0.195804\n",
      "[120]\ttrain's binary_logloss: 0.19452\n",
      "[121]\ttrain's binary_logloss: 0.193742\n",
      "[122]\ttrain's binary_logloss: 0.192721\n",
      "[123]\ttrain's binary_logloss: 0.191777\n",
      "[124]\ttrain's binary_logloss: 0.191043\n",
      "[125]\ttrain's binary_logloss: 0.190235\n",
      "[126]\ttrain's binary_logloss: 0.189519\n",
      "[127]\ttrain's binary_logloss: 0.188461\n",
      "[128]\ttrain's binary_logloss: 0.187743\n",
      "[129]\ttrain's binary_logloss: 0.186209\n",
      "[130]\ttrain's binary_logloss: 0.185589\n",
      "[131]\ttrain's binary_logloss: 0.184918\n",
      "[132]\ttrain's binary_logloss: 0.183813\n",
      "[133]\ttrain's binary_logloss: 0.182655\n",
      "[134]\ttrain's binary_logloss: 0.181989\n",
      "[135]\ttrain's binary_logloss: 0.181103\n",
      "[136]\ttrain's binary_logloss: 0.18046\n",
      "[137]\ttrain's binary_logloss: 0.179155\n",
      "[138]\ttrain's binary_logloss: 0.178649\n",
      "[139]\ttrain's binary_logloss: 0.177763\n",
      "[140]\ttrain's binary_logloss: 0.176758\n",
      "[141]\ttrain's binary_logloss: 0.175398\n",
      "[142]\ttrain's binary_logloss: 0.174555\n",
      "[143]\ttrain's binary_logloss: 0.173431\n",
      "[144]\ttrain's binary_logloss: 0.172795\n",
      "[145]\ttrain's binary_logloss: 0.171829\n",
      "[146]\ttrain's binary_logloss: 0.170794\n",
      "[147]\ttrain's binary_logloss: 0.16996\n",
      "[148]\ttrain's binary_logloss: 0.169299\n",
      "[149]\ttrain's binary_logloss: 0.168474\n",
      "[150]\ttrain's binary_logloss: 0.167255\n",
      "[151]\ttrain's binary_logloss: 0.166508\n",
      "[152]\ttrain's binary_logloss: 0.165976\n",
      "[153]\ttrain's binary_logloss: 0.165176\n",
      "[154]\ttrain's binary_logloss: 0.164243\n",
      "[155]\ttrain's binary_logloss: 0.163129\n",
      "[156]\ttrain's binary_logloss: 0.16261\n",
      "[157]\ttrain's binary_logloss: 0.161583\n",
      "[158]\ttrain's binary_logloss: 0.16081\n",
      "[159]\ttrain's binary_logloss: 0.159906\n",
      "[160]\ttrain's binary_logloss: 0.159349\n",
      "[161]\ttrain's binary_logloss: 0.158649\n",
      "[162]\ttrain's binary_logloss: 0.157701\n",
      "[163]\ttrain's binary_logloss: 0.15675\n",
      "[164]\ttrain's binary_logloss: 0.15578\n",
      "[165]\ttrain's binary_logloss: 0.154765\n",
      "[166]\ttrain's binary_logloss: 0.154205\n",
      "[167]\ttrain's binary_logloss: 0.153335\n",
      "[168]\ttrain's binary_logloss: 0.152659\n",
      "[169]\ttrain's binary_logloss: 0.151726\n",
      "[170]\ttrain's binary_logloss: 0.150959\n",
      "[171]\ttrain's binary_logloss: 0.150255\n",
      "[172]\ttrain's binary_logloss: 0.149312\n",
      "[173]\ttrain's binary_logloss: 0.148715\n",
      "[174]\ttrain's binary_logloss: 0.147935\n",
      "[175]\ttrain's binary_logloss: 0.147207\n",
      "[176]\ttrain's binary_logloss: 0.146467\n",
      "[177]\ttrain's binary_logloss: 0.145747\n",
      "[178]\ttrain's binary_logloss: 0.144968\n",
      "[179]\ttrain's binary_logloss: 0.143976\n",
      "[180]\ttrain's binary_logloss: 0.143349\n",
      "[181]\ttrain's binary_logloss: 0.142777\n",
      "[182]\ttrain's binary_logloss: 0.141895\n",
      "[183]\ttrain's binary_logloss: 0.14117\n",
      "[184]\ttrain's binary_logloss: 0.140235\n",
      "[185]\ttrain's binary_logloss: 0.139442\n",
      "[186]\ttrain's binary_logloss: 0.138812\n",
      "[187]\ttrain's binary_logloss: 0.138275\n",
      "[188]\ttrain's binary_logloss: 0.137689\n",
      "[189]\ttrain's binary_logloss: 0.137015\n",
      "[190]\ttrain's binary_logloss: 0.136435\n",
      "[191]\ttrain's binary_logloss: 0.135791\n",
      "[192]\ttrain's binary_logloss: 0.135149\n",
      "[193]\ttrain's binary_logloss: 0.134353\n",
      "[194]\ttrain's binary_logloss: 0.133886\n",
      "[195]\ttrain's binary_logloss: 0.133157\n",
      "[196]\ttrain's binary_logloss: 0.132694\n",
      "[197]\ttrain's binary_logloss: 0.13204\n",
      "[198]\ttrain's binary_logloss: 0.131377\n",
      "[199]\ttrain's binary_logloss: 0.130818\n",
      "[200]\ttrain's binary_logloss: 0.130261\n",
      "[201]\ttrain's binary_logloss: 0.129614\n",
      "[202]\ttrain's binary_logloss: 0.129119\n",
      "[203]\ttrain's binary_logloss: 0.128704\n",
      "[204]\ttrain's binary_logloss: 0.128289\n",
      "[205]\ttrain's binary_logloss: 0.127834\n",
      "[206]\ttrain's binary_logloss: 0.127428\n",
      "[207]\ttrain's binary_logloss: 0.126912\n",
      "[208]\ttrain's binary_logloss: 0.126199\n",
      "[209]\ttrain's binary_logloss: 0.125629\n",
      "[210]\ttrain's binary_logloss: 0.12503\n",
      "[211]\ttrain's binary_logloss: 0.124452\n",
      "[212]\ttrain's binary_logloss: 0.123912\n",
      "[213]\ttrain's binary_logloss: 0.123397\n",
      "[214]\ttrain's binary_logloss: 0.122826\n",
      "[215]\ttrain's binary_logloss: 0.122334\n",
      "[216]\ttrain's binary_logloss: 0.121682\n",
      "[217]\ttrain's binary_logloss: 0.121058\n",
      "[218]\ttrain's binary_logloss: 0.120728\n",
      "[219]\ttrain's binary_logloss: 0.120108\n",
      "[220]\ttrain's binary_logloss: 0.119467\n",
      "[221]\ttrain's binary_logloss: 0.119047\n",
      "[222]\ttrain's binary_logloss: 0.11837\n",
      "[223]\ttrain's binary_logloss: 0.117889\n",
      "[224]\ttrain's binary_logloss: 0.117508\n",
      "[225]\ttrain's binary_logloss: 0.116907\n",
      "[226]\ttrain's binary_logloss: 0.116397\n",
      "[227]\ttrain's binary_logloss: 0.115744\n",
      "[228]\ttrain's binary_logloss: 0.115241\n",
      "[229]\ttrain's binary_logloss: 0.114706\n",
      "[230]\ttrain's binary_logloss: 0.114348\n",
      "[231]\ttrain's binary_logloss: 0.113906\n",
      "[232]\ttrain's binary_logloss: 0.113534\n",
      "[233]\ttrain's binary_logloss: 0.113161\n",
      "[234]\ttrain's binary_logloss: 0.112658\n",
      "[235]\ttrain's binary_logloss: 0.11218\n",
      "[236]\ttrain's binary_logloss: 0.111752\n",
      "[237]\ttrain's binary_logloss: 0.111266\n",
      "[238]\ttrain's binary_logloss: 0.11082\n",
      "[239]\ttrain's binary_logloss: 0.110329\n",
      "[240]\ttrain's binary_logloss: 0.109861\n",
      "[241]\ttrain's binary_logloss: 0.109598\n",
      "[242]\ttrain's binary_logloss: 0.109082\n",
      "[243]\ttrain's binary_logloss: 0.108708\n",
      "[244]\ttrain's binary_logloss: 0.108284\n",
      "[245]\ttrain's binary_logloss: 0.107735\n",
      "[246]\ttrain's binary_logloss: 0.107267\n",
      "[247]\ttrain's binary_logloss: 0.106863\n",
      "[248]\ttrain's binary_logloss: 0.106298\n",
      "[249]\ttrain's binary_logloss: 0.105944\n",
      "[250]\ttrain's binary_logloss: 0.105679\n",
      "[251]\ttrain's binary_logloss: 0.105136\n",
      "[252]\ttrain's binary_logloss: 0.104807\n",
      "[253]\ttrain's binary_logloss: 0.10451\n",
      "[254]\ttrain's binary_logloss: 0.104076\n",
      "[255]\ttrain's binary_logloss: 0.103735\n",
      "[256]\ttrain's binary_logloss: 0.103418\n",
      "[257]\ttrain's binary_logloss: 0.103173\n",
      "[258]\ttrain's binary_logloss: 0.102829\n",
      "[259]\ttrain's binary_logloss: 0.102462\n",
      "[260]\ttrain's binary_logloss: 0.10204\n",
      "[261]\ttrain's binary_logloss: 0.101655\n",
      "[262]\ttrain's binary_logloss: 0.10139\n",
      "[263]\ttrain's binary_logloss: 0.100887\n",
      "[264]\ttrain's binary_logloss: 0.10056\n",
      "[265]\ttrain's binary_logloss: 0.100219\n",
      "[266]\ttrain's binary_logloss: 0.0998298\n",
      "[267]\ttrain's binary_logloss: 0.0996125\n",
      "[268]\ttrain's binary_logloss: 0.099272\n",
      "[269]\ttrain's binary_logloss: 0.0988129\n",
      "[270]\ttrain's binary_logloss: 0.0984263\n",
      "[271]\ttrain's binary_logloss: 0.0980475\n",
      "[272]\ttrain's binary_logloss: 0.0976559\n",
      "[273]\ttrain's binary_logloss: 0.0971706\n",
      "[274]\ttrain's binary_logloss: 0.0966521\n",
      "[275]\ttrain's binary_logloss: 0.0962974\n",
      "[276]\ttrain's binary_logloss: 0.0959101\n",
      "[277]\ttrain's binary_logloss: 0.0955168\n",
      "[278]\ttrain's binary_logloss: 0.09525\n",
      "[279]\ttrain's binary_logloss: 0.0949607\n",
      "[280]\ttrain's binary_logloss: 0.0945074\n",
      "[281]\ttrain's binary_logloss: 0.0942575\n",
      "[282]\ttrain's binary_logloss: 0.0940096\n",
      "[283]\ttrain's binary_logloss: 0.093557\n",
      "[284]\ttrain's binary_logloss: 0.093279\n",
      "[285]\ttrain's binary_logloss: 0.0929881\n",
      "[286]\ttrain's binary_logloss: 0.0925315\n",
      "[287]\ttrain's binary_logloss: 0.0922306\n",
      "[288]\ttrain's binary_logloss: 0.0919725\n",
      "[289]\ttrain's binary_logloss: 0.0917172\n",
      "[290]\ttrain's binary_logloss: 0.0912802\n",
      "[291]\ttrain's binary_logloss: 0.0910027\n",
      "[292]\ttrain's binary_logloss: 0.0905927\n",
      "[293]\ttrain's binary_logloss: 0.090328\n",
      "[294]\ttrain's binary_logloss: 0.0899746\n",
      "[295]\ttrain's binary_logloss: 0.0896888\n",
      "[296]\ttrain's binary_logloss: 0.0894817\n",
      "[297]\ttrain's binary_logloss: 0.0891636\n",
      "[298]\ttrain's binary_logloss: 0.0888349\n",
      "[299]\ttrain's binary_logloss: 0.0885953\n",
      "[300]\ttrain's binary_logloss: 0.088236\n",
      "[301]\ttrain's binary_logloss: 0.0879255\n",
      "[302]\ttrain's binary_logloss: 0.0875638\n",
      "[303]\ttrain's binary_logloss: 0.0872464\n",
      "[304]\ttrain's binary_logloss: 0.0869583\n",
      "[305]\ttrain's binary_logloss: 0.0865499\n",
      "[306]\ttrain's binary_logloss: 0.0862575\n",
      "[307]\ttrain's binary_logloss: 0.0859256\n",
      "[308]\ttrain's binary_logloss: 0.0856135\n",
      "[309]\ttrain's binary_logloss: 0.0852874\n",
      "[310]\ttrain's binary_logloss: 0.0849515\n",
      "[311]\ttrain's binary_logloss: 0.0845017\n",
      "[312]\ttrain's binary_logloss: 0.0842184\n",
      "[313]\ttrain's binary_logloss: 0.0838351\n",
      "[314]\ttrain's binary_logloss: 0.083489\n",
      "[315]\ttrain's binary_logloss: 0.0832336\n",
      "[316]\ttrain's binary_logloss: 0.0829025\n",
      "[317]\ttrain's binary_logloss: 0.0826862\n",
      "[318]\ttrain's binary_logloss: 0.0824436\n",
      "[319]\ttrain's binary_logloss: 0.0821922\n",
      "[320]\ttrain's binary_logloss: 0.0820017\n",
      "[321]\ttrain's binary_logloss: 0.0816868\n",
      "[322]\ttrain's binary_logloss: 0.0814244\n",
      "[323]\ttrain's binary_logloss: 0.0811457\n",
      "[324]\ttrain's binary_logloss: 0.0809554\n",
      "[325]\ttrain's binary_logloss: 0.0806175\n",
      "[326]\ttrain's binary_logloss: 0.080361\n",
      "[327]\ttrain's binary_logloss: 0.0799872\n",
      "[328]\ttrain's binary_logloss: 0.0796845\n",
      "[329]\ttrain's binary_logloss: 0.0794718\n",
      "[330]\ttrain's binary_logloss: 0.0791083\n",
      "[331]\ttrain's binary_logloss: 0.0789311\n",
      "[332]\ttrain's binary_logloss: 0.0787092\n",
      "[333]\ttrain's binary_logloss: 0.0784438\n",
      "[334]\ttrain's binary_logloss: 0.0782098\n",
      "[335]\ttrain's binary_logloss: 0.0778961\n",
      "[336]\ttrain's binary_logloss: 0.077684\n",
      "[337]\ttrain's binary_logloss: 0.0773722\n",
      "[338]\ttrain's binary_logloss: 0.0768648\n",
      "[339]\ttrain's binary_logloss: 0.0765069\n",
      "[340]\ttrain's binary_logloss: 0.0763368\n",
      "[341]\ttrain's binary_logloss: 0.0760971\n",
      "[342]\ttrain's binary_logloss: 0.075822\n",
      "[343]\ttrain's binary_logloss: 0.0755802\n",
      "[344]\ttrain's binary_logloss: 0.0752465\n",
      "[345]\ttrain's binary_logloss: 0.0749274\n",
      "[346]\ttrain's binary_logloss: 0.0746732\n",
      "[347]\ttrain's binary_logloss: 0.0742712\n",
      "[348]\ttrain's binary_logloss: 0.0739543\n",
      "[349]\ttrain's binary_logloss: 0.0736926\n",
      "[350]\ttrain's binary_logloss: 0.0734034\n",
      "[351]\ttrain's binary_logloss: 0.0731881\n",
      "[352]\ttrain's binary_logloss: 0.0729633\n",
      "[353]\ttrain's binary_logloss: 0.0727896\n",
      "[354]\ttrain's binary_logloss: 0.072562\n",
      "[355]\ttrain's binary_logloss: 0.0723966\n",
      "[356]\ttrain's binary_logloss: 0.0722166\n",
      "[357]\ttrain's binary_logloss: 0.0720762\n",
      "[358]\ttrain's binary_logloss: 0.0718436\n",
      "[359]\ttrain's binary_logloss: 0.0715495\n",
      "[360]\ttrain's binary_logloss: 0.0712312\n",
      "[361]\ttrain's binary_logloss: 0.0709383\n",
      "[362]\ttrain's binary_logloss: 0.0706654\n",
      "[363]\ttrain's binary_logloss: 0.0704478\n",
      "[364]\ttrain's binary_logloss: 0.0701822\n",
      "[365]\ttrain's binary_logloss: 0.0698736\n",
      "[366]\ttrain's binary_logloss: 0.0696692\n",
      "[367]\ttrain's binary_logloss: 0.0694489\n",
      "[368]\ttrain's binary_logloss: 0.0692292\n",
      "[369]\ttrain's binary_logloss: 0.0689507\n",
      "[370]\ttrain's binary_logloss: 0.0686758\n",
      "[371]\ttrain's binary_logloss: 0.068452\n",
      "[372]\ttrain's binary_logloss: 0.0683111\n",
      "[373]\ttrain's binary_logloss: 0.0681434\n",
      "[374]\ttrain's binary_logloss: 0.0679451\n",
      "[375]\ttrain's binary_logloss: 0.0678024\n",
      "[376]\ttrain's binary_logloss: 0.0676655\n",
      "[377]\ttrain's binary_logloss: 0.0675469\n",
      "[378]\ttrain's binary_logloss: 0.0673618\n",
      "[379]\ttrain's binary_logloss: 0.0670873\n",
      "[380]\ttrain's binary_logloss: 0.0668862\n",
      "[381]\ttrain's binary_logloss: 0.0666353\n",
      "[382]\ttrain's binary_logloss: 0.0664688\n",
      "[383]\ttrain's binary_logloss: 0.06623\n",
      "[384]\ttrain's binary_logloss: 0.0660523\n",
      "[385]\ttrain's binary_logloss: 0.0658824\n",
      "[386]\ttrain's binary_logloss: 0.0657147\n",
      "[387]\ttrain's binary_logloss: 0.0654769\n",
      "[388]\ttrain's binary_logloss: 0.065332\n",
      "[389]\ttrain's binary_logloss: 0.0649566\n",
      "[390]\ttrain's binary_logloss: 0.0647142\n",
      "[391]\ttrain's binary_logloss: 0.0645946\n",
      "[392]\ttrain's binary_logloss: 0.0644482\n",
      "[393]\ttrain's binary_logloss: 0.0642709\n",
      "[394]\ttrain's binary_logloss: 0.0641023\n",
      "[395]\ttrain's binary_logloss: 0.0638893\n",
      "[396]\ttrain's binary_logloss: 0.0636629\n",
      "[397]\ttrain's binary_logloss: 0.0635351\n",
      "[398]\ttrain's binary_logloss: 0.0633455\n",
      "[399]\ttrain's binary_logloss: 0.0630941\n",
      "[400]\ttrain's binary_logloss: 0.0629091\n",
      "[401]\ttrain's binary_logloss: 0.0626924\n",
      "[402]\ttrain's binary_logloss: 0.0625167\n",
      "[403]\ttrain's binary_logloss: 0.0622561\n",
      "[404]\ttrain's binary_logloss: 0.0619753\n",
      "[405]\ttrain's binary_logloss: 0.0618633\n",
      "[406]\ttrain's binary_logloss: 0.0617229\n",
      "[407]\ttrain's binary_logloss: 0.0615427\n",
      "[408]\ttrain's binary_logloss: 0.0612426\n",
      "[409]\ttrain's binary_logloss: 0.0610159\n",
      "[410]\ttrain's binary_logloss: 0.0608265\n",
      "[411]\ttrain's binary_logloss: 0.0606313\n",
      "[412]\ttrain's binary_logloss: 0.0604568\n",
      "[413]\ttrain's binary_logloss: 0.0603012\n",
      "[414]\ttrain's binary_logloss: 0.0601036\n",
      "[415]\ttrain's binary_logloss: 0.0599016\n",
      "[416]\ttrain's binary_logloss: 0.0597181\n",
      "[417]\ttrain's binary_logloss: 0.0595756\n",
      "[418]\ttrain's binary_logloss: 0.0594021\n",
      "[419]\ttrain's binary_logloss: 0.0592228\n",
      "[420]\ttrain's binary_logloss: 0.0590974\n",
      "[421]\ttrain's binary_logloss: 0.0589592\n",
      "[422]\ttrain's binary_logloss: 0.0587928\n",
      "[423]\ttrain's binary_logloss: 0.0585746\n",
      "[424]\ttrain's binary_logloss: 0.0584008\n",
      "[425]\ttrain's binary_logloss: 0.0581982\n",
      "[426]\ttrain's binary_logloss: 0.0579921\n",
      "[427]\ttrain's binary_logloss: 0.0578342\n",
      "[428]\ttrain's binary_logloss: 0.0577103\n",
      "[429]\ttrain's binary_logloss: 0.0575945\n",
      "[430]\ttrain's binary_logloss: 0.0573897\n",
      "[431]\ttrain's binary_logloss: 0.0572105\n",
      "[432]\ttrain's binary_logloss: 0.0570479\n",
      "[433]\ttrain's binary_logloss: 0.0567783\n",
      "[434]\ttrain's binary_logloss: 0.0566714\n",
      "[435]\ttrain's binary_logloss: 0.0565666\n",
      "[436]\ttrain's binary_logloss: 0.0563979\n",
      "[437]\ttrain's binary_logloss: 0.056224\n",
      "[438]\ttrain's binary_logloss: 0.0560582\n",
      "[439]\ttrain's binary_logloss: 0.0559133\n",
      "[440]\ttrain's binary_logloss: 0.0557307\n",
      "[441]\ttrain's binary_logloss: 0.055639\n",
      "[442]\ttrain's binary_logloss: 0.0554478\n",
      "[443]\ttrain's binary_logloss: 0.0553049\n",
      "[444]\ttrain's binary_logloss: 0.0551379\n",
      "[445]\ttrain's binary_logloss: 0.0549936\n",
      "[446]\ttrain's binary_logloss: 0.0548406\n",
      "[447]\ttrain's binary_logloss: 0.0546784\n",
      "[448]\ttrain's binary_logloss: 0.0545747\n",
      "[449]\ttrain's binary_logloss: 0.0544377\n",
      "[450]\ttrain's binary_logloss: 0.054326\n",
      "[451]\ttrain's binary_logloss: 0.0541696\n",
      "[452]\ttrain's binary_logloss: 0.0540874\n",
      "[453]\ttrain's binary_logloss: 0.0539605\n",
      "[454]\ttrain's binary_logloss: 0.0538119\n",
      "[455]\ttrain's binary_logloss: 0.0536672\n",
      "[456]\ttrain's binary_logloss: 0.0535799\n",
      "[457]\ttrain's binary_logloss: 0.0533833\n",
      "[458]\ttrain's binary_logloss: 0.0532557\n",
      "[459]\ttrain's binary_logloss: 0.0531591\n",
      "[460]\ttrain's binary_logloss: 0.0529716\n",
      "[461]\ttrain's binary_logloss: 0.0528433\n",
      "[462]\ttrain's binary_logloss: 0.0527358\n",
      "[463]\ttrain's binary_logloss: 0.0526425\n",
      "[464]\ttrain's binary_logloss: 0.0524576\n",
      "[465]\ttrain's binary_logloss: 0.0523841\n",
      "[466]\ttrain's binary_logloss: 0.0522507\n",
      "[467]\ttrain's binary_logloss: 0.0521395\n",
      "[468]\ttrain's binary_logloss: 0.051896\n",
      "[469]\ttrain's binary_logloss: 0.0517641\n",
      "[470]\ttrain's binary_logloss: 0.0516128\n",
      "[471]\ttrain's binary_logloss: 0.0514234\n",
      "[472]\ttrain's binary_logloss: 0.0512009\n",
      "[473]\ttrain's binary_logloss: 0.0510577\n",
      "[474]\ttrain's binary_logloss: 0.0509314\n",
      "[475]\ttrain's binary_logloss: 0.0507913\n",
      "[476]\ttrain's binary_logloss: 0.0507249\n",
      "[477]\ttrain's binary_logloss: 0.0505905\n",
      "[478]\ttrain's binary_logloss: 0.0504886\n",
      "[479]\ttrain's binary_logloss: 0.0503968\n",
      "[480]\ttrain's binary_logloss: 0.0501881\n",
      "[481]\ttrain's binary_logloss: 0.0500122\n",
      "[482]\ttrain's binary_logloss: 0.0497888\n",
      "[483]\ttrain's binary_logloss: 0.0496567\n",
      "[484]\ttrain's binary_logloss: 0.0495297\n",
      "[485]\ttrain's binary_logloss: 0.0493861\n",
      "[486]\ttrain's binary_logloss: 0.0492679\n",
      "[487]\ttrain's binary_logloss: 0.0491456\n",
      "[488]\ttrain's binary_logloss: 0.048953\n",
      "[489]\ttrain's binary_logloss: 0.0488285\n",
      "[490]\ttrain's binary_logloss: 0.0486891\n",
      "[491]\ttrain's binary_logloss: 0.0486347\n",
      "[492]\ttrain's binary_logloss: 0.0485155\n",
      "[493]\ttrain's binary_logloss: 0.0482789\n",
      "[494]\ttrain's binary_logloss: 0.0481425\n",
      "[495]\ttrain's binary_logloss: 0.047983\n",
      "[496]\ttrain's binary_logloss: 0.0478556\n",
      "[497]\ttrain's binary_logloss: 0.0476813\n",
      "[498]\ttrain's binary_logloss: 0.0475647\n",
      "[499]\ttrain's binary_logloss: 0.0475025\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "[0]\ttest-logloss:0.48809\n",
      "[1]\ttest-logloss:0.44679\n",
      "[2]\ttest-logloss:0.42412\n",
      "[3]\ttest-logloss:0.44016\n",
      "[4]\ttest-logloss:0.44331\n",
      "[5]\ttest-logloss:0.44183\n",
      "[6]\ttest-logloss:0.46534\n",
      "[7]\ttest-logloss:0.46678\n",
      "[8]\ttest-logloss:0.47348\n",
      "[9]\ttest-logloss:0.46493\n",
      "[10]\ttest-logloss:0.46420\n",
      "[11]\ttest-logloss:0.45894\n",
      "[12]\ttest-logloss:0.46860\n",
      "[13]\ttest-logloss:0.46470\n",
      "[14]\ttest-logloss:0.45878\n",
      "[15]\ttest-logloss:0.45910\n",
      "[16]\ttest-logloss:0.46146\n",
      "[17]\ttest-logloss:0.47669\n",
      "[18]\ttest-logloss:0.47311\n",
      "[19]\ttest-logloss:0.47043\n",
      "[20]\ttest-logloss:0.48647\n",
      "[21]\ttest-logloss:0.48392\n",
      "[22]\ttest-logloss:0.49170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trainの形状： (646, 43)  y_trainの形状： (646,)  X_testの形状： (278, 43)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.645979\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.607469\n",
      "[3]\ttrain's binary_logloss: 0.575587\n",
      "[4]\ttrain's binary_logloss: 0.54889\n",
      "[5]\ttrain's binary_logloss: 0.524775\n",
      "[6]\ttrain's binary_logloss: 0.505158\n",
      "[7]\ttrain's binary_logloss: 0.487333\n",
      "[8]\ttrain's binary_logloss: 0.473403\n",
      "[9]\ttrain's binary_logloss: 0.459756\n",
      "[10]\ttrain's binary_logloss: 0.447863\n",
      "[11]\ttrain's binary_logloss: 0.437382\n",
      "[12]\ttrain's binary_logloss: 0.42888\n",
      "[13]\ttrain's binary_logloss: 0.420697\n",
      "[14]\ttrain's binary_logloss: 0.413379\n",
      "[15]\ttrain's binary_logloss: 0.407086\n",
      "[16]\ttrain's binary_logloss: 0.400418\n",
      "[17]\ttrain's binary_logloss: 0.394532\n",
      "[18]\ttrain's binary_logloss: 0.389788\n",
      "[19]\ttrain's binary_logloss: 0.384675\n",
      "[20]\ttrain's binary_logloss: 0.380166\n",
      "[21]\ttrain's binary_logloss: 0.375858\n",
      "[22]\ttrain's binary_logloss: 0.371429\n",
      "[23]\ttrain's binary_logloss: 0.367647\n",
      "[24]\ttrain's binary_logloss: 0.362687\n",
      "[25]\ttrain's binary_logloss: 0.358916\n",
      "[26]\ttrain's binary_logloss: 0.3553\n",
      "[27]\ttrain's binary_logloss: 0.351454\n",
      "[28]\ttrain's binary_logloss: 0.347952\n",
      "[29]\ttrain's binary_logloss: 0.344491\n",
      "[30]\ttrain's binary_logloss: 0.341\n",
      "[31]\ttrain's binary_logloss: 0.338273\n",
      "[32]\ttrain's binary_logloss: 0.335374\n",
      "[33]\ttrain's binary_logloss: 0.332966\n",
      "[34]\ttrain's binary_logloss: 0.329758\n",
      "[35]\ttrain's binary_logloss: 0.327267\n",
      "[36]\ttrain's binary_logloss: 0.324796\n",
      "[37]\ttrain's binary_logloss: 0.322593\n",
      "[38]\ttrain's binary_logloss: 0.319497\n",
      "[39]\ttrain's binary_logloss: 0.316936\n",
      "[40]\ttrain's binary_logloss: 0.314706\n",
      "[41]\ttrain's binary_logloss: 0.312041\n",
      "[42]\ttrain's binary_logloss: 0.309377\n",
      "[43]\ttrain's binary_logloss: 0.307265\n",
      "[44]\ttrain's binary_logloss: 0.304797\n",
      "[45]\ttrain's binary_logloss: 0.302932\n",
      "[46]\ttrain's binary_logloss: 0.301226\n",
      "[47]\ttrain's binary_logloss: 0.299184\n",
      "[48]\ttrain's binary_logloss: 0.29694\n",
      "[49]\ttrain's binary_logloss: 0.295391\n",
      "[50]\ttrain's binary_logloss: 0.293026\n",
      "[51]\ttrain's binary_logloss: 0.291295\n",
      "[52]\ttrain's binary_logloss: 0.289817\n",
      "[53]\ttrain's binary_logloss: 0.28778\n",
      "[54]\ttrain's binary_logloss: 0.285807\n",
      "[55]\ttrain's binary_logloss: 0.283796\n",
      "[56]\ttrain's binary_logloss: 0.281902\n",
      "[57]\ttrain's binary_logloss: 0.280353\n",
      "[58]\ttrain's binary_logloss: 0.278133\n",
      "[59]\ttrain's binary_logloss: 0.276636\n",
      "[60]\ttrain's binary_logloss: 0.274882\n",
      "[61]\ttrain's binary_logloss: 0.272477\n",
      "[62]\ttrain's binary_logloss: 0.27115\n",
      "[63]\ttrain's binary_logloss: 0.268909\n",
      "[64]\ttrain's binary_logloss: 0.26711\n",
      "[65]\ttrain's binary_logloss: 0.265627\n",
      "[66]\ttrain's binary_logloss: 0.264103\n",
      "[67]\ttrain's binary_logloss: 0.262114\n",
      "[68]\ttrain's binary_logloss: 0.26011\n",
      "[69]\ttrain's binary_logloss: 0.258665\n",
      "[70]\ttrain's binary_logloss: 0.25738\n",
      "[71]\ttrain's binary_logloss: 0.255726\n",
      "[72]\ttrain's binary_logloss: 0.254223\n",
      "[73]\ttrain's binary_logloss: 0.252303\n",
      "[74]\ttrain's binary_logloss: 0.251051\n",
      "[75]\ttrain's binary_logloss: 0.249495\n",
      "[76]\ttrain's binary_logloss: 0.247928\n",
      "[77]\ttrain's binary_logloss: 0.246865\n",
      "[78]\ttrain's binary_logloss: 0.245542\n",
      "[79]\ttrain's binary_logloss: 0.24408\n",
      "[80]\ttrain's binary_logloss: 0.242746\n",
      "[81]\ttrain's binary_logloss: 0.241516\n",
      "[82]\ttrain's binary_logloss: 0.240294\n",
      "[83]\ttrain's binary_logloss: 0.238656\n",
      "[84]\ttrain's binary_logloss: 0.237595\n",
      "[85]\ttrain's binary_logloss: 0.236696\n",
      "[86]\ttrain's binary_logloss: 0.235792\n",
      "[87]\ttrain's binary_logloss: 0.234593\n",
      "[88]\ttrain's binary_logloss: 0.233253\n",
      "[89]\ttrain's binary_logloss: 0.232353\n",
      "[90]\ttrain's binary_logloss: 0.230887\n",
      "[91]\ttrain's binary_logloss: 0.229588\n",
      "[92]\ttrain's binary_logloss: 0.228103\n",
      "[93]\ttrain's binary_logloss: 0.227024\n",
      "[94]\ttrain's binary_logloss: 0.225505\n",
      "[95]\ttrain's binary_logloss: 0.224624\n",
      "[96]\ttrain's binary_logloss: 0.222889\n",
      "[97]\ttrain's binary_logloss: 0.221902\n",
      "[98]\ttrain's binary_logloss: 0.22063\n",
      "[99]\ttrain's binary_logloss: 0.218838\n",
      "[100]\ttrain's binary_logloss: 0.217476\n",
      "[101]\ttrain's binary_logloss: 0.21629\n",
      "[102]\ttrain's binary_logloss: 0.214851\n",
      "[103]\ttrain's binary_logloss: 0.213776\n",
      "[104]\ttrain's binary_logloss: 0.212298\n",
      "[105]\ttrain's binary_logloss: 0.211099\n",
      "[106]\ttrain's binary_logloss: 0.210155\n",
      "[107]\ttrain's binary_logloss: 0.209238\n",
      "[108]\ttrain's binary_logloss: 0.2083\n",
      "[109]\ttrain's binary_logloss: 0.207146\n",
      "[110]\ttrain's binary_logloss: 0.206077\n",
      "[111]\ttrain's binary_logloss: 0.204606\n",
      "[112]\ttrain's binary_logloss: 0.203562\n",
      "[113]\ttrain's binary_logloss: 0.202641\n",
      "[114]\ttrain's binary_logloss: 0.20154\n",
      "[115]\ttrain's binary_logloss: 0.200288\n",
      "[116]\ttrain's binary_logloss: 0.199032\n",
      "[117]\ttrain's binary_logloss: 0.197964\n",
      "[118]\ttrain's binary_logloss: 0.196656\n",
      "[119]\ttrain's binary_logloss: 0.195804\n",
      "[120]\ttrain's binary_logloss: 0.19452\n",
      "[121]\ttrain's binary_logloss: 0.193742\n",
      "[122]\ttrain's binary_logloss: 0.192721\n",
      "[123]\ttrain's binary_logloss: 0.191777\n",
      "[124]\ttrain's binary_logloss: 0.191043\n",
      "[125]\ttrain's binary_logloss: 0.190235\n",
      "[126]\ttrain's binary_logloss: 0.189519\n",
      "[127]\ttrain's binary_logloss: 0.188461\n",
      "[128]\ttrain's binary_logloss: 0.187743\n",
      "[129]\ttrain's binary_logloss: 0.186209\n",
      "[130]\ttrain's binary_logloss: 0.185589\n",
      "[131]\ttrain's binary_logloss: 0.184918\n",
      "[132]\ttrain's binary_logloss: 0.183813\n",
      "[133]\ttrain's binary_logloss: 0.182655\n",
      "[134]\ttrain's binary_logloss: 0.181989\n",
      "[135]\ttrain's binary_logloss: 0.181103\n",
      "[136]\ttrain's binary_logloss: 0.18046\n",
      "[137]\ttrain's binary_logloss: 0.179155\n",
      "[138]\ttrain's binary_logloss: 0.178649\n",
      "[139]\ttrain's binary_logloss: 0.177763\n",
      "[140]\ttrain's binary_logloss: 0.176758\n",
      "[141]\ttrain's binary_logloss: 0.175398\n",
      "[142]\ttrain's binary_logloss: 0.174555\n",
      "[143]\ttrain's binary_logloss: 0.173431\n",
      "[144]\ttrain's binary_logloss: 0.172795\n",
      "[145]\ttrain's binary_logloss: 0.171829\n",
      "[146]\ttrain's binary_logloss: 0.170794\n",
      "[147]\ttrain's binary_logloss: 0.16996\n",
      "[148]\ttrain's binary_logloss: 0.169299\n",
      "[149]\ttrain's binary_logloss: 0.168474\n",
      "[150]\ttrain's binary_logloss: 0.167255\n",
      "[151]\ttrain's binary_logloss: 0.166508\n",
      "[152]\ttrain's binary_logloss: 0.165976\n",
      "[153]\ttrain's binary_logloss: 0.165176\n",
      "[154]\ttrain's binary_logloss: 0.164243\n",
      "[155]\ttrain's binary_logloss: 0.163129\n",
      "[156]\ttrain's binary_logloss: 0.16261\n",
      "[157]\ttrain's binary_logloss: 0.161583\n",
      "[158]\ttrain's binary_logloss: 0.16081\n",
      "[159]\ttrain's binary_logloss: 0.159906\n",
      "[160]\ttrain's binary_logloss: 0.159349\n",
      "[161]\ttrain's binary_logloss: 0.158649\n",
      "[162]\ttrain's binary_logloss: 0.157701\n",
      "[163]\ttrain's binary_logloss: 0.15675\n",
      "[164]\ttrain's binary_logloss: 0.15578\n",
      "[165]\ttrain's binary_logloss: 0.154765\n",
      "[166]\ttrain's binary_logloss: 0.154205\n",
      "[167]\ttrain's binary_logloss: 0.153335\n",
      "[168]\ttrain's binary_logloss: 0.152659\n",
      "[169]\ttrain's binary_logloss: 0.151726\n",
      "[170]\ttrain's binary_logloss: 0.150959\n",
      "[171]\ttrain's binary_logloss: 0.150255\n",
      "[172]\ttrain's binary_logloss: 0.149312\n",
      "[173]\ttrain's binary_logloss: 0.148715\n",
      "[174]\ttrain's binary_logloss: 0.147935\n",
      "[175]\ttrain's binary_logloss: 0.147207\n",
      "[176]\ttrain's binary_logloss: 0.146467\n",
      "[177]\ttrain's binary_logloss: 0.145747\n",
      "[178]\ttrain's binary_logloss: 0.144968\n",
      "[179]\ttrain's binary_logloss: 0.143976\n",
      "[180]\ttrain's binary_logloss: 0.143349\n",
      "[181]\ttrain's binary_logloss: 0.142777\n",
      "[182]\ttrain's binary_logloss: 0.141895\n",
      "[183]\ttrain's binary_logloss: 0.14117\n",
      "[184]\ttrain's binary_logloss: 0.140235\n",
      "[185]\ttrain's binary_logloss: 0.139442\n",
      "[186]\ttrain's binary_logloss: 0.138812\n",
      "[187]\ttrain's binary_logloss: 0.138275\n",
      "[188]\ttrain's binary_logloss: 0.137689\n",
      "[189]\ttrain's binary_logloss: 0.137015\n",
      "[190]\ttrain's binary_logloss: 0.136435\n",
      "[191]\ttrain's binary_logloss: 0.135791\n",
      "[192]\ttrain's binary_logloss: 0.135149\n",
      "[193]\ttrain's binary_logloss: 0.134353\n",
      "[194]\ttrain's binary_logloss: 0.133886\n",
      "[195]\ttrain's binary_logloss: 0.133157\n",
      "[196]\ttrain's binary_logloss: 0.132694\n",
      "[197]\ttrain's binary_logloss: 0.13204\n",
      "[198]\ttrain's binary_logloss: 0.131377\n",
      "[199]\ttrain's binary_logloss: 0.130818\n",
      "[200]\ttrain's binary_logloss: 0.130261\n",
      "[201]\ttrain's binary_logloss: 0.129614\n",
      "[202]\ttrain's binary_logloss: 0.129119\n",
      "[203]\ttrain's binary_logloss: 0.128704\n",
      "[204]\ttrain's binary_logloss: 0.128289\n",
      "[205]\ttrain's binary_logloss: 0.127834\n",
      "[206]\ttrain's binary_logloss: 0.127428\n",
      "[207]\ttrain's binary_logloss: 0.126912\n",
      "[208]\ttrain's binary_logloss: 0.126199\n",
      "[209]\ttrain's binary_logloss: 0.125629\n",
      "[210]\ttrain's binary_logloss: 0.12503\n",
      "[211]\ttrain's binary_logloss: 0.124452\n",
      "[212]\ttrain's binary_logloss: 0.123912\n",
      "[213]\ttrain's binary_logloss: 0.123397\n",
      "[214]\ttrain's binary_logloss: 0.122826\n",
      "[215]\ttrain's binary_logloss: 0.122334\n",
      "[216]\ttrain's binary_logloss: 0.121682\n",
      "[217]\ttrain's binary_logloss: 0.121058\n",
      "[218]\ttrain's binary_logloss: 0.120728\n",
      "[219]\ttrain's binary_logloss: 0.120108\n",
      "[220]\ttrain's binary_logloss: 0.119467\n",
      "[221]\ttrain's binary_logloss: 0.119047\n",
      "[222]\ttrain's binary_logloss: 0.11837\n",
      "[223]\ttrain's binary_logloss: 0.117889\n",
      "[224]\ttrain's binary_logloss: 0.117508\n",
      "[225]\ttrain's binary_logloss: 0.116907\n",
      "[226]\ttrain's binary_logloss: 0.116397\n",
      "[227]\ttrain's binary_logloss: 0.115744\n",
      "[228]\ttrain's binary_logloss: 0.115241\n",
      "[229]\ttrain's binary_logloss: 0.114706\n",
      "[230]\ttrain's binary_logloss: 0.114348\n",
      "[231]\ttrain's binary_logloss: 0.113906\n",
      "[232]\ttrain's binary_logloss: 0.113534\n",
      "[233]\ttrain's binary_logloss: 0.113161\n",
      "[234]\ttrain's binary_logloss: 0.112658\n",
      "[235]\ttrain's binary_logloss: 0.11218\n",
      "[236]\ttrain's binary_logloss: 0.111752\n",
      "[237]\ttrain's binary_logloss: 0.111266\n",
      "[238]\ttrain's binary_logloss: 0.11082\n",
      "[239]\ttrain's binary_logloss: 0.110329\n",
      "[240]\ttrain's binary_logloss: 0.109861\n",
      "[241]\ttrain's binary_logloss: 0.109598\n",
      "[242]\ttrain's binary_logloss: 0.109082\n",
      "[243]\ttrain's binary_logloss: 0.108708\n",
      "[244]\ttrain's binary_logloss: 0.108284\n",
      "[245]\ttrain's binary_logloss: 0.107735\n",
      "[246]\ttrain's binary_logloss: 0.107267\n",
      "[247]\ttrain's binary_logloss: 0.106863\n",
      "[248]\ttrain's binary_logloss: 0.106298\n",
      "[249]\ttrain's binary_logloss: 0.105944\n",
      "[250]\ttrain's binary_logloss: 0.105679\n",
      "[251]\ttrain's binary_logloss: 0.105136\n",
      "[252]\ttrain's binary_logloss: 0.104807\n",
      "[253]\ttrain's binary_logloss: 0.10451\n",
      "[254]\ttrain's binary_logloss: 0.104076\n",
      "[255]\ttrain's binary_logloss: 0.103735\n",
      "[256]\ttrain's binary_logloss: 0.103418\n",
      "[257]\ttrain's binary_logloss: 0.103173\n",
      "[258]\ttrain's binary_logloss: 0.102829\n",
      "[259]\ttrain's binary_logloss: 0.102462\n",
      "[260]\ttrain's binary_logloss: 0.10204\n",
      "[261]\ttrain's binary_logloss: 0.101655\n",
      "[262]\ttrain's binary_logloss: 0.10139\n",
      "[263]\ttrain's binary_logloss: 0.100887\n",
      "[264]\ttrain's binary_logloss: 0.10056\n",
      "[265]\ttrain's binary_logloss: 0.100219\n",
      "[266]\ttrain's binary_logloss: 0.0998298\n",
      "[267]\ttrain's binary_logloss: 0.0996125\n",
      "[268]\ttrain's binary_logloss: 0.099272\n",
      "[269]\ttrain's binary_logloss: 0.0988129\n",
      "[270]\ttrain's binary_logloss: 0.0984263\n",
      "[271]\ttrain's binary_logloss: 0.0980475\n",
      "[272]\ttrain's binary_logloss: 0.0976559\n",
      "[273]\ttrain's binary_logloss: 0.0971706\n",
      "[274]\ttrain's binary_logloss: 0.0966521\n",
      "[275]\ttrain's binary_logloss: 0.0962974\n",
      "[276]\ttrain's binary_logloss: 0.0959101\n",
      "[277]\ttrain's binary_logloss: 0.0955168\n",
      "[278]\ttrain's binary_logloss: 0.09525\n",
      "[279]\ttrain's binary_logloss: 0.0949607\n",
      "[280]\ttrain's binary_logloss: 0.0945074\n",
      "[281]\ttrain's binary_logloss: 0.0942575\n",
      "[282]\ttrain's binary_logloss: 0.0940096\n",
      "[283]\ttrain's binary_logloss: 0.093557\n",
      "[284]\ttrain's binary_logloss: 0.093279\n",
      "[285]\ttrain's binary_logloss: 0.0929881\n",
      "[286]\ttrain's binary_logloss: 0.0925315\n",
      "[287]\ttrain's binary_logloss: 0.0922306\n",
      "[288]\ttrain's binary_logloss: 0.0919725\n",
      "[289]\ttrain's binary_logloss: 0.0917172\n",
      "[290]\ttrain's binary_logloss: 0.0912802\n",
      "[291]\ttrain's binary_logloss: 0.0910027\n",
      "[292]\ttrain's binary_logloss: 0.0905927\n",
      "[293]\ttrain's binary_logloss: 0.090328\n",
      "[294]\ttrain's binary_logloss: 0.0899746\n",
      "[295]\ttrain's binary_logloss: 0.0896888\n",
      "[296]\ttrain's binary_logloss: 0.0894817\n",
      "[297]\ttrain's binary_logloss: 0.0891636\n",
      "[298]\ttrain's binary_logloss: 0.0888349\n",
      "[299]\ttrain's binary_logloss: 0.0885953\n",
      "[300]\ttrain's binary_logloss: 0.088236\n",
      "[301]\ttrain's binary_logloss: 0.0879255\n",
      "[302]\ttrain's binary_logloss: 0.0875638\n",
      "[303]\ttrain's binary_logloss: 0.0872464\n",
      "[304]\ttrain's binary_logloss: 0.0869583\n",
      "[305]\ttrain's binary_logloss: 0.0865499\n",
      "[306]\ttrain's binary_logloss: 0.0862575\n",
      "[307]\ttrain's binary_logloss: 0.0859256\n",
      "[308]\ttrain's binary_logloss: 0.0856135\n",
      "[309]\ttrain's binary_logloss: 0.0852874\n",
      "[310]\ttrain's binary_logloss: 0.0849515\n",
      "[311]\ttrain's binary_logloss: 0.0845017\n",
      "[312]\ttrain's binary_logloss: 0.0842184\n",
      "[313]\ttrain's binary_logloss: 0.0838351\n",
      "[314]\ttrain's binary_logloss: 0.083489\n",
      "[315]\ttrain's binary_logloss: 0.0832336\n",
      "[316]\ttrain's binary_logloss: 0.0829025\n",
      "[317]\ttrain's binary_logloss: 0.0826862\n",
      "[318]\ttrain's binary_logloss: 0.0824436\n",
      "[319]\ttrain's binary_logloss: 0.0821922\n",
      "[320]\ttrain's binary_logloss: 0.0820017\n",
      "[321]\ttrain's binary_logloss: 0.0816868\n",
      "[322]\ttrain's binary_logloss: 0.0814244\n",
      "[323]\ttrain's binary_logloss: 0.0811457\n",
      "[324]\ttrain's binary_logloss: 0.0809554\n",
      "[325]\ttrain's binary_logloss: 0.0806175\n",
      "[326]\ttrain's binary_logloss: 0.080361\n",
      "[327]\ttrain's binary_logloss: 0.0799872\n",
      "[328]\ttrain's binary_logloss: 0.0796845\n",
      "[329]\ttrain's binary_logloss: 0.0794718\n",
      "[330]\ttrain's binary_logloss: 0.0791083\n",
      "[331]\ttrain's binary_logloss: 0.0789311\n",
      "[332]\ttrain's binary_logloss: 0.0787092\n",
      "[333]\ttrain's binary_logloss: 0.0784438\n",
      "[334]\ttrain's binary_logloss: 0.0782098\n",
      "[335]\ttrain's binary_logloss: 0.0778961\n",
      "[336]\ttrain's binary_logloss: 0.077684\n",
      "[337]\ttrain's binary_logloss: 0.0773722\n",
      "[338]\ttrain's binary_logloss: 0.0768648\n",
      "[339]\ttrain's binary_logloss: 0.0765069\n",
      "[340]\ttrain's binary_logloss: 0.0763368\n",
      "[341]\ttrain's binary_logloss: 0.0760971\n",
      "[342]\ttrain's binary_logloss: 0.075822\n",
      "[343]\ttrain's binary_logloss: 0.0755802\n",
      "[344]\ttrain's binary_logloss: 0.0752465\n",
      "[345]\ttrain's binary_logloss: 0.0749274\n",
      "[346]\ttrain's binary_logloss: 0.0746732\n",
      "[347]\ttrain's binary_logloss: 0.0742712\n",
      "[348]\ttrain's binary_logloss: 0.0739543\n",
      "[349]\ttrain's binary_logloss: 0.0736926\n",
      "[350]\ttrain's binary_logloss: 0.0734034\n",
      "[351]\ttrain's binary_logloss: 0.0731881\n",
      "[352]\ttrain's binary_logloss: 0.0729633\n",
      "[353]\ttrain's binary_logloss: 0.0727896\n",
      "[354]\ttrain's binary_logloss: 0.072562\n",
      "[355]\ttrain's binary_logloss: 0.0723966\n",
      "[356]\ttrain's binary_logloss: 0.0722166\n",
      "[357]\ttrain's binary_logloss: 0.0720762\n",
      "[358]\ttrain's binary_logloss: 0.0718436\n",
      "[359]\ttrain's binary_logloss: 0.0715495\n",
      "[360]\ttrain's binary_logloss: 0.0712312\n",
      "[361]\ttrain's binary_logloss: 0.0709383\n",
      "[362]\ttrain's binary_logloss: 0.0706654\n",
      "[363]\ttrain's binary_logloss: 0.0704478\n",
      "[364]\ttrain's binary_logloss: 0.0701822\n",
      "[365]\ttrain's binary_logloss: 0.0698736\n",
      "[366]\ttrain's binary_logloss: 0.0696692\n",
      "[367]\ttrain's binary_logloss: 0.0694489\n",
      "[368]\ttrain's binary_logloss: 0.0692292\n",
      "[369]\ttrain's binary_logloss: 0.0689507\n",
      "[370]\ttrain's binary_logloss: 0.0686758\n",
      "[371]\ttrain's binary_logloss: 0.068452\n",
      "[372]\ttrain's binary_logloss: 0.0683111\n",
      "[373]\ttrain's binary_logloss: 0.0681434\n",
      "[374]\ttrain's binary_logloss: 0.0679451\n",
      "[375]\ttrain's binary_logloss: 0.0678024\n",
      "[376]\ttrain's binary_logloss: 0.0676655\n",
      "[377]\ttrain's binary_logloss: 0.0675469\n",
      "[378]\ttrain's binary_logloss: 0.0673618\n",
      "[379]\ttrain's binary_logloss: 0.0670873\n",
      "[380]\ttrain's binary_logloss: 0.0668862\n",
      "[381]\ttrain's binary_logloss: 0.0666353\n",
      "[382]\ttrain's binary_logloss: 0.0664688\n",
      "[383]\ttrain's binary_logloss: 0.06623\n",
      "[384]\ttrain's binary_logloss: 0.0660523\n",
      "[385]\ttrain's binary_logloss: 0.0658824\n",
      "[386]\ttrain's binary_logloss: 0.0657147\n",
      "[387]\ttrain's binary_logloss: 0.0654769\n",
      "[388]\ttrain's binary_logloss: 0.065332\n",
      "[389]\ttrain's binary_logloss: 0.0649566\n",
      "[390]\ttrain's binary_logloss: 0.0647142\n",
      "[391]\ttrain's binary_logloss: 0.0645946\n",
      "[392]\ttrain's binary_logloss: 0.0644482\n",
      "[393]\ttrain's binary_logloss: 0.0642709\n",
      "[394]\ttrain's binary_logloss: 0.0641023\n",
      "[395]\ttrain's binary_logloss: 0.0638893\n",
      "[396]\ttrain's binary_logloss: 0.0636629\n",
      "[397]\ttrain's binary_logloss: 0.0635351\n",
      "[398]\ttrain's binary_logloss: 0.0633455\n",
      "[399]\ttrain's binary_logloss: 0.0630941\n",
      "[400]\ttrain's binary_logloss: 0.0629091\n",
      "[401]\ttrain's binary_logloss: 0.0626924\n",
      "[402]\ttrain's binary_logloss: 0.0625167\n",
      "[403]\ttrain's binary_logloss: 0.0622561\n",
      "[404]\ttrain's binary_logloss: 0.0619753\n",
      "[405]\ttrain's binary_logloss: 0.0618633\n",
      "[406]\ttrain's binary_logloss: 0.0617229\n",
      "[407]\ttrain's binary_logloss: 0.0615427\n",
      "[408]\ttrain's binary_logloss: 0.0612426\n",
      "[409]\ttrain's binary_logloss: 0.0610159\n",
      "[410]\ttrain's binary_logloss: 0.0608265\n",
      "[411]\ttrain's binary_logloss: 0.0606313\n",
      "[412]\ttrain's binary_logloss: 0.0604568\n",
      "[413]\ttrain's binary_logloss: 0.0603012\n",
      "[414]\ttrain's binary_logloss: 0.0601036\n",
      "[415]\ttrain's binary_logloss: 0.0599016\n",
      "[416]\ttrain's binary_logloss: 0.0597181\n",
      "[417]\ttrain's binary_logloss: 0.0595756\n",
      "[418]\ttrain's binary_logloss: 0.0594021\n",
      "[419]\ttrain's binary_logloss: 0.0592228\n",
      "[420]\ttrain's binary_logloss: 0.0590974\n",
      "[421]\ttrain's binary_logloss: 0.0589592\n",
      "[422]\ttrain's binary_logloss: 0.0587928\n",
      "[423]\ttrain's binary_logloss: 0.0585746\n",
      "[424]\ttrain's binary_logloss: 0.0584008\n",
      "[425]\ttrain's binary_logloss: 0.0581982\n",
      "[426]\ttrain's binary_logloss: 0.0579921\n",
      "[427]\ttrain's binary_logloss: 0.0578342\n",
      "[428]\ttrain's binary_logloss: 0.0577103\n",
      "[429]\ttrain's binary_logloss: 0.0575945\n",
      "[430]\ttrain's binary_logloss: 0.0573897\n",
      "[431]\ttrain's binary_logloss: 0.0572105\n",
      "[432]\ttrain's binary_logloss: 0.0570479\n",
      "[433]\ttrain's binary_logloss: 0.0567783\n",
      "[434]\ttrain's binary_logloss: 0.0566714\n",
      "[435]\ttrain's binary_logloss: 0.0565666\n",
      "[436]\ttrain's binary_logloss: 0.0563979\n",
      "[437]\ttrain's binary_logloss: 0.056224\n",
      "[438]\ttrain's binary_logloss: 0.0560582\n",
      "[439]\ttrain's binary_logloss: 0.0559133\n",
      "[440]\ttrain's binary_logloss: 0.0557307\n",
      "[441]\ttrain's binary_logloss: 0.055639\n",
      "[442]\ttrain's binary_logloss: 0.0554478\n",
      "[443]\ttrain's binary_logloss: 0.0553049\n",
      "[444]\ttrain's binary_logloss: 0.0551379\n",
      "[445]\ttrain's binary_logloss: 0.0549936\n",
      "[446]\ttrain's binary_logloss: 0.0548406\n",
      "[447]\ttrain's binary_logloss: 0.0546784\n",
      "[448]\ttrain's binary_logloss: 0.0545747\n",
      "[449]\ttrain's binary_logloss: 0.0544377\n",
      "[450]\ttrain's binary_logloss: 0.054326\n",
      "[451]\ttrain's binary_logloss: 0.0541696\n",
      "[452]\ttrain's binary_logloss: 0.0540874\n",
      "[453]\ttrain's binary_logloss: 0.0539605\n",
      "[454]\ttrain's binary_logloss: 0.0538119\n",
      "[455]\ttrain's binary_logloss: 0.0536672\n",
      "[456]\ttrain's binary_logloss: 0.0535799\n",
      "[457]\ttrain's binary_logloss: 0.0533833\n",
      "[458]\ttrain's binary_logloss: 0.0532557\n",
      "[459]\ttrain's binary_logloss: 0.0531591\n",
      "[460]\ttrain's binary_logloss: 0.0529716\n",
      "[461]\ttrain's binary_logloss: 0.0528433\n",
      "[462]\ttrain's binary_logloss: 0.0527358\n",
      "[463]\ttrain's binary_logloss: 0.0526425\n",
      "[464]\ttrain's binary_logloss: 0.0524576\n",
      "[465]\ttrain's binary_logloss: 0.0523841\n",
      "[466]\ttrain's binary_logloss: 0.0522507\n",
      "[467]\ttrain's binary_logloss: 0.0521395\n",
      "[468]\ttrain's binary_logloss: 0.051896\n",
      "[469]\ttrain's binary_logloss: 0.0517641\n",
      "[470]\ttrain's binary_logloss: 0.0516128\n",
      "[471]\ttrain's binary_logloss: 0.0514234\n",
      "[472]\ttrain's binary_logloss: 0.0512009\n",
      "[473]\ttrain's binary_logloss: 0.0510577\n",
      "[474]\ttrain's binary_logloss: 0.0509314\n",
      "[475]\ttrain's binary_logloss: 0.0507913\n",
      "[476]\ttrain's binary_logloss: 0.0507249\n",
      "[477]\ttrain's binary_logloss: 0.0505905\n",
      "[478]\ttrain's binary_logloss: 0.0504886\n",
      "[479]\ttrain's binary_logloss: 0.0503968\n",
      "[480]\ttrain's binary_logloss: 0.0501881\n",
      "[481]\ttrain's binary_logloss: 0.0500122\n",
      "[482]\ttrain's binary_logloss: 0.0497888\n",
      "[483]\ttrain's binary_logloss: 0.0496567\n",
      "[484]\ttrain's binary_logloss: 0.0495297\n",
      "[485]\ttrain's binary_logloss: 0.0493861\n",
      "[486]\ttrain's binary_logloss: 0.0492679\n",
      "[487]\ttrain's binary_logloss: 0.0491456\n",
      "[488]\ttrain's binary_logloss: 0.048953\n",
      "[489]\ttrain's binary_logloss: 0.0488285\n",
      "[490]\ttrain's binary_logloss: 0.0486891\n",
      "[491]\ttrain's binary_logloss: 0.0486347\n",
      "[492]\ttrain's binary_logloss: 0.0485155\n",
      "[493]\ttrain's binary_logloss: 0.0482789\n",
      "[494]\ttrain's binary_logloss: 0.0481425\n",
      "[495]\ttrain's binary_logloss: 0.047983\n",
      "[496]\ttrain's binary_logloss: 0.0478556\n",
      "[497]\ttrain's binary_logloss: 0.0476813\n",
      "[498]\ttrain's binary_logloss: 0.0475647\n",
      "[499]\ttrain's binary_logloss: 0.0475025\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "[0]\ttest-logloss:0.48809\n",
      "[1]\ttest-logloss:0.44679\n",
      "[2]\ttest-logloss:0.42412\n",
      "[3]\ttest-logloss:0.44016\n",
      "[4]\ttest-logloss:0.44331\n",
      "[5]\ttest-logloss:0.44183\n",
      "[6]\ttest-logloss:0.46534\n",
      "[7]\ttest-logloss:0.46678\n",
      "[8]\ttest-logloss:0.47348\n",
      "[9]\ttest-logloss:0.46493\n",
      "[10]\ttest-logloss:0.46420\n",
      "[11]\ttest-logloss:0.45894\n",
      "[12]\ttest-logloss:0.46860\n",
      "[13]\ttest-logloss:0.46470\n",
      "[14]\ttest-logloss:0.45878\n",
      "[15]\ttest-logloss:0.45910\n",
      "[16]\ttest-logloss:0.46146\n",
      "[17]\ttest-logloss:0.47669\n",
      "[18]\ttest-logloss:0.47311\n",
      "[19]\ttest-logloss:0.47043\n",
      "[20]\ttest-logloss:0.48647\n",
      "[21]\ttest-logloss:0.48392\n",
      "[22]\ttest-logloss:0.49170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trainの形状： (646, 43)  y_trainの形状： (646,)  X_testの形状： (278, 43)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.645979\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.607469\n",
      "[3]\ttrain's binary_logloss: 0.575587\n",
      "[4]\ttrain's binary_logloss: 0.54889\n",
      "[5]\ttrain's binary_logloss: 0.524775\n",
      "[6]\ttrain's binary_logloss: 0.505158\n",
      "[7]\ttrain's binary_logloss: 0.487333\n",
      "[8]\ttrain's binary_logloss: 0.473403\n",
      "[9]\ttrain's binary_logloss: 0.459756\n",
      "[10]\ttrain's binary_logloss: 0.447863\n",
      "[11]\ttrain's binary_logloss: 0.437382\n",
      "[12]\ttrain's binary_logloss: 0.42888\n",
      "[13]\ttrain's binary_logloss: 0.420697\n",
      "[14]\ttrain's binary_logloss: 0.413379\n",
      "[15]\ttrain's binary_logloss: 0.407086\n",
      "[16]\ttrain's binary_logloss: 0.400418\n",
      "[17]\ttrain's binary_logloss: 0.394532\n",
      "[18]\ttrain's binary_logloss: 0.389788\n",
      "[19]\ttrain's binary_logloss: 0.384675\n",
      "[20]\ttrain's binary_logloss: 0.380166\n",
      "[21]\ttrain's binary_logloss: 0.375858\n",
      "[22]\ttrain's binary_logloss: 0.371429\n",
      "[23]\ttrain's binary_logloss: 0.367647\n",
      "[24]\ttrain's binary_logloss: 0.362687\n",
      "[25]\ttrain's binary_logloss: 0.358916\n",
      "[26]\ttrain's binary_logloss: 0.3553\n",
      "[27]\ttrain's binary_logloss: 0.351454\n",
      "[28]\ttrain's binary_logloss: 0.347952\n",
      "[29]\ttrain's binary_logloss: 0.344491\n",
      "[30]\ttrain's binary_logloss: 0.341\n",
      "[31]\ttrain's binary_logloss: 0.338273\n",
      "[32]\ttrain's binary_logloss: 0.335374\n",
      "[33]\ttrain's binary_logloss: 0.332966\n",
      "[34]\ttrain's binary_logloss: 0.329758\n",
      "[35]\ttrain's binary_logloss: 0.327267\n",
      "[36]\ttrain's binary_logloss: 0.324796\n",
      "[37]\ttrain's binary_logloss: 0.322593\n",
      "[38]\ttrain's binary_logloss: 0.319497\n",
      "[39]\ttrain's binary_logloss: 0.316936\n",
      "[40]\ttrain's binary_logloss: 0.314706\n",
      "[41]\ttrain's binary_logloss: 0.312041\n",
      "[42]\ttrain's binary_logloss: 0.309377\n",
      "[43]\ttrain's binary_logloss: 0.307265\n",
      "[44]\ttrain's binary_logloss: 0.304797\n",
      "[45]\ttrain's binary_logloss: 0.302932\n",
      "[46]\ttrain's binary_logloss: 0.301226\n",
      "[47]\ttrain's binary_logloss: 0.299184\n",
      "[48]\ttrain's binary_logloss: 0.29694\n",
      "[49]\ttrain's binary_logloss: 0.295391\n",
      "[50]\ttrain's binary_logloss: 0.293026\n",
      "[51]\ttrain's binary_logloss: 0.291295\n",
      "[52]\ttrain's binary_logloss: 0.289817\n",
      "[53]\ttrain's binary_logloss: 0.28778\n",
      "[54]\ttrain's binary_logloss: 0.285807\n",
      "[55]\ttrain's binary_logloss: 0.283796\n",
      "[56]\ttrain's binary_logloss: 0.281902\n",
      "[57]\ttrain's binary_logloss: 0.280353\n",
      "[58]\ttrain's binary_logloss: 0.278133\n",
      "[59]\ttrain's binary_logloss: 0.276636\n",
      "[60]\ttrain's binary_logloss: 0.274882\n",
      "[61]\ttrain's binary_logloss: 0.272477\n",
      "[62]\ttrain's binary_logloss: 0.27115\n",
      "[63]\ttrain's binary_logloss: 0.268909\n",
      "[64]\ttrain's binary_logloss: 0.26711\n",
      "[65]\ttrain's binary_logloss: 0.265627\n",
      "[66]\ttrain's binary_logloss: 0.264103\n",
      "[67]\ttrain's binary_logloss: 0.262114\n",
      "[68]\ttrain's binary_logloss: 0.26011\n",
      "[69]\ttrain's binary_logloss: 0.258665\n",
      "[70]\ttrain's binary_logloss: 0.25738\n",
      "[71]\ttrain's binary_logloss: 0.255726\n",
      "[72]\ttrain's binary_logloss: 0.254223\n",
      "[73]\ttrain's binary_logloss: 0.252303\n",
      "[74]\ttrain's binary_logloss: 0.251051\n",
      "[75]\ttrain's binary_logloss: 0.249495\n",
      "[76]\ttrain's binary_logloss: 0.247928\n",
      "[77]\ttrain's binary_logloss: 0.246865\n",
      "[78]\ttrain's binary_logloss: 0.245542\n",
      "[79]\ttrain's binary_logloss: 0.24408\n",
      "[80]\ttrain's binary_logloss: 0.242746\n",
      "[81]\ttrain's binary_logloss: 0.241516\n",
      "[82]\ttrain's binary_logloss: 0.240294\n",
      "[83]\ttrain's binary_logloss: 0.238656\n",
      "[84]\ttrain's binary_logloss: 0.237595\n",
      "[85]\ttrain's binary_logloss: 0.236696\n",
      "[86]\ttrain's binary_logloss: 0.235792\n",
      "[87]\ttrain's binary_logloss: 0.234593\n",
      "[88]\ttrain's binary_logloss: 0.233253\n",
      "[89]\ttrain's binary_logloss: 0.232353\n",
      "[90]\ttrain's binary_logloss: 0.230887\n",
      "[91]\ttrain's binary_logloss: 0.229588\n",
      "[92]\ttrain's binary_logloss: 0.228103\n",
      "[93]\ttrain's binary_logloss: 0.227024\n",
      "[94]\ttrain's binary_logloss: 0.225505\n",
      "[95]\ttrain's binary_logloss: 0.224624\n",
      "[96]\ttrain's binary_logloss: 0.222889\n",
      "[97]\ttrain's binary_logloss: 0.221902\n",
      "[98]\ttrain's binary_logloss: 0.22063\n",
      "[99]\ttrain's binary_logloss: 0.218838\n",
      "[100]\ttrain's binary_logloss: 0.217476\n",
      "[101]\ttrain's binary_logloss: 0.21629\n",
      "[102]\ttrain's binary_logloss: 0.214851\n",
      "[103]\ttrain's binary_logloss: 0.213776\n",
      "[104]\ttrain's binary_logloss: 0.212298\n",
      "[105]\ttrain's binary_logloss: 0.211099\n",
      "[106]\ttrain's binary_logloss: 0.210155\n",
      "[107]\ttrain's binary_logloss: 0.209238\n",
      "[108]\ttrain's binary_logloss: 0.2083\n",
      "[109]\ttrain's binary_logloss: 0.207146\n",
      "[110]\ttrain's binary_logloss: 0.206077\n",
      "[111]\ttrain's binary_logloss: 0.204606\n",
      "[112]\ttrain's binary_logloss: 0.203562\n",
      "[113]\ttrain's binary_logloss: 0.202641\n",
      "[114]\ttrain's binary_logloss: 0.20154\n",
      "[115]\ttrain's binary_logloss: 0.200288\n",
      "[116]\ttrain's binary_logloss: 0.199032\n",
      "[117]\ttrain's binary_logloss: 0.197964\n",
      "[118]\ttrain's binary_logloss: 0.196656\n",
      "[119]\ttrain's binary_logloss: 0.195804\n",
      "[120]\ttrain's binary_logloss: 0.19452\n",
      "[121]\ttrain's binary_logloss: 0.193742\n",
      "[122]\ttrain's binary_logloss: 0.192721\n",
      "[123]\ttrain's binary_logloss: 0.191777\n",
      "[124]\ttrain's binary_logloss: 0.191043\n",
      "[125]\ttrain's binary_logloss: 0.190235\n",
      "[126]\ttrain's binary_logloss: 0.189519\n",
      "[127]\ttrain's binary_logloss: 0.188461\n",
      "[128]\ttrain's binary_logloss: 0.187743\n",
      "[129]\ttrain's binary_logloss: 0.186209\n",
      "[130]\ttrain's binary_logloss: 0.185589\n",
      "[131]\ttrain's binary_logloss: 0.184918\n",
      "[132]\ttrain's binary_logloss: 0.183813\n",
      "[133]\ttrain's binary_logloss: 0.182655\n",
      "[134]\ttrain's binary_logloss: 0.181989\n",
      "[135]\ttrain's binary_logloss: 0.181103\n",
      "[136]\ttrain's binary_logloss: 0.18046\n",
      "[137]\ttrain's binary_logloss: 0.179155\n",
      "[138]\ttrain's binary_logloss: 0.178649\n",
      "[139]\ttrain's binary_logloss: 0.177763\n",
      "[140]\ttrain's binary_logloss: 0.176758\n",
      "[141]\ttrain's binary_logloss: 0.175398\n",
      "[142]\ttrain's binary_logloss: 0.174555\n",
      "[143]\ttrain's binary_logloss: 0.173431\n",
      "[144]\ttrain's binary_logloss: 0.172795\n",
      "[145]\ttrain's binary_logloss: 0.171829\n",
      "[146]\ttrain's binary_logloss: 0.170794\n",
      "[147]\ttrain's binary_logloss: 0.16996\n",
      "[148]\ttrain's binary_logloss: 0.169299\n",
      "[149]\ttrain's binary_logloss: 0.168474\n",
      "[150]\ttrain's binary_logloss: 0.167255\n",
      "[151]\ttrain's binary_logloss: 0.166508\n",
      "[152]\ttrain's binary_logloss: 0.165976\n",
      "[153]\ttrain's binary_logloss: 0.165176\n",
      "[154]\ttrain's binary_logloss: 0.164243\n",
      "[155]\ttrain's binary_logloss: 0.163129\n",
      "[156]\ttrain's binary_logloss: 0.16261\n",
      "[157]\ttrain's binary_logloss: 0.161583\n",
      "[158]\ttrain's binary_logloss: 0.16081\n",
      "[159]\ttrain's binary_logloss: 0.159906\n",
      "[160]\ttrain's binary_logloss: 0.159349\n",
      "[161]\ttrain's binary_logloss: 0.158649\n",
      "[162]\ttrain's binary_logloss: 0.157701\n",
      "[163]\ttrain's binary_logloss: 0.15675\n",
      "[164]\ttrain's binary_logloss: 0.15578\n",
      "[165]\ttrain's binary_logloss: 0.154765\n",
      "[166]\ttrain's binary_logloss: 0.154205\n",
      "[167]\ttrain's binary_logloss: 0.153335\n",
      "[168]\ttrain's binary_logloss: 0.152659\n",
      "[169]\ttrain's binary_logloss: 0.151726\n",
      "[170]\ttrain's binary_logloss: 0.150959\n",
      "[171]\ttrain's binary_logloss: 0.150255\n",
      "[172]\ttrain's binary_logloss: 0.149312\n",
      "[173]\ttrain's binary_logloss: 0.148715\n",
      "[174]\ttrain's binary_logloss: 0.147935\n",
      "[175]\ttrain's binary_logloss: 0.147207\n",
      "[176]\ttrain's binary_logloss: 0.146467\n",
      "[177]\ttrain's binary_logloss: 0.145747\n",
      "[178]\ttrain's binary_logloss: 0.144968\n",
      "[179]\ttrain's binary_logloss: 0.143976\n",
      "[180]\ttrain's binary_logloss: 0.143349\n",
      "[181]\ttrain's binary_logloss: 0.142777\n",
      "[182]\ttrain's binary_logloss: 0.141895\n",
      "[183]\ttrain's binary_logloss: 0.14117\n",
      "[184]\ttrain's binary_logloss: 0.140235\n",
      "[185]\ttrain's binary_logloss: 0.139442\n",
      "[186]\ttrain's binary_logloss: 0.138812\n",
      "[187]\ttrain's binary_logloss: 0.138275\n",
      "[188]\ttrain's binary_logloss: 0.137689\n",
      "[189]\ttrain's binary_logloss: 0.137015\n",
      "[190]\ttrain's binary_logloss: 0.136435\n",
      "[191]\ttrain's binary_logloss: 0.135791\n",
      "[192]\ttrain's binary_logloss: 0.135149\n",
      "[193]\ttrain's binary_logloss: 0.134353\n",
      "[194]\ttrain's binary_logloss: 0.133886\n",
      "[195]\ttrain's binary_logloss: 0.133157\n",
      "[196]\ttrain's binary_logloss: 0.132694\n",
      "[197]\ttrain's binary_logloss: 0.13204\n",
      "[198]\ttrain's binary_logloss: 0.131377\n",
      "[199]\ttrain's binary_logloss: 0.130818\n",
      "[200]\ttrain's binary_logloss: 0.130261\n",
      "[201]\ttrain's binary_logloss: 0.129614\n",
      "[202]\ttrain's binary_logloss: 0.129119\n",
      "[203]\ttrain's binary_logloss: 0.128704\n",
      "[204]\ttrain's binary_logloss: 0.128289\n",
      "[205]\ttrain's binary_logloss: 0.127834\n",
      "[206]\ttrain's binary_logloss: 0.127428\n",
      "[207]\ttrain's binary_logloss: 0.126912\n",
      "[208]\ttrain's binary_logloss: 0.126199\n",
      "[209]\ttrain's binary_logloss: 0.125629\n",
      "[210]\ttrain's binary_logloss: 0.12503\n",
      "[211]\ttrain's binary_logloss: 0.124452\n",
      "[212]\ttrain's binary_logloss: 0.123912\n",
      "[213]\ttrain's binary_logloss: 0.123397\n",
      "[214]\ttrain's binary_logloss: 0.122826\n",
      "[215]\ttrain's binary_logloss: 0.122334\n",
      "[216]\ttrain's binary_logloss: 0.121682\n",
      "[217]\ttrain's binary_logloss: 0.121058\n",
      "[218]\ttrain's binary_logloss: 0.120728\n",
      "[219]\ttrain's binary_logloss: 0.120108\n",
      "[220]\ttrain's binary_logloss: 0.119467\n",
      "[221]\ttrain's binary_logloss: 0.119047\n",
      "[222]\ttrain's binary_logloss: 0.11837\n",
      "[223]\ttrain's binary_logloss: 0.117889\n",
      "[224]\ttrain's binary_logloss: 0.117508\n",
      "[225]\ttrain's binary_logloss: 0.116907\n",
      "[226]\ttrain's binary_logloss: 0.116397\n",
      "[227]\ttrain's binary_logloss: 0.115744\n",
      "[228]\ttrain's binary_logloss: 0.115241\n",
      "[229]\ttrain's binary_logloss: 0.114706\n",
      "[230]\ttrain's binary_logloss: 0.114348\n",
      "[231]\ttrain's binary_logloss: 0.113906\n",
      "[232]\ttrain's binary_logloss: 0.113534\n",
      "[233]\ttrain's binary_logloss: 0.113161\n",
      "[234]\ttrain's binary_logloss: 0.112658\n",
      "[235]\ttrain's binary_logloss: 0.11218\n",
      "[236]\ttrain's binary_logloss: 0.111752\n",
      "[237]\ttrain's binary_logloss: 0.111266\n",
      "[238]\ttrain's binary_logloss: 0.11082\n",
      "[239]\ttrain's binary_logloss: 0.110329\n",
      "[240]\ttrain's binary_logloss: 0.109861\n",
      "[241]\ttrain's binary_logloss: 0.109598\n",
      "[242]\ttrain's binary_logloss: 0.109082\n",
      "[243]\ttrain's binary_logloss: 0.108708\n",
      "[244]\ttrain's binary_logloss: 0.108284\n",
      "[245]\ttrain's binary_logloss: 0.107735\n",
      "[246]\ttrain's binary_logloss: 0.107267\n",
      "[247]\ttrain's binary_logloss: 0.106863\n",
      "[248]\ttrain's binary_logloss: 0.106298\n",
      "[249]\ttrain's binary_logloss: 0.105944\n",
      "[250]\ttrain's binary_logloss: 0.105679\n",
      "[251]\ttrain's binary_logloss: 0.105136\n",
      "[252]\ttrain's binary_logloss: 0.104807\n",
      "[253]\ttrain's binary_logloss: 0.10451\n",
      "[254]\ttrain's binary_logloss: 0.104076\n",
      "[255]\ttrain's binary_logloss: 0.103735\n",
      "[256]\ttrain's binary_logloss: 0.103418\n",
      "[257]\ttrain's binary_logloss: 0.103173\n",
      "[258]\ttrain's binary_logloss: 0.102829\n",
      "[259]\ttrain's binary_logloss: 0.102462\n",
      "[260]\ttrain's binary_logloss: 0.10204\n",
      "[261]\ttrain's binary_logloss: 0.101655\n",
      "[262]\ttrain's binary_logloss: 0.10139\n",
      "[263]\ttrain's binary_logloss: 0.100887\n",
      "[264]\ttrain's binary_logloss: 0.10056\n",
      "[265]\ttrain's binary_logloss: 0.100219\n",
      "[266]\ttrain's binary_logloss: 0.0998298\n",
      "[267]\ttrain's binary_logloss: 0.0996125\n",
      "[268]\ttrain's binary_logloss: 0.099272\n",
      "[269]\ttrain's binary_logloss: 0.0988129\n",
      "[270]\ttrain's binary_logloss: 0.0984263\n",
      "[271]\ttrain's binary_logloss: 0.0980475\n",
      "[272]\ttrain's binary_logloss: 0.0976559\n",
      "[273]\ttrain's binary_logloss: 0.0971706\n",
      "[274]\ttrain's binary_logloss: 0.0966521\n",
      "[275]\ttrain's binary_logloss: 0.0962974\n",
      "[276]\ttrain's binary_logloss: 0.0959101\n",
      "[277]\ttrain's binary_logloss: 0.0955168\n",
      "[278]\ttrain's binary_logloss: 0.09525\n",
      "[279]\ttrain's binary_logloss: 0.0949607\n",
      "[280]\ttrain's binary_logloss: 0.0945074\n",
      "[281]\ttrain's binary_logloss: 0.0942575\n",
      "[282]\ttrain's binary_logloss: 0.0940096\n",
      "[283]\ttrain's binary_logloss: 0.093557\n",
      "[284]\ttrain's binary_logloss: 0.093279\n",
      "[285]\ttrain's binary_logloss: 0.0929881\n",
      "[286]\ttrain's binary_logloss: 0.0925315\n",
      "[287]\ttrain's binary_logloss: 0.0922306\n",
      "[288]\ttrain's binary_logloss: 0.0919725\n",
      "[289]\ttrain's binary_logloss: 0.0917172\n",
      "[290]\ttrain's binary_logloss: 0.0912802\n",
      "[291]\ttrain's binary_logloss: 0.0910027\n",
      "[292]\ttrain's binary_logloss: 0.0905927\n",
      "[293]\ttrain's binary_logloss: 0.090328\n",
      "[294]\ttrain's binary_logloss: 0.0899746\n",
      "[295]\ttrain's binary_logloss: 0.0896888\n",
      "[296]\ttrain's binary_logloss: 0.0894817\n",
      "[297]\ttrain's binary_logloss: 0.0891636\n",
      "[298]\ttrain's binary_logloss: 0.0888349\n",
      "[299]\ttrain's binary_logloss: 0.0885953\n",
      "[300]\ttrain's binary_logloss: 0.088236\n",
      "[301]\ttrain's binary_logloss: 0.0879255\n",
      "[302]\ttrain's binary_logloss: 0.0875638\n",
      "[303]\ttrain's binary_logloss: 0.0872464\n",
      "[304]\ttrain's binary_logloss: 0.0869583\n",
      "[305]\ttrain's binary_logloss: 0.0865499\n",
      "[306]\ttrain's binary_logloss: 0.0862575\n",
      "[307]\ttrain's binary_logloss: 0.0859256\n",
      "[308]\ttrain's binary_logloss: 0.0856135\n",
      "[309]\ttrain's binary_logloss: 0.0852874\n",
      "[310]\ttrain's binary_logloss: 0.0849515\n",
      "[311]\ttrain's binary_logloss: 0.0845017\n",
      "[312]\ttrain's binary_logloss: 0.0842184\n",
      "[313]\ttrain's binary_logloss: 0.0838351\n",
      "[314]\ttrain's binary_logloss: 0.083489\n",
      "[315]\ttrain's binary_logloss: 0.0832336\n",
      "[316]\ttrain's binary_logloss: 0.0829025\n",
      "[317]\ttrain's binary_logloss: 0.0826862\n",
      "[318]\ttrain's binary_logloss: 0.0824436\n",
      "[319]\ttrain's binary_logloss: 0.0821922\n",
      "[320]\ttrain's binary_logloss: 0.0820017\n",
      "[321]\ttrain's binary_logloss: 0.0816868\n",
      "[322]\ttrain's binary_logloss: 0.0814244\n",
      "[323]\ttrain's binary_logloss: 0.0811457\n",
      "[324]\ttrain's binary_logloss: 0.0809554\n",
      "[325]\ttrain's binary_logloss: 0.0806175\n",
      "[326]\ttrain's binary_logloss: 0.080361\n",
      "[327]\ttrain's binary_logloss: 0.0799872\n",
      "[328]\ttrain's binary_logloss: 0.0796845\n",
      "[329]\ttrain's binary_logloss: 0.0794718\n",
      "[330]\ttrain's binary_logloss: 0.0791083\n",
      "[331]\ttrain's binary_logloss: 0.0789311\n",
      "[332]\ttrain's binary_logloss: 0.0787092\n",
      "[333]\ttrain's binary_logloss: 0.0784438\n",
      "[334]\ttrain's binary_logloss: 0.0782098\n",
      "[335]\ttrain's binary_logloss: 0.0778961\n",
      "[336]\ttrain's binary_logloss: 0.077684\n",
      "[337]\ttrain's binary_logloss: 0.0773722\n",
      "[338]\ttrain's binary_logloss: 0.0768648\n",
      "[339]\ttrain's binary_logloss: 0.0765069\n",
      "[340]\ttrain's binary_logloss: 0.0763368\n",
      "[341]\ttrain's binary_logloss: 0.0760971\n",
      "[342]\ttrain's binary_logloss: 0.075822\n",
      "[343]\ttrain's binary_logloss: 0.0755802\n",
      "[344]\ttrain's binary_logloss: 0.0752465\n",
      "[345]\ttrain's binary_logloss: 0.0749274\n",
      "[346]\ttrain's binary_logloss: 0.0746732\n",
      "[347]\ttrain's binary_logloss: 0.0742712\n",
      "[348]\ttrain's binary_logloss: 0.0739543\n",
      "[349]\ttrain's binary_logloss: 0.0736926\n",
      "[350]\ttrain's binary_logloss: 0.0734034\n",
      "[351]\ttrain's binary_logloss: 0.0731881\n",
      "[352]\ttrain's binary_logloss: 0.0729633\n",
      "[353]\ttrain's binary_logloss: 0.0727896\n",
      "[354]\ttrain's binary_logloss: 0.072562\n",
      "[355]\ttrain's binary_logloss: 0.0723966\n",
      "[356]\ttrain's binary_logloss: 0.0722166\n",
      "[357]\ttrain's binary_logloss: 0.0720762\n",
      "[358]\ttrain's binary_logloss: 0.0718436\n",
      "[359]\ttrain's binary_logloss: 0.0715495\n",
      "[360]\ttrain's binary_logloss: 0.0712312\n",
      "[361]\ttrain's binary_logloss: 0.0709383\n",
      "[362]\ttrain's binary_logloss: 0.0706654\n",
      "[363]\ttrain's binary_logloss: 0.0704478\n",
      "[364]\ttrain's binary_logloss: 0.0701822\n",
      "[365]\ttrain's binary_logloss: 0.0698736\n",
      "[366]\ttrain's binary_logloss: 0.0696692\n",
      "[367]\ttrain's binary_logloss: 0.0694489\n",
      "[368]\ttrain's binary_logloss: 0.0692292\n",
      "[369]\ttrain's binary_logloss: 0.0689507\n",
      "[370]\ttrain's binary_logloss: 0.0686758\n",
      "[371]\ttrain's binary_logloss: 0.068452\n",
      "[372]\ttrain's binary_logloss: 0.0683111\n",
      "[373]\ttrain's binary_logloss: 0.0681434\n",
      "[374]\ttrain's binary_logloss: 0.0679451\n",
      "[375]\ttrain's binary_logloss: 0.0678024\n",
      "[376]\ttrain's binary_logloss: 0.0676655\n",
      "[377]\ttrain's binary_logloss: 0.0675469\n",
      "[378]\ttrain's binary_logloss: 0.0673618\n",
      "[379]\ttrain's binary_logloss: 0.0670873\n",
      "[380]\ttrain's binary_logloss: 0.0668862\n",
      "[381]\ttrain's binary_logloss: 0.0666353\n",
      "[382]\ttrain's binary_logloss: 0.0664688\n",
      "[383]\ttrain's binary_logloss: 0.06623\n",
      "[384]\ttrain's binary_logloss: 0.0660523\n",
      "[385]\ttrain's binary_logloss: 0.0658824\n",
      "[386]\ttrain's binary_logloss: 0.0657147\n",
      "[387]\ttrain's binary_logloss: 0.0654769\n",
      "[388]\ttrain's binary_logloss: 0.065332\n",
      "[389]\ttrain's binary_logloss: 0.0649566\n",
      "[390]\ttrain's binary_logloss: 0.0647142\n",
      "[391]\ttrain's binary_logloss: 0.0645946\n",
      "[392]\ttrain's binary_logloss: 0.0644482\n",
      "[393]\ttrain's binary_logloss: 0.0642709\n",
      "[394]\ttrain's binary_logloss: 0.0641023\n",
      "[395]\ttrain's binary_logloss: 0.0638893\n",
      "[396]\ttrain's binary_logloss: 0.0636629\n",
      "[397]\ttrain's binary_logloss: 0.0635351\n",
      "[398]\ttrain's binary_logloss: 0.0633455\n",
      "[399]\ttrain's binary_logloss: 0.0630941\n",
      "[400]\ttrain's binary_logloss: 0.0629091\n",
      "[401]\ttrain's binary_logloss: 0.0626924\n",
      "[402]\ttrain's binary_logloss: 0.0625167\n",
      "[403]\ttrain's binary_logloss: 0.0622561\n",
      "[404]\ttrain's binary_logloss: 0.0619753\n",
      "[405]\ttrain's binary_logloss: 0.0618633\n",
      "[406]\ttrain's binary_logloss: 0.0617229\n",
      "[407]\ttrain's binary_logloss: 0.0615427\n",
      "[408]\ttrain's binary_logloss: 0.0612426\n",
      "[409]\ttrain's binary_logloss: 0.0610159\n",
      "[410]\ttrain's binary_logloss: 0.0608265\n",
      "[411]\ttrain's binary_logloss: 0.0606313\n",
      "[412]\ttrain's binary_logloss: 0.0604568\n",
      "[413]\ttrain's binary_logloss: 0.0603012\n",
      "[414]\ttrain's binary_logloss: 0.0601036\n",
      "[415]\ttrain's binary_logloss: 0.0599016\n",
      "[416]\ttrain's binary_logloss: 0.0597181\n",
      "[417]\ttrain's binary_logloss: 0.0595756\n",
      "[418]\ttrain's binary_logloss: 0.0594021\n",
      "[419]\ttrain's binary_logloss: 0.0592228\n",
      "[420]\ttrain's binary_logloss: 0.0590974\n",
      "[421]\ttrain's binary_logloss: 0.0589592\n",
      "[422]\ttrain's binary_logloss: 0.0587928\n",
      "[423]\ttrain's binary_logloss: 0.0585746\n",
      "[424]\ttrain's binary_logloss: 0.0584008\n",
      "[425]\ttrain's binary_logloss: 0.0581982\n",
      "[426]\ttrain's binary_logloss: 0.0579921\n",
      "[427]\ttrain's binary_logloss: 0.0578342\n",
      "[428]\ttrain's binary_logloss: 0.0577103\n",
      "[429]\ttrain's binary_logloss: 0.0575945\n",
      "[430]\ttrain's binary_logloss: 0.0573897\n",
      "[431]\ttrain's binary_logloss: 0.0572105\n",
      "[432]\ttrain's binary_logloss: 0.0570479\n",
      "[433]\ttrain's binary_logloss: 0.0567783\n",
      "[434]\ttrain's binary_logloss: 0.0566714\n",
      "[435]\ttrain's binary_logloss: 0.0565666\n",
      "[436]\ttrain's binary_logloss: 0.0563979\n",
      "[437]\ttrain's binary_logloss: 0.056224\n",
      "[438]\ttrain's binary_logloss: 0.0560582\n",
      "[439]\ttrain's binary_logloss: 0.0559133\n",
      "[440]\ttrain's binary_logloss: 0.0557307\n",
      "[441]\ttrain's binary_logloss: 0.055639\n",
      "[442]\ttrain's binary_logloss: 0.0554478\n",
      "[443]\ttrain's binary_logloss: 0.0553049\n",
      "[444]\ttrain's binary_logloss: 0.0551379\n",
      "[445]\ttrain's binary_logloss: 0.0549936\n",
      "[446]\ttrain's binary_logloss: 0.0548406\n",
      "[447]\ttrain's binary_logloss: 0.0546784\n",
      "[448]\ttrain's binary_logloss: 0.0545747\n",
      "[449]\ttrain's binary_logloss: 0.0544377\n",
      "[450]\ttrain's binary_logloss: 0.054326\n",
      "[451]\ttrain's binary_logloss: 0.0541696\n",
      "[452]\ttrain's binary_logloss: 0.0540874\n",
      "[453]\ttrain's binary_logloss: 0.0539605\n",
      "[454]\ttrain's binary_logloss: 0.0538119\n",
      "[455]\ttrain's binary_logloss: 0.0536672\n",
      "[456]\ttrain's binary_logloss: 0.0535799\n",
      "[457]\ttrain's binary_logloss: 0.0533833\n",
      "[458]\ttrain's binary_logloss: 0.0532557\n",
      "[459]\ttrain's binary_logloss: 0.0531591\n",
      "[460]\ttrain's binary_logloss: 0.0529716\n",
      "[461]\ttrain's binary_logloss: 0.0528433\n",
      "[462]\ttrain's binary_logloss: 0.0527358\n",
      "[463]\ttrain's binary_logloss: 0.0526425\n",
      "[464]\ttrain's binary_logloss: 0.0524576\n",
      "[465]\ttrain's binary_logloss: 0.0523841\n",
      "[466]\ttrain's binary_logloss: 0.0522507\n",
      "[467]\ttrain's binary_logloss: 0.0521395\n",
      "[468]\ttrain's binary_logloss: 0.051896\n",
      "[469]\ttrain's binary_logloss: 0.0517641\n",
      "[470]\ttrain's binary_logloss: 0.0516128\n",
      "[471]\ttrain's binary_logloss: 0.0514234\n",
      "[472]\ttrain's binary_logloss: 0.0512009\n",
      "[473]\ttrain's binary_logloss: 0.0510577\n",
      "[474]\ttrain's binary_logloss: 0.0509314\n",
      "[475]\ttrain's binary_logloss: 0.0507913\n",
      "[476]\ttrain's binary_logloss: 0.0507249\n",
      "[477]\ttrain's binary_logloss: 0.0505905\n",
      "[478]\ttrain's binary_logloss: 0.0504886\n",
      "[479]\ttrain's binary_logloss: 0.0503968\n",
      "[480]\ttrain's binary_logloss: 0.0501881\n",
      "[481]\ttrain's binary_logloss: 0.0500122\n",
      "[482]\ttrain's binary_logloss: 0.0497888\n",
      "[483]\ttrain's binary_logloss: 0.0496567\n",
      "[484]\ttrain's binary_logloss: 0.0495297\n",
      "[485]\ttrain's binary_logloss: 0.0493861\n",
      "[486]\ttrain's binary_logloss: 0.0492679\n",
      "[487]\ttrain's binary_logloss: 0.0491456\n",
      "[488]\ttrain's binary_logloss: 0.048953\n",
      "[489]\ttrain's binary_logloss: 0.0488285\n",
      "[490]\ttrain's binary_logloss: 0.0486891\n",
      "[491]\ttrain's binary_logloss: 0.0486347\n",
      "[492]\ttrain's binary_logloss: 0.0485155\n",
      "[493]\ttrain's binary_logloss: 0.0482789\n",
      "[494]\ttrain's binary_logloss: 0.0481425\n",
      "[495]\ttrain's binary_logloss: 0.047983\n",
      "[496]\ttrain's binary_logloss: 0.0478556\n",
      "[497]\ttrain's binary_logloss: 0.0476813\n",
      "[498]\ttrain's binary_logloss: 0.0475647\n",
      "[499]\ttrain's binary_logloss: 0.0475025\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "[0]\ttest-logloss:0.48809\n",
      "[1]\ttest-logloss:0.44679\n",
      "[2]\ttest-logloss:0.42412\n",
      "[3]\ttest-logloss:0.44016\n",
      "[4]\ttest-logloss:0.44331\n",
      "[5]\ttest-logloss:0.44183\n",
      "[6]\ttest-logloss:0.46534\n",
      "[7]\ttest-logloss:0.46678\n",
      "[8]\ttest-logloss:0.47348\n",
      "[9]\ttest-logloss:0.46493\n",
      "[10]\ttest-logloss:0.46420\n",
      "[11]\ttest-logloss:0.45894\n",
      "[12]\ttest-logloss:0.46860\n",
      "[13]\ttest-logloss:0.46470\n",
      "[14]\ttest-logloss:0.45878\n",
      "[15]\ttest-logloss:0.45910\n",
      "[16]\ttest-logloss:0.46146\n",
      "[17]\ttest-logloss:0.47669\n",
      "[18]\ttest-logloss:0.47311\n",
      "[19]\ttest-logloss:0.47043\n",
      "[20]\ttest-logloss:0.48647\n",
      "[21]\ttest-logloss:0.48392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trainの形状： (646, 43)  y_trainの形状： (646,)  X_testの形状： (278, 43)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.645979\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.607469\n",
      "[3]\ttrain's binary_logloss: 0.575587\n",
      "[4]\ttrain's binary_logloss: 0.54889\n",
      "[5]\ttrain's binary_logloss: 0.524775\n",
      "[6]\ttrain's binary_logloss: 0.505158\n",
      "[7]\ttrain's binary_logloss: 0.487333\n",
      "[8]\ttrain's binary_logloss: 0.473403\n",
      "[9]\ttrain's binary_logloss: 0.459756\n",
      "[10]\ttrain's binary_logloss: 0.447863\n",
      "[11]\ttrain's binary_logloss: 0.437382\n",
      "[12]\ttrain's binary_logloss: 0.42888\n",
      "[13]\ttrain's binary_logloss: 0.420697\n",
      "[14]\ttrain's binary_logloss: 0.413379\n",
      "[15]\ttrain's binary_logloss: 0.407086\n",
      "[16]\ttrain's binary_logloss: 0.400418\n",
      "[17]\ttrain's binary_logloss: 0.394532\n",
      "[18]\ttrain's binary_logloss: 0.389788\n",
      "[19]\ttrain's binary_logloss: 0.384675\n",
      "[20]\ttrain's binary_logloss: 0.380166\n",
      "[21]\ttrain's binary_logloss: 0.375858\n",
      "[22]\ttrain's binary_logloss: 0.371429\n",
      "[23]\ttrain's binary_logloss: 0.367647\n",
      "[24]\ttrain's binary_logloss: 0.362687\n",
      "[25]\ttrain's binary_logloss: 0.358916\n",
      "[26]\ttrain's binary_logloss: 0.3553\n",
      "[27]\ttrain's binary_logloss: 0.351454\n",
      "[28]\ttrain's binary_logloss: 0.347952\n",
      "[29]\ttrain's binary_logloss: 0.344491\n",
      "[30]\ttrain's binary_logloss: 0.341\n",
      "[31]\ttrain's binary_logloss: 0.338273\n",
      "[32]\ttrain's binary_logloss: 0.335374\n",
      "[33]\ttrain's binary_logloss: 0.332966\n",
      "[34]\ttrain's binary_logloss: 0.329758\n",
      "[35]\ttrain's binary_logloss: 0.327267\n",
      "[36]\ttrain's binary_logloss: 0.324796\n",
      "[37]\ttrain's binary_logloss: 0.322593\n",
      "[38]\ttrain's binary_logloss: 0.319497\n",
      "[39]\ttrain's binary_logloss: 0.316936\n",
      "[40]\ttrain's binary_logloss: 0.314706\n",
      "[41]\ttrain's binary_logloss: 0.312041\n",
      "[42]\ttrain's binary_logloss: 0.309377\n",
      "[43]\ttrain's binary_logloss: 0.307265\n",
      "[44]\ttrain's binary_logloss: 0.304797\n",
      "[45]\ttrain's binary_logloss: 0.302932\n",
      "[46]\ttrain's binary_logloss: 0.301226\n",
      "[47]\ttrain's binary_logloss: 0.299184\n",
      "[48]\ttrain's binary_logloss: 0.29694\n",
      "[49]\ttrain's binary_logloss: 0.295391\n",
      "[50]\ttrain's binary_logloss: 0.293026\n",
      "[51]\ttrain's binary_logloss: 0.291295\n",
      "[52]\ttrain's binary_logloss: 0.289817\n",
      "[53]\ttrain's binary_logloss: 0.28778\n",
      "[54]\ttrain's binary_logloss: 0.285807\n",
      "[55]\ttrain's binary_logloss: 0.283796\n",
      "[56]\ttrain's binary_logloss: 0.281902\n",
      "[57]\ttrain's binary_logloss: 0.280353\n",
      "[58]\ttrain's binary_logloss: 0.278133\n",
      "[59]\ttrain's binary_logloss: 0.276636\n",
      "[60]\ttrain's binary_logloss: 0.274882\n",
      "[61]\ttrain's binary_logloss: 0.272477\n",
      "[62]\ttrain's binary_logloss: 0.27115\n",
      "[63]\ttrain's binary_logloss: 0.268909\n",
      "[64]\ttrain's binary_logloss: 0.26711\n",
      "[65]\ttrain's binary_logloss: 0.265627\n",
      "[66]\ttrain's binary_logloss: 0.264103\n",
      "[67]\ttrain's binary_logloss: 0.262114\n",
      "[68]\ttrain's binary_logloss: 0.26011\n",
      "[69]\ttrain's binary_logloss: 0.258665\n",
      "[70]\ttrain's binary_logloss: 0.25738\n",
      "[71]\ttrain's binary_logloss: 0.255726\n",
      "[72]\ttrain's binary_logloss: 0.254223\n",
      "[73]\ttrain's binary_logloss: 0.252303\n",
      "[74]\ttrain's binary_logloss: 0.251051\n",
      "[75]\ttrain's binary_logloss: 0.249495\n",
      "[76]\ttrain's binary_logloss: 0.247928\n",
      "[77]\ttrain's binary_logloss: 0.246865\n",
      "[78]\ttrain's binary_logloss: 0.245542\n",
      "[79]\ttrain's binary_logloss: 0.24408\n",
      "[80]\ttrain's binary_logloss: 0.242746\n",
      "[81]\ttrain's binary_logloss: 0.241516\n",
      "[82]\ttrain's binary_logloss: 0.240294\n",
      "[83]\ttrain's binary_logloss: 0.238656\n",
      "[84]\ttrain's binary_logloss: 0.237595\n",
      "[85]\ttrain's binary_logloss: 0.236696\n",
      "[86]\ttrain's binary_logloss: 0.235792\n",
      "[87]\ttrain's binary_logloss: 0.234593\n",
      "[88]\ttrain's binary_logloss: 0.233253\n",
      "[89]\ttrain's binary_logloss: 0.232353\n",
      "[90]\ttrain's binary_logloss: 0.230887\n",
      "[91]\ttrain's binary_logloss: 0.229588\n",
      "[92]\ttrain's binary_logloss: 0.228103\n",
      "[93]\ttrain's binary_logloss: 0.227024\n",
      "[94]\ttrain's binary_logloss: 0.225505\n",
      "[95]\ttrain's binary_logloss: 0.224624\n",
      "[96]\ttrain's binary_logloss: 0.222889\n",
      "[97]\ttrain's binary_logloss: 0.221902\n",
      "[98]\ttrain's binary_logloss: 0.22063\n",
      "[99]\ttrain's binary_logloss: 0.218838\n",
      "[100]\ttrain's binary_logloss: 0.217476\n",
      "[101]\ttrain's binary_logloss: 0.21629\n",
      "[102]\ttrain's binary_logloss: 0.214851\n",
      "[103]\ttrain's binary_logloss: 0.213776\n",
      "[104]\ttrain's binary_logloss: 0.212298\n",
      "[105]\ttrain's binary_logloss: 0.211099\n",
      "[106]\ttrain's binary_logloss: 0.210155\n",
      "[107]\ttrain's binary_logloss: 0.209238\n",
      "[108]\ttrain's binary_logloss: 0.2083\n",
      "[109]\ttrain's binary_logloss: 0.207146\n",
      "[110]\ttrain's binary_logloss: 0.206077\n",
      "[111]\ttrain's binary_logloss: 0.204606\n",
      "[112]\ttrain's binary_logloss: 0.203562\n",
      "[113]\ttrain's binary_logloss: 0.202641\n",
      "[114]\ttrain's binary_logloss: 0.20154\n",
      "[115]\ttrain's binary_logloss: 0.200288\n",
      "[116]\ttrain's binary_logloss: 0.199032\n",
      "[117]\ttrain's binary_logloss: 0.197964\n",
      "[118]\ttrain's binary_logloss: 0.196656\n",
      "[119]\ttrain's binary_logloss: 0.195804\n",
      "[120]\ttrain's binary_logloss: 0.19452\n",
      "[121]\ttrain's binary_logloss: 0.193742\n",
      "[122]\ttrain's binary_logloss: 0.192721\n",
      "[123]\ttrain's binary_logloss: 0.191777\n",
      "[124]\ttrain's binary_logloss: 0.191043\n",
      "[125]\ttrain's binary_logloss: 0.190235\n",
      "[126]\ttrain's binary_logloss: 0.189519\n",
      "[127]\ttrain's binary_logloss: 0.188461\n",
      "[128]\ttrain's binary_logloss: 0.187743\n",
      "[129]\ttrain's binary_logloss: 0.186209\n",
      "[130]\ttrain's binary_logloss: 0.185589\n",
      "[131]\ttrain's binary_logloss: 0.184918\n",
      "[132]\ttrain's binary_logloss: 0.183813\n",
      "[133]\ttrain's binary_logloss: 0.182655\n",
      "[134]\ttrain's binary_logloss: 0.181989\n",
      "[135]\ttrain's binary_logloss: 0.181103\n",
      "[136]\ttrain's binary_logloss: 0.18046\n",
      "[137]\ttrain's binary_logloss: 0.179155\n",
      "[138]\ttrain's binary_logloss: 0.178649\n",
      "[139]\ttrain's binary_logloss: 0.177763\n",
      "[140]\ttrain's binary_logloss: 0.176758\n",
      "[141]\ttrain's binary_logloss: 0.175398\n",
      "[142]\ttrain's binary_logloss: 0.174555\n",
      "[143]\ttrain's binary_logloss: 0.173431\n",
      "[144]\ttrain's binary_logloss: 0.172795\n",
      "[145]\ttrain's binary_logloss: 0.171829\n",
      "[146]\ttrain's binary_logloss: 0.170794\n",
      "[147]\ttrain's binary_logloss: 0.16996\n",
      "[148]\ttrain's binary_logloss: 0.169299\n",
      "[149]\ttrain's binary_logloss: 0.168474\n",
      "[150]\ttrain's binary_logloss: 0.167255\n",
      "[151]\ttrain's binary_logloss: 0.166508\n",
      "[152]\ttrain's binary_logloss: 0.165976\n",
      "[153]\ttrain's binary_logloss: 0.165176\n",
      "[154]\ttrain's binary_logloss: 0.164243\n",
      "[155]\ttrain's binary_logloss: 0.163129\n",
      "[156]\ttrain's binary_logloss: 0.16261\n",
      "[157]\ttrain's binary_logloss: 0.161583\n",
      "[158]\ttrain's binary_logloss: 0.16081\n",
      "[159]\ttrain's binary_logloss: 0.159906\n",
      "[160]\ttrain's binary_logloss: 0.159349\n",
      "[161]\ttrain's binary_logloss: 0.158649\n",
      "[162]\ttrain's binary_logloss: 0.157701\n",
      "[163]\ttrain's binary_logloss: 0.15675\n",
      "[164]\ttrain's binary_logloss: 0.15578\n",
      "[165]\ttrain's binary_logloss: 0.154765\n",
      "[166]\ttrain's binary_logloss: 0.154205\n",
      "[167]\ttrain's binary_logloss: 0.153335\n",
      "[168]\ttrain's binary_logloss: 0.152659\n",
      "[169]\ttrain's binary_logloss: 0.151726\n",
      "[170]\ttrain's binary_logloss: 0.150959\n",
      "[171]\ttrain's binary_logloss: 0.150255\n",
      "[172]\ttrain's binary_logloss: 0.149312\n",
      "[173]\ttrain's binary_logloss: 0.148715\n",
      "[174]\ttrain's binary_logloss: 0.147935\n",
      "[175]\ttrain's binary_logloss: 0.147207\n",
      "[176]\ttrain's binary_logloss: 0.146467\n",
      "[177]\ttrain's binary_logloss: 0.145747\n",
      "[178]\ttrain's binary_logloss: 0.144968\n",
      "[179]\ttrain's binary_logloss: 0.143976\n",
      "[180]\ttrain's binary_logloss: 0.143349\n",
      "[181]\ttrain's binary_logloss: 0.142777\n",
      "[182]\ttrain's binary_logloss: 0.141895\n",
      "[183]\ttrain's binary_logloss: 0.14117\n",
      "[184]\ttrain's binary_logloss: 0.140235\n",
      "[185]\ttrain's binary_logloss: 0.139442\n",
      "[186]\ttrain's binary_logloss: 0.138812\n",
      "[187]\ttrain's binary_logloss: 0.138275\n",
      "[188]\ttrain's binary_logloss: 0.137689\n",
      "[189]\ttrain's binary_logloss: 0.137015\n",
      "[190]\ttrain's binary_logloss: 0.136435\n",
      "[191]\ttrain's binary_logloss: 0.135791\n",
      "[192]\ttrain's binary_logloss: 0.135149\n",
      "[193]\ttrain's binary_logloss: 0.134353\n",
      "[194]\ttrain's binary_logloss: 0.133886\n",
      "[195]\ttrain's binary_logloss: 0.133157\n",
      "[196]\ttrain's binary_logloss: 0.132694\n",
      "[197]\ttrain's binary_logloss: 0.13204\n",
      "[198]\ttrain's binary_logloss: 0.131377\n",
      "[199]\ttrain's binary_logloss: 0.130818\n",
      "[200]\ttrain's binary_logloss: 0.130261\n",
      "[201]\ttrain's binary_logloss: 0.129614\n",
      "[202]\ttrain's binary_logloss: 0.129119\n",
      "[203]\ttrain's binary_logloss: 0.128704\n",
      "[204]\ttrain's binary_logloss: 0.128289\n",
      "[205]\ttrain's binary_logloss: 0.127834\n",
      "[206]\ttrain's binary_logloss: 0.127428\n",
      "[207]\ttrain's binary_logloss: 0.126912\n",
      "[208]\ttrain's binary_logloss: 0.126199\n",
      "[209]\ttrain's binary_logloss: 0.125629\n",
      "[210]\ttrain's binary_logloss: 0.12503\n",
      "[211]\ttrain's binary_logloss: 0.124452\n",
      "[212]\ttrain's binary_logloss: 0.123912\n",
      "[213]\ttrain's binary_logloss: 0.123397\n",
      "[214]\ttrain's binary_logloss: 0.122826\n",
      "[215]\ttrain's binary_logloss: 0.122334\n",
      "[216]\ttrain's binary_logloss: 0.121682\n",
      "[217]\ttrain's binary_logloss: 0.121058\n",
      "[218]\ttrain's binary_logloss: 0.120728\n",
      "[219]\ttrain's binary_logloss: 0.120108\n",
      "[220]\ttrain's binary_logloss: 0.119467\n",
      "[221]\ttrain's binary_logloss: 0.119047\n",
      "[222]\ttrain's binary_logloss: 0.11837\n",
      "[223]\ttrain's binary_logloss: 0.117889\n",
      "[224]\ttrain's binary_logloss: 0.117508\n",
      "[225]\ttrain's binary_logloss: 0.116907\n",
      "[226]\ttrain's binary_logloss: 0.116397\n",
      "[227]\ttrain's binary_logloss: 0.115744\n",
      "[228]\ttrain's binary_logloss: 0.115241\n",
      "[229]\ttrain's binary_logloss: 0.114706\n",
      "[230]\ttrain's binary_logloss: 0.114348\n",
      "[231]\ttrain's binary_logloss: 0.113906\n",
      "[232]\ttrain's binary_logloss: 0.113534\n",
      "[233]\ttrain's binary_logloss: 0.113161\n",
      "[234]\ttrain's binary_logloss: 0.112658\n",
      "[235]\ttrain's binary_logloss: 0.11218\n",
      "[236]\ttrain's binary_logloss: 0.111752\n",
      "[237]\ttrain's binary_logloss: 0.111266\n",
      "[238]\ttrain's binary_logloss: 0.11082\n",
      "[239]\ttrain's binary_logloss: 0.110329\n",
      "[240]\ttrain's binary_logloss: 0.109861\n",
      "[241]\ttrain's binary_logloss: 0.109598\n",
      "[242]\ttrain's binary_logloss: 0.109082\n",
      "[243]\ttrain's binary_logloss: 0.108708\n",
      "[244]\ttrain's binary_logloss: 0.108284\n",
      "[245]\ttrain's binary_logloss: 0.107735\n",
      "[246]\ttrain's binary_logloss: 0.107267\n",
      "[247]\ttrain's binary_logloss: 0.106863\n",
      "[248]\ttrain's binary_logloss: 0.106298\n",
      "[249]\ttrain's binary_logloss: 0.105944\n",
      "[250]\ttrain's binary_logloss: 0.105679\n",
      "[251]\ttrain's binary_logloss: 0.105136\n",
      "[252]\ttrain's binary_logloss: 0.104807\n",
      "[253]\ttrain's binary_logloss: 0.10451\n",
      "[254]\ttrain's binary_logloss: 0.104076\n",
      "[255]\ttrain's binary_logloss: 0.103735\n",
      "[256]\ttrain's binary_logloss: 0.103418\n",
      "[257]\ttrain's binary_logloss: 0.103173\n",
      "[258]\ttrain's binary_logloss: 0.102829\n",
      "[259]\ttrain's binary_logloss: 0.102462\n",
      "[260]\ttrain's binary_logloss: 0.10204\n",
      "[261]\ttrain's binary_logloss: 0.101655\n",
      "[262]\ttrain's binary_logloss: 0.10139\n",
      "[263]\ttrain's binary_logloss: 0.100887\n",
      "[264]\ttrain's binary_logloss: 0.10056\n",
      "[265]\ttrain's binary_logloss: 0.100219\n",
      "[266]\ttrain's binary_logloss: 0.0998298\n",
      "[267]\ttrain's binary_logloss: 0.0996125\n",
      "[268]\ttrain's binary_logloss: 0.099272\n",
      "[269]\ttrain's binary_logloss: 0.0988129\n",
      "[270]\ttrain's binary_logloss: 0.0984263\n",
      "[271]\ttrain's binary_logloss: 0.0980475\n",
      "[272]\ttrain's binary_logloss: 0.0976559\n",
      "[273]\ttrain's binary_logloss: 0.0971706\n",
      "[274]\ttrain's binary_logloss: 0.0966521\n",
      "[275]\ttrain's binary_logloss: 0.0962974\n",
      "[276]\ttrain's binary_logloss: 0.0959101\n",
      "[277]\ttrain's binary_logloss: 0.0955168\n",
      "[278]\ttrain's binary_logloss: 0.09525\n",
      "[279]\ttrain's binary_logloss: 0.0949607\n",
      "[280]\ttrain's binary_logloss: 0.0945074\n",
      "[281]\ttrain's binary_logloss: 0.0942575\n",
      "[282]\ttrain's binary_logloss: 0.0940096\n",
      "[283]\ttrain's binary_logloss: 0.093557\n",
      "[284]\ttrain's binary_logloss: 0.093279\n",
      "[285]\ttrain's binary_logloss: 0.0929881\n",
      "[286]\ttrain's binary_logloss: 0.0925315\n",
      "[287]\ttrain's binary_logloss: 0.0922306\n",
      "[288]\ttrain's binary_logloss: 0.0919725\n",
      "[289]\ttrain's binary_logloss: 0.0917172\n",
      "[290]\ttrain's binary_logloss: 0.0912802\n",
      "[291]\ttrain's binary_logloss: 0.0910027\n",
      "[292]\ttrain's binary_logloss: 0.0905927\n",
      "[293]\ttrain's binary_logloss: 0.090328\n",
      "[294]\ttrain's binary_logloss: 0.0899746\n",
      "[295]\ttrain's binary_logloss: 0.0896888\n",
      "[296]\ttrain's binary_logloss: 0.0894817\n",
      "[297]\ttrain's binary_logloss: 0.0891636\n",
      "[298]\ttrain's binary_logloss: 0.0888349\n",
      "[299]\ttrain's binary_logloss: 0.0885953\n",
      "[300]\ttrain's binary_logloss: 0.088236\n",
      "[301]\ttrain's binary_logloss: 0.0879255\n",
      "[302]\ttrain's binary_logloss: 0.0875638\n",
      "[303]\ttrain's binary_logloss: 0.0872464\n",
      "[304]\ttrain's binary_logloss: 0.0869583\n",
      "[305]\ttrain's binary_logloss: 0.0865499\n",
      "[306]\ttrain's binary_logloss: 0.0862575\n",
      "[307]\ttrain's binary_logloss: 0.0859256\n",
      "[308]\ttrain's binary_logloss: 0.0856135\n",
      "[309]\ttrain's binary_logloss: 0.0852874\n",
      "[310]\ttrain's binary_logloss: 0.0849515\n",
      "[311]\ttrain's binary_logloss: 0.0845017\n",
      "[312]\ttrain's binary_logloss: 0.0842184\n",
      "[313]\ttrain's binary_logloss: 0.0838351\n",
      "[314]\ttrain's binary_logloss: 0.083489\n",
      "[315]\ttrain's binary_logloss: 0.0832336\n",
      "[316]\ttrain's binary_logloss: 0.0829025\n",
      "[317]\ttrain's binary_logloss: 0.0826862\n",
      "[318]\ttrain's binary_logloss: 0.0824436\n",
      "[319]\ttrain's binary_logloss: 0.0821922\n",
      "[320]\ttrain's binary_logloss: 0.0820017\n",
      "[321]\ttrain's binary_logloss: 0.0816868\n",
      "[322]\ttrain's binary_logloss: 0.0814244\n",
      "[323]\ttrain's binary_logloss: 0.0811457\n",
      "[324]\ttrain's binary_logloss: 0.0809554\n",
      "[325]\ttrain's binary_logloss: 0.0806175\n",
      "[326]\ttrain's binary_logloss: 0.080361\n",
      "[327]\ttrain's binary_logloss: 0.0799872\n",
      "[328]\ttrain's binary_logloss: 0.0796845\n",
      "[329]\ttrain's binary_logloss: 0.0794718\n",
      "[330]\ttrain's binary_logloss: 0.0791083\n",
      "[331]\ttrain's binary_logloss: 0.0789311\n",
      "[332]\ttrain's binary_logloss: 0.0787092\n",
      "[333]\ttrain's binary_logloss: 0.0784438\n",
      "[334]\ttrain's binary_logloss: 0.0782098\n",
      "[335]\ttrain's binary_logloss: 0.0778961\n",
      "[336]\ttrain's binary_logloss: 0.077684\n",
      "[337]\ttrain's binary_logloss: 0.0773722\n",
      "[338]\ttrain's binary_logloss: 0.0768648\n",
      "[339]\ttrain's binary_logloss: 0.0765069\n",
      "[340]\ttrain's binary_logloss: 0.0763368\n",
      "[341]\ttrain's binary_logloss: 0.0760971\n",
      "[342]\ttrain's binary_logloss: 0.075822\n",
      "[343]\ttrain's binary_logloss: 0.0755802\n",
      "[344]\ttrain's binary_logloss: 0.0752465\n",
      "[345]\ttrain's binary_logloss: 0.0749274\n",
      "[346]\ttrain's binary_logloss: 0.0746732\n",
      "[347]\ttrain's binary_logloss: 0.0742712\n",
      "[348]\ttrain's binary_logloss: 0.0739543\n",
      "[349]\ttrain's binary_logloss: 0.0736926\n",
      "[350]\ttrain's binary_logloss: 0.0734034\n",
      "[351]\ttrain's binary_logloss: 0.0731881\n",
      "[352]\ttrain's binary_logloss: 0.0729633\n",
      "[353]\ttrain's binary_logloss: 0.0727896\n",
      "[354]\ttrain's binary_logloss: 0.072562\n",
      "[355]\ttrain's binary_logloss: 0.0723966\n",
      "[356]\ttrain's binary_logloss: 0.0722166\n",
      "[357]\ttrain's binary_logloss: 0.0720762\n",
      "[358]\ttrain's binary_logloss: 0.0718436\n",
      "[359]\ttrain's binary_logloss: 0.0715495\n",
      "[360]\ttrain's binary_logloss: 0.0712312\n",
      "[361]\ttrain's binary_logloss: 0.0709383\n",
      "[362]\ttrain's binary_logloss: 0.0706654\n",
      "[363]\ttrain's binary_logloss: 0.0704478\n",
      "[364]\ttrain's binary_logloss: 0.0701822\n",
      "[365]\ttrain's binary_logloss: 0.0698736\n",
      "[366]\ttrain's binary_logloss: 0.0696692\n",
      "[367]\ttrain's binary_logloss: 0.0694489\n",
      "[368]\ttrain's binary_logloss: 0.0692292\n",
      "[369]\ttrain's binary_logloss: 0.0689507\n",
      "[370]\ttrain's binary_logloss: 0.0686758\n",
      "[371]\ttrain's binary_logloss: 0.068452\n",
      "[372]\ttrain's binary_logloss: 0.0683111\n",
      "[373]\ttrain's binary_logloss: 0.0681434\n",
      "[374]\ttrain's binary_logloss: 0.0679451\n",
      "[375]\ttrain's binary_logloss: 0.0678024\n",
      "[376]\ttrain's binary_logloss: 0.0676655\n",
      "[377]\ttrain's binary_logloss: 0.0675469\n",
      "[378]\ttrain's binary_logloss: 0.0673618\n",
      "[379]\ttrain's binary_logloss: 0.0670873\n",
      "[380]\ttrain's binary_logloss: 0.0668862\n",
      "[381]\ttrain's binary_logloss: 0.0666353\n",
      "[382]\ttrain's binary_logloss: 0.0664688\n",
      "[383]\ttrain's binary_logloss: 0.06623\n",
      "[384]\ttrain's binary_logloss: 0.0660523\n",
      "[385]\ttrain's binary_logloss: 0.0658824\n",
      "[386]\ttrain's binary_logloss: 0.0657147\n",
      "[387]\ttrain's binary_logloss: 0.0654769\n",
      "[388]\ttrain's binary_logloss: 0.065332\n",
      "[389]\ttrain's binary_logloss: 0.0649566\n",
      "[390]\ttrain's binary_logloss: 0.0647142\n",
      "[391]\ttrain's binary_logloss: 0.0645946\n",
      "[392]\ttrain's binary_logloss: 0.0644482\n",
      "[393]\ttrain's binary_logloss: 0.0642709\n",
      "[394]\ttrain's binary_logloss: 0.0641023\n",
      "[395]\ttrain's binary_logloss: 0.0638893\n",
      "[396]\ttrain's binary_logloss: 0.0636629\n",
      "[397]\ttrain's binary_logloss: 0.0635351\n",
      "[398]\ttrain's binary_logloss: 0.0633455\n",
      "[399]\ttrain's binary_logloss: 0.0630941\n",
      "[400]\ttrain's binary_logloss: 0.0629091\n",
      "[401]\ttrain's binary_logloss: 0.0626924\n",
      "[402]\ttrain's binary_logloss: 0.0625167\n",
      "[403]\ttrain's binary_logloss: 0.0622561\n",
      "[404]\ttrain's binary_logloss: 0.0619753\n",
      "[405]\ttrain's binary_logloss: 0.0618633\n",
      "[406]\ttrain's binary_logloss: 0.0617229\n",
      "[407]\ttrain's binary_logloss: 0.0615427\n",
      "[408]\ttrain's binary_logloss: 0.0612426\n",
      "[409]\ttrain's binary_logloss: 0.0610159\n",
      "[410]\ttrain's binary_logloss: 0.0608265\n",
      "[411]\ttrain's binary_logloss: 0.0606313\n",
      "[412]\ttrain's binary_logloss: 0.0604568\n",
      "[413]\ttrain's binary_logloss: 0.0603012\n",
      "[414]\ttrain's binary_logloss: 0.0601036\n",
      "[415]\ttrain's binary_logloss: 0.0599016\n",
      "[416]\ttrain's binary_logloss: 0.0597181\n",
      "[417]\ttrain's binary_logloss: 0.0595756\n",
      "[418]\ttrain's binary_logloss: 0.0594021\n",
      "[419]\ttrain's binary_logloss: 0.0592228\n",
      "[420]\ttrain's binary_logloss: 0.0590974\n",
      "[421]\ttrain's binary_logloss: 0.0589592\n",
      "[422]\ttrain's binary_logloss: 0.0587928\n",
      "[423]\ttrain's binary_logloss: 0.0585746\n",
      "[424]\ttrain's binary_logloss: 0.0584008\n",
      "[425]\ttrain's binary_logloss: 0.0581982\n",
      "[426]\ttrain's binary_logloss: 0.0579921\n",
      "[427]\ttrain's binary_logloss: 0.0578342\n",
      "[428]\ttrain's binary_logloss: 0.0577103\n",
      "[429]\ttrain's binary_logloss: 0.0575945\n",
      "[430]\ttrain's binary_logloss: 0.0573897\n",
      "[431]\ttrain's binary_logloss: 0.0572105\n",
      "[432]\ttrain's binary_logloss: 0.0570479\n",
      "[433]\ttrain's binary_logloss: 0.0567783\n",
      "[434]\ttrain's binary_logloss: 0.0566714\n",
      "[435]\ttrain's binary_logloss: 0.0565666\n",
      "[436]\ttrain's binary_logloss: 0.0563979\n",
      "[437]\ttrain's binary_logloss: 0.056224\n",
      "[438]\ttrain's binary_logloss: 0.0560582\n",
      "[439]\ttrain's binary_logloss: 0.0559133\n",
      "[440]\ttrain's binary_logloss: 0.0557307\n",
      "[441]\ttrain's binary_logloss: 0.055639\n",
      "[442]\ttrain's binary_logloss: 0.0554478\n",
      "[443]\ttrain's binary_logloss: 0.0553049\n",
      "[444]\ttrain's binary_logloss: 0.0551379\n",
      "[445]\ttrain's binary_logloss: 0.0549936\n",
      "[446]\ttrain's binary_logloss: 0.0548406\n",
      "[447]\ttrain's binary_logloss: 0.0546784\n",
      "[448]\ttrain's binary_logloss: 0.0545747\n",
      "[449]\ttrain's binary_logloss: 0.0544377\n",
      "[450]\ttrain's binary_logloss: 0.054326\n",
      "[451]\ttrain's binary_logloss: 0.0541696\n",
      "[452]\ttrain's binary_logloss: 0.0540874\n",
      "[453]\ttrain's binary_logloss: 0.0539605\n",
      "[454]\ttrain's binary_logloss: 0.0538119\n",
      "[455]\ttrain's binary_logloss: 0.0536672\n",
      "[456]\ttrain's binary_logloss: 0.0535799\n",
      "[457]\ttrain's binary_logloss: 0.0533833\n",
      "[458]\ttrain's binary_logloss: 0.0532557\n",
      "[459]\ttrain's binary_logloss: 0.0531591\n",
      "[460]\ttrain's binary_logloss: 0.0529716\n",
      "[461]\ttrain's binary_logloss: 0.0528433\n",
      "[462]\ttrain's binary_logloss: 0.0527358\n",
      "[463]\ttrain's binary_logloss: 0.0526425\n",
      "[464]\ttrain's binary_logloss: 0.0524576\n",
      "[465]\ttrain's binary_logloss: 0.0523841\n",
      "[466]\ttrain's binary_logloss: 0.0522507\n",
      "[467]\ttrain's binary_logloss: 0.0521395\n",
      "[468]\ttrain's binary_logloss: 0.051896\n",
      "[469]\ttrain's binary_logloss: 0.0517641\n",
      "[470]\ttrain's binary_logloss: 0.0516128\n",
      "[471]\ttrain's binary_logloss: 0.0514234\n",
      "[472]\ttrain's binary_logloss: 0.0512009\n",
      "[473]\ttrain's binary_logloss: 0.0510577\n",
      "[474]\ttrain's binary_logloss: 0.0509314\n",
      "[475]\ttrain's binary_logloss: 0.0507913\n",
      "[476]\ttrain's binary_logloss: 0.0507249\n",
      "[477]\ttrain's binary_logloss: 0.0505905\n",
      "[478]\ttrain's binary_logloss: 0.0504886\n",
      "[479]\ttrain's binary_logloss: 0.0503968\n",
      "[480]\ttrain's binary_logloss: 0.0501881\n",
      "[481]\ttrain's binary_logloss: 0.0500122\n",
      "[482]\ttrain's binary_logloss: 0.0497888\n",
      "[483]\ttrain's binary_logloss: 0.0496567\n",
      "[484]\ttrain's binary_logloss: 0.0495297\n",
      "[485]\ttrain's binary_logloss: 0.0493861\n",
      "[486]\ttrain's binary_logloss: 0.0492679\n",
      "[487]\ttrain's binary_logloss: 0.0491456\n",
      "[488]\ttrain's binary_logloss: 0.048953\n",
      "[489]\ttrain's binary_logloss: 0.0488285\n",
      "[490]\ttrain's binary_logloss: 0.0486891\n",
      "[491]\ttrain's binary_logloss: 0.0486347\n",
      "[492]\ttrain's binary_logloss: 0.0485155\n",
      "[493]\ttrain's binary_logloss: 0.0482789\n",
      "[494]\ttrain's binary_logloss: 0.0481425\n",
      "[495]\ttrain's binary_logloss: 0.047983\n",
      "[496]\ttrain's binary_logloss: 0.0478556\n",
      "[497]\ttrain's binary_logloss: 0.0476813\n",
      "[498]\ttrain's binary_logloss: 0.0475647\n",
      "[499]\ttrain's binary_logloss: 0.0475025\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "[0]\ttest-logloss:0.48809\n",
      "[1]\ttest-logloss:0.44679\n",
      "[2]\ttest-logloss:0.42412\n",
      "[3]\ttest-logloss:0.44016\n",
      "[4]\ttest-logloss:0.44331\n",
      "[5]\ttest-logloss:0.44183\n",
      "[6]\ttest-logloss:0.46534\n",
      "[7]\ttest-logloss:0.46678\n",
      "[8]\ttest-logloss:0.47348\n",
      "[9]\ttest-logloss:0.46493\n",
      "[10]\ttest-logloss:0.46420\n",
      "[11]\ttest-logloss:0.45894\n",
      "[12]\ttest-logloss:0.46860\n",
      "[13]\ttest-logloss:0.46470\n",
      "[14]\ttest-logloss:0.45878\n",
      "[15]\ttest-logloss:0.45910\n",
      "[16]\ttest-logloss:0.46146\n",
      "[17]\ttest-logloss:0.47669\n",
      "[18]\ttest-logloss:0.47311\n",
      "[19]\ttest-logloss:0.47043\n",
      "[20]\ttest-logloss:0.48647\n",
      "[21]\ttest-logloss:0.48392\n",
      "[22]\ttest-logloss:0.49170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trainの形状： (646, 43)  y_trainの形状： (646,)  X_testの形状： (278, 43)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.645979\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.607469\n",
      "[3]\ttrain's binary_logloss: 0.575587\n",
      "[4]\ttrain's binary_logloss: 0.54889\n",
      "[5]\ttrain's binary_logloss: 0.524775\n",
      "[6]\ttrain's binary_logloss: 0.505158\n",
      "[7]\ttrain's binary_logloss: 0.487333\n",
      "[8]\ttrain's binary_logloss: 0.473403\n",
      "[9]\ttrain's binary_logloss: 0.459756\n",
      "[10]\ttrain's binary_logloss: 0.447863\n",
      "[11]\ttrain's binary_logloss: 0.437382\n",
      "[12]\ttrain's binary_logloss: 0.42888\n",
      "[13]\ttrain's binary_logloss: 0.420697\n",
      "[14]\ttrain's binary_logloss: 0.413379\n",
      "[15]\ttrain's binary_logloss: 0.407086\n",
      "[16]\ttrain's binary_logloss: 0.400418\n",
      "[17]\ttrain's binary_logloss: 0.394532\n",
      "[18]\ttrain's binary_logloss: 0.389788\n",
      "[19]\ttrain's binary_logloss: 0.384675\n",
      "[20]\ttrain's binary_logloss: 0.380166\n",
      "[21]\ttrain's binary_logloss: 0.375858\n",
      "[22]\ttrain's binary_logloss: 0.371429\n",
      "[23]\ttrain's binary_logloss: 0.367647\n",
      "[24]\ttrain's binary_logloss: 0.362687\n",
      "[25]\ttrain's binary_logloss: 0.358916\n",
      "[26]\ttrain's binary_logloss: 0.3553\n",
      "[27]\ttrain's binary_logloss: 0.351454\n",
      "[28]\ttrain's binary_logloss: 0.347952\n",
      "[29]\ttrain's binary_logloss: 0.344491\n",
      "[30]\ttrain's binary_logloss: 0.341\n",
      "[31]\ttrain's binary_logloss: 0.338273\n",
      "[32]\ttrain's binary_logloss: 0.335374\n",
      "[33]\ttrain's binary_logloss: 0.332966\n",
      "[34]\ttrain's binary_logloss: 0.329758\n",
      "[35]\ttrain's binary_logloss: 0.327267\n",
      "[36]\ttrain's binary_logloss: 0.324796\n",
      "[37]\ttrain's binary_logloss: 0.322593\n",
      "[38]\ttrain's binary_logloss: 0.319497\n",
      "[39]\ttrain's binary_logloss: 0.316936\n",
      "[40]\ttrain's binary_logloss: 0.314706\n",
      "[41]\ttrain's binary_logloss: 0.312041\n",
      "[42]\ttrain's binary_logloss: 0.309377\n",
      "[43]\ttrain's binary_logloss: 0.307265\n",
      "[44]\ttrain's binary_logloss: 0.304797\n",
      "[45]\ttrain's binary_logloss: 0.302932\n",
      "[46]\ttrain's binary_logloss: 0.301226\n",
      "[47]\ttrain's binary_logloss: 0.299184\n",
      "[48]\ttrain's binary_logloss: 0.29694\n",
      "[49]\ttrain's binary_logloss: 0.295391\n",
      "[50]\ttrain's binary_logloss: 0.293026\n",
      "[51]\ttrain's binary_logloss: 0.291295\n",
      "[52]\ttrain's binary_logloss: 0.289817\n",
      "[53]\ttrain's binary_logloss: 0.28778\n",
      "[54]\ttrain's binary_logloss: 0.285807\n",
      "[55]\ttrain's binary_logloss: 0.283796\n",
      "[56]\ttrain's binary_logloss: 0.281902\n",
      "[57]\ttrain's binary_logloss: 0.280353\n",
      "[58]\ttrain's binary_logloss: 0.278133\n",
      "[59]\ttrain's binary_logloss: 0.276636\n",
      "[60]\ttrain's binary_logloss: 0.274882\n",
      "[61]\ttrain's binary_logloss: 0.272477\n",
      "[62]\ttrain's binary_logloss: 0.27115\n",
      "[63]\ttrain's binary_logloss: 0.268909\n",
      "[64]\ttrain's binary_logloss: 0.26711\n",
      "[65]\ttrain's binary_logloss: 0.265627\n",
      "[66]\ttrain's binary_logloss: 0.264103\n",
      "[67]\ttrain's binary_logloss: 0.262114\n",
      "[68]\ttrain's binary_logloss: 0.26011\n",
      "[69]\ttrain's binary_logloss: 0.258665\n",
      "[70]\ttrain's binary_logloss: 0.25738\n",
      "[71]\ttrain's binary_logloss: 0.255726\n",
      "[72]\ttrain's binary_logloss: 0.254223\n",
      "[73]\ttrain's binary_logloss: 0.252303\n",
      "[74]\ttrain's binary_logloss: 0.251051\n",
      "[75]\ttrain's binary_logloss: 0.249495\n",
      "[76]\ttrain's binary_logloss: 0.247928\n",
      "[77]\ttrain's binary_logloss: 0.246865\n",
      "[78]\ttrain's binary_logloss: 0.245542\n",
      "[79]\ttrain's binary_logloss: 0.24408\n",
      "[80]\ttrain's binary_logloss: 0.242746\n",
      "[81]\ttrain's binary_logloss: 0.241516\n",
      "[82]\ttrain's binary_logloss: 0.240294\n",
      "[83]\ttrain's binary_logloss: 0.238656\n",
      "[84]\ttrain's binary_logloss: 0.237595\n",
      "[85]\ttrain's binary_logloss: 0.236696\n",
      "[86]\ttrain's binary_logloss: 0.235792\n",
      "[87]\ttrain's binary_logloss: 0.234593\n",
      "[88]\ttrain's binary_logloss: 0.233253\n",
      "[89]\ttrain's binary_logloss: 0.232353\n",
      "[90]\ttrain's binary_logloss: 0.230887\n",
      "[91]\ttrain's binary_logloss: 0.229588\n",
      "[92]\ttrain's binary_logloss: 0.228103\n",
      "[93]\ttrain's binary_logloss: 0.227024\n",
      "[94]\ttrain's binary_logloss: 0.225505\n",
      "[95]\ttrain's binary_logloss: 0.224624\n",
      "[96]\ttrain's binary_logloss: 0.222889\n",
      "[97]\ttrain's binary_logloss: 0.221902\n",
      "[98]\ttrain's binary_logloss: 0.22063\n",
      "[99]\ttrain's binary_logloss: 0.218838\n",
      "[100]\ttrain's binary_logloss: 0.217476\n",
      "[101]\ttrain's binary_logloss: 0.21629\n",
      "[102]\ttrain's binary_logloss: 0.214851\n",
      "[103]\ttrain's binary_logloss: 0.213776\n",
      "[104]\ttrain's binary_logloss: 0.212298\n",
      "[105]\ttrain's binary_logloss: 0.211099\n",
      "[106]\ttrain's binary_logloss: 0.210155\n",
      "[107]\ttrain's binary_logloss: 0.209238\n",
      "[108]\ttrain's binary_logloss: 0.2083\n",
      "[109]\ttrain's binary_logloss: 0.207146\n",
      "[110]\ttrain's binary_logloss: 0.206077\n",
      "[111]\ttrain's binary_logloss: 0.204606\n",
      "[112]\ttrain's binary_logloss: 0.203562\n",
      "[113]\ttrain's binary_logloss: 0.202641\n",
      "[114]\ttrain's binary_logloss: 0.20154\n",
      "[115]\ttrain's binary_logloss: 0.200288\n",
      "[116]\ttrain's binary_logloss: 0.199032\n",
      "[117]\ttrain's binary_logloss: 0.197964\n",
      "[118]\ttrain's binary_logloss: 0.196656\n",
      "[119]\ttrain's binary_logloss: 0.195804\n",
      "[120]\ttrain's binary_logloss: 0.19452\n",
      "[121]\ttrain's binary_logloss: 0.193742\n",
      "[122]\ttrain's binary_logloss: 0.192721\n",
      "[123]\ttrain's binary_logloss: 0.191777\n",
      "[124]\ttrain's binary_logloss: 0.191043\n",
      "[125]\ttrain's binary_logloss: 0.190235\n",
      "[126]\ttrain's binary_logloss: 0.189519\n",
      "[127]\ttrain's binary_logloss: 0.188461\n",
      "[128]\ttrain's binary_logloss: 0.187743\n",
      "[129]\ttrain's binary_logloss: 0.186209\n",
      "[130]\ttrain's binary_logloss: 0.185589\n",
      "[131]\ttrain's binary_logloss: 0.184918\n",
      "[132]\ttrain's binary_logloss: 0.183813\n",
      "[133]\ttrain's binary_logloss: 0.182655\n",
      "[134]\ttrain's binary_logloss: 0.181989\n",
      "[135]\ttrain's binary_logloss: 0.181103\n",
      "[136]\ttrain's binary_logloss: 0.18046\n",
      "[137]\ttrain's binary_logloss: 0.179155\n",
      "[138]\ttrain's binary_logloss: 0.178649\n",
      "[139]\ttrain's binary_logloss: 0.177763\n",
      "[140]\ttrain's binary_logloss: 0.176758\n",
      "[141]\ttrain's binary_logloss: 0.175398\n",
      "[142]\ttrain's binary_logloss: 0.174555\n",
      "[143]\ttrain's binary_logloss: 0.173431\n",
      "[144]\ttrain's binary_logloss: 0.172795\n",
      "[145]\ttrain's binary_logloss: 0.171829\n",
      "[146]\ttrain's binary_logloss: 0.170794\n",
      "[147]\ttrain's binary_logloss: 0.16996\n",
      "[148]\ttrain's binary_logloss: 0.169299\n",
      "[149]\ttrain's binary_logloss: 0.168474\n",
      "[150]\ttrain's binary_logloss: 0.167255\n",
      "[151]\ttrain's binary_logloss: 0.166508\n",
      "[152]\ttrain's binary_logloss: 0.165976\n",
      "[153]\ttrain's binary_logloss: 0.165176\n",
      "[154]\ttrain's binary_logloss: 0.164243\n",
      "[155]\ttrain's binary_logloss: 0.163129\n",
      "[156]\ttrain's binary_logloss: 0.16261\n",
      "[157]\ttrain's binary_logloss: 0.161583\n",
      "[158]\ttrain's binary_logloss: 0.16081\n",
      "[159]\ttrain's binary_logloss: 0.159906\n",
      "[160]\ttrain's binary_logloss: 0.159349\n",
      "[161]\ttrain's binary_logloss: 0.158649\n",
      "[162]\ttrain's binary_logloss: 0.157701\n",
      "[163]\ttrain's binary_logloss: 0.15675\n",
      "[164]\ttrain's binary_logloss: 0.15578\n",
      "[165]\ttrain's binary_logloss: 0.154765\n",
      "[166]\ttrain's binary_logloss: 0.154205\n",
      "[167]\ttrain's binary_logloss: 0.153335\n",
      "[168]\ttrain's binary_logloss: 0.152659\n",
      "[169]\ttrain's binary_logloss: 0.151726\n",
      "[170]\ttrain's binary_logloss: 0.150959\n",
      "[171]\ttrain's binary_logloss: 0.150255\n",
      "[172]\ttrain's binary_logloss: 0.149312\n",
      "[173]\ttrain's binary_logloss: 0.148715\n",
      "[174]\ttrain's binary_logloss: 0.147935\n",
      "[175]\ttrain's binary_logloss: 0.147207\n",
      "[176]\ttrain's binary_logloss: 0.146467\n",
      "[177]\ttrain's binary_logloss: 0.145747\n",
      "[178]\ttrain's binary_logloss: 0.144968\n",
      "[179]\ttrain's binary_logloss: 0.143976\n",
      "[180]\ttrain's binary_logloss: 0.143349\n",
      "[181]\ttrain's binary_logloss: 0.142777\n",
      "[182]\ttrain's binary_logloss: 0.141895\n",
      "[183]\ttrain's binary_logloss: 0.14117\n",
      "[184]\ttrain's binary_logloss: 0.140235\n",
      "[185]\ttrain's binary_logloss: 0.139442\n",
      "[186]\ttrain's binary_logloss: 0.138812\n",
      "[187]\ttrain's binary_logloss: 0.138275\n",
      "[188]\ttrain's binary_logloss: 0.137689\n",
      "[189]\ttrain's binary_logloss: 0.137015\n",
      "[190]\ttrain's binary_logloss: 0.136435\n",
      "[191]\ttrain's binary_logloss: 0.135791\n",
      "[192]\ttrain's binary_logloss: 0.135149\n",
      "[193]\ttrain's binary_logloss: 0.134353\n",
      "[194]\ttrain's binary_logloss: 0.133886\n",
      "[195]\ttrain's binary_logloss: 0.133157\n",
      "[196]\ttrain's binary_logloss: 0.132694\n",
      "[197]\ttrain's binary_logloss: 0.13204\n",
      "[198]\ttrain's binary_logloss: 0.131377\n",
      "[199]\ttrain's binary_logloss: 0.130818\n",
      "[200]\ttrain's binary_logloss: 0.130261\n",
      "[201]\ttrain's binary_logloss: 0.129614\n",
      "[202]\ttrain's binary_logloss: 0.129119\n",
      "[203]\ttrain's binary_logloss: 0.128704\n",
      "[204]\ttrain's binary_logloss: 0.128289\n",
      "[205]\ttrain's binary_logloss: 0.127834\n",
      "[206]\ttrain's binary_logloss: 0.127428\n",
      "[207]\ttrain's binary_logloss: 0.126912\n",
      "[208]\ttrain's binary_logloss: 0.126199\n",
      "[209]\ttrain's binary_logloss: 0.125629\n",
      "[210]\ttrain's binary_logloss: 0.12503\n",
      "[211]\ttrain's binary_logloss: 0.124452\n",
      "[212]\ttrain's binary_logloss: 0.123912\n",
      "[213]\ttrain's binary_logloss: 0.123397\n",
      "[214]\ttrain's binary_logloss: 0.122826\n",
      "[215]\ttrain's binary_logloss: 0.122334\n",
      "[216]\ttrain's binary_logloss: 0.121682\n",
      "[217]\ttrain's binary_logloss: 0.121058\n",
      "[218]\ttrain's binary_logloss: 0.120728\n",
      "[219]\ttrain's binary_logloss: 0.120108\n",
      "[220]\ttrain's binary_logloss: 0.119467\n",
      "[221]\ttrain's binary_logloss: 0.119047\n",
      "[222]\ttrain's binary_logloss: 0.11837\n",
      "[223]\ttrain's binary_logloss: 0.117889\n",
      "[224]\ttrain's binary_logloss: 0.117508\n",
      "[225]\ttrain's binary_logloss: 0.116907\n",
      "[226]\ttrain's binary_logloss: 0.116397\n",
      "[227]\ttrain's binary_logloss: 0.115744\n",
      "[228]\ttrain's binary_logloss: 0.115241\n",
      "[229]\ttrain's binary_logloss: 0.114706\n",
      "[230]\ttrain's binary_logloss: 0.114348\n",
      "[231]\ttrain's binary_logloss: 0.113906\n",
      "[232]\ttrain's binary_logloss: 0.113534\n",
      "[233]\ttrain's binary_logloss: 0.113161\n",
      "[234]\ttrain's binary_logloss: 0.112658\n",
      "[235]\ttrain's binary_logloss: 0.11218\n",
      "[236]\ttrain's binary_logloss: 0.111752\n",
      "[237]\ttrain's binary_logloss: 0.111266\n",
      "[238]\ttrain's binary_logloss: 0.11082\n",
      "[239]\ttrain's binary_logloss: 0.110329\n",
      "[240]\ttrain's binary_logloss: 0.109861\n",
      "[241]\ttrain's binary_logloss: 0.109598\n",
      "[242]\ttrain's binary_logloss: 0.109082\n",
      "[243]\ttrain's binary_logloss: 0.108708\n",
      "[244]\ttrain's binary_logloss: 0.108284\n",
      "[245]\ttrain's binary_logloss: 0.107735\n",
      "[246]\ttrain's binary_logloss: 0.107267\n",
      "[247]\ttrain's binary_logloss: 0.106863\n",
      "[248]\ttrain's binary_logloss: 0.106298\n",
      "[249]\ttrain's binary_logloss: 0.105944\n",
      "[250]\ttrain's binary_logloss: 0.105679\n",
      "[251]\ttrain's binary_logloss: 0.105136\n",
      "[252]\ttrain's binary_logloss: 0.104807\n",
      "[253]\ttrain's binary_logloss: 0.10451\n",
      "[254]\ttrain's binary_logloss: 0.104076\n",
      "[255]\ttrain's binary_logloss: 0.103735\n",
      "[256]\ttrain's binary_logloss: 0.103418\n",
      "[257]\ttrain's binary_logloss: 0.103173\n",
      "[258]\ttrain's binary_logloss: 0.102829\n",
      "[259]\ttrain's binary_logloss: 0.102462\n",
      "[260]\ttrain's binary_logloss: 0.10204\n",
      "[261]\ttrain's binary_logloss: 0.101655\n",
      "[262]\ttrain's binary_logloss: 0.10139\n",
      "[263]\ttrain's binary_logloss: 0.100887\n",
      "[264]\ttrain's binary_logloss: 0.10056\n",
      "[265]\ttrain's binary_logloss: 0.100219\n",
      "[266]\ttrain's binary_logloss: 0.0998298\n",
      "[267]\ttrain's binary_logloss: 0.0996125\n",
      "[268]\ttrain's binary_logloss: 0.099272\n",
      "[269]\ttrain's binary_logloss: 0.0988129\n",
      "[270]\ttrain's binary_logloss: 0.0984263\n",
      "[271]\ttrain's binary_logloss: 0.0980475\n",
      "[272]\ttrain's binary_logloss: 0.0976559\n",
      "[273]\ttrain's binary_logloss: 0.0971706\n",
      "[274]\ttrain's binary_logloss: 0.0966521\n",
      "[275]\ttrain's binary_logloss: 0.0962974\n",
      "[276]\ttrain's binary_logloss: 0.0959101\n",
      "[277]\ttrain's binary_logloss: 0.0955168\n",
      "[278]\ttrain's binary_logloss: 0.09525\n",
      "[279]\ttrain's binary_logloss: 0.0949607\n",
      "[280]\ttrain's binary_logloss: 0.0945074\n",
      "[281]\ttrain's binary_logloss: 0.0942575\n",
      "[282]\ttrain's binary_logloss: 0.0940096\n",
      "[283]\ttrain's binary_logloss: 0.093557\n",
      "[284]\ttrain's binary_logloss: 0.093279\n",
      "[285]\ttrain's binary_logloss: 0.0929881\n",
      "[286]\ttrain's binary_logloss: 0.0925315\n",
      "[287]\ttrain's binary_logloss: 0.0922306\n",
      "[288]\ttrain's binary_logloss: 0.0919725\n",
      "[289]\ttrain's binary_logloss: 0.0917172\n",
      "[290]\ttrain's binary_logloss: 0.0912802\n",
      "[291]\ttrain's binary_logloss: 0.0910027\n",
      "[292]\ttrain's binary_logloss: 0.0905927\n",
      "[293]\ttrain's binary_logloss: 0.090328\n",
      "[294]\ttrain's binary_logloss: 0.0899746\n",
      "[295]\ttrain's binary_logloss: 0.0896888\n",
      "[296]\ttrain's binary_logloss: 0.0894817\n",
      "[297]\ttrain's binary_logloss: 0.0891636\n",
      "[298]\ttrain's binary_logloss: 0.0888349\n",
      "[299]\ttrain's binary_logloss: 0.0885953\n",
      "[300]\ttrain's binary_logloss: 0.088236\n",
      "[301]\ttrain's binary_logloss: 0.0879255\n",
      "[302]\ttrain's binary_logloss: 0.0875638\n",
      "[303]\ttrain's binary_logloss: 0.0872464\n",
      "[304]\ttrain's binary_logloss: 0.0869583\n",
      "[305]\ttrain's binary_logloss: 0.0865499\n",
      "[306]\ttrain's binary_logloss: 0.0862575\n",
      "[307]\ttrain's binary_logloss: 0.0859256\n",
      "[308]\ttrain's binary_logloss: 0.0856135\n",
      "[309]\ttrain's binary_logloss: 0.0852874\n",
      "[310]\ttrain's binary_logloss: 0.0849515\n",
      "[311]\ttrain's binary_logloss: 0.0845017\n",
      "[312]\ttrain's binary_logloss: 0.0842184\n",
      "[313]\ttrain's binary_logloss: 0.0838351\n",
      "[314]\ttrain's binary_logloss: 0.083489\n",
      "[315]\ttrain's binary_logloss: 0.0832336\n",
      "[316]\ttrain's binary_logloss: 0.0829025\n",
      "[317]\ttrain's binary_logloss: 0.0826862\n",
      "[318]\ttrain's binary_logloss: 0.0824436\n",
      "[319]\ttrain's binary_logloss: 0.0821922\n",
      "[320]\ttrain's binary_logloss: 0.0820017\n",
      "[321]\ttrain's binary_logloss: 0.0816868\n",
      "[322]\ttrain's binary_logloss: 0.0814244\n",
      "[323]\ttrain's binary_logloss: 0.0811457\n",
      "[324]\ttrain's binary_logloss: 0.0809554\n",
      "[325]\ttrain's binary_logloss: 0.0806175\n",
      "[326]\ttrain's binary_logloss: 0.080361\n",
      "[327]\ttrain's binary_logloss: 0.0799872\n",
      "[328]\ttrain's binary_logloss: 0.0796845\n",
      "[329]\ttrain's binary_logloss: 0.0794718\n",
      "[330]\ttrain's binary_logloss: 0.0791083\n",
      "[331]\ttrain's binary_logloss: 0.0789311\n",
      "[332]\ttrain's binary_logloss: 0.0787092\n",
      "[333]\ttrain's binary_logloss: 0.0784438\n",
      "[334]\ttrain's binary_logloss: 0.0782098\n",
      "[335]\ttrain's binary_logloss: 0.0778961\n",
      "[336]\ttrain's binary_logloss: 0.077684\n",
      "[337]\ttrain's binary_logloss: 0.0773722\n",
      "[338]\ttrain's binary_logloss: 0.0768648\n",
      "[339]\ttrain's binary_logloss: 0.0765069\n",
      "[340]\ttrain's binary_logloss: 0.0763368\n",
      "[341]\ttrain's binary_logloss: 0.0760971\n",
      "[342]\ttrain's binary_logloss: 0.075822\n",
      "[343]\ttrain's binary_logloss: 0.0755802\n",
      "[344]\ttrain's binary_logloss: 0.0752465\n",
      "[345]\ttrain's binary_logloss: 0.0749274\n",
      "[346]\ttrain's binary_logloss: 0.0746732\n",
      "[347]\ttrain's binary_logloss: 0.0742712\n",
      "[348]\ttrain's binary_logloss: 0.0739543\n",
      "[349]\ttrain's binary_logloss: 0.0736926\n",
      "[350]\ttrain's binary_logloss: 0.0734034\n",
      "[351]\ttrain's binary_logloss: 0.0731881\n",
      "[352]\ttrain's binary_logloss: 0.0729633\n",
      "[353]\ttrain's binary_logloss: 0.0727896\n",
      "[354]\ttrain's binary_logloss: 0.072562\n",
      "[355]\ttrain's binary_logloss: 0.0723966\n",
      "[356]\ttrain's binary_logloss: 0.0722166\n",
      "[357]\ttrain's binary_logloss: 0.0720762\n",
      "[358]\ttrain's binary_logloss: 0.0718436\n",
      "[359]\ttrain's binary_logloss: 0.0715495\n",
      "[360]\ttrain's binary_logloss: 0.0712312\n",
      "[361]\ttrain's binary_logloss: 0.0709383\n",
      "[362]\ttrain's binary_logloss: 0.0706654\n",
      "[363]\ttrain's binary_logloss: 0.0704478\n",
      "[364]\ttrain's binary_logloss: 0.0701822\n",
      "[365]\ttrain's binary_logloss: 0.0698736\n",
      "[366]\ttrain's binary_logloss: 0.0696692\n",
      "[367]\ttrain's binary_logloss: 0.0694489\n",
      "[368]\ttrain's binary_logloss: 0.0692292\n",
      "[369]\ttrain's binary_logloss: 0.0689507\n",
      "[370]\ttrain's binary_logloss: 0.0686758\n",
      "[371]\ttrain's binary_logloss: 0.068452\n",
      "[372]\ttrain's binary_logloss: 0.0683111\n",
      "[373]\ttrain's binary_logloss: 0.0681434\n",
      "[374]\ttrain's binary_logloss: 0.0679451\n",
      "[375]\ttrain's binary_logloss: 0.0678024\n",
      "[376]\ttrain's binary_logloss: 0.0676655\n",
      "[377]\ttrain's binary_logloss: 0.0675469\n",
      "[378]\ttrain's binary_logloss: 0.0673618\n",
      "[379]\ttrain's binary_logloss: 0.0670873\n",
      "[380]\ttrain's binary_logloss: 0.0668862\n",
      "[381]\ttrain's binary_logloss: 0.0666353\n",
      "[382]\ttrain's binary_logloss: 0.0664688\n",
      "[383]\ttrain's binary_logloss: 0.06623\n",
      "[384]\ttrain's binary_logloss: 0.0660523\n",
      "[385]\ttrain's binary_logloss: 0.0658824\n",
      "[386]\ttrain's binary_logloss: 0.0657147\n",
      "[387]\ttrain's binary_logloss: 0.0654769\n",
      "[388]\ttrain's binary_logloss: 0.065332\n",
      "[389]\ttrain's binary_logloss: 0.0649566\n",
      "[390]\ttrain's binary_logloss: 0.0647142\n",
      "[391]\ttrain's binary_logloss: 0.0645946\n",
      "[392]\ttrain's binary_logloss: 0.0644482\n",
      "[393]\ttrain's binary_logloss: 0.0642709\n",
      "[394]\ttrain's binary_logloss: 0.0641023\n",
      "[395]\ttrain's binary_logloss: 0.0638893\n",
      "[396]\ttrain's binary_logloss: 0.0636629\n",
      "[397]\ttrain's binary_logloss: 0.0635351\n",
      "[398]\ttrain's binary_logloss: 0.0633455\n",
      "[399]\ttrain's binary_logloss: 0.0630941\n",
      "[400]\ttrain's binary_logloss: 0.0629091\n",
      "[401]\ttrain's binary_logloss: 0.0626924\n",
      "[402]\ttrain's binary_logloss: 0.0625167\n",
      "[403]\ttrain's binary_logloss: 0.0622561\n",
      "[404]\ttrain's binary_logloss: 0.0619753\n",
      "[405]\ttrain's binary_logloss: 0.0618633\n",
      "[406]\ttrain's binary_logloss: 0.0617229\n",
      "[407]\ttrain's binary_logloss: 0.0615427\n",
      "[408]\ttrain's binary_logloss: 0.0612426\n",
      "[409]\ttrain's binary_logloss: 0.0610159\n",
      "[410]\ttrain's binary_logloss: 0.0608265\n",
      "[411]\ttrain's binary_logloss: 0.0606313\n",
      "[412]\ttrain's binary_logloss: 0.0604568\n",
      "[413]\ttrain's binary_logloss: 0.0603012\n",
      "[414]\ttrain's binary_logloss: 0.0601036\n",
      "[415]\ttrain's binary_logloss: 0.0599016\n",
      "[416]\ttrain's binary_logloss: 0.0597181\n",
      "[417]\ttrain's binary_logloss: 0.0595756\n",
      "[418]\ttrain's binary_logloss: 0.0594021\n",
      "[419]\ttrain's binary_logloss: 0.0592228\n",
      "[420]\ttrain's binary_logloss: 0.0590974\n",
      "[421]\ttrain's binary_logloss: 0.0589592\n",
      "[422]\ttrain's binary_logloss: 0.0587928\n",
      "[423]\ttrain's binary_logloss: 0.0585746\n",
      "[424]\ttrain's binary_logloss: 0.0584008\n",
      "[425]\ttrain's binary_logloss: 0.0581982\n",
      "[426]\ttrain's binary_logloss: 0.0579921\n",
      "[427]\ttrain's binary_logloss: 0.0578342\n",
      "[428]\ttrain's binary_logloss: 0.0577103\n",
      "[429]\ttrain's binary_logloss: 0.0575945\n",
      "[430]\ttrain's binary_logloss: 0.0573897\n",
      "[431]\ttrain's binary_logloss: 0.0572105\n",
      "[432]\ttrain's binary_logloss: 0.0570479\n",
      "[433]\ttrain's binary_logloss: 0.0567783\n",
      "[434]\ttrain's binary_logloss: 0.0566714\n",
      "[435]\ttrain's binary_logloss: 0.0565666\n",
      "[436]\ttrain's binary_logloss: 0.0563979\n",
      "[437]\ttrain's binary_logloss: 0.056224\n",
      "[438]\ttrain's binary_logloss: 0.0560582\n",
      "[439]\ttrain's binary_logloss: 0.0559133\n",
      "[440]\ttrain's binary_logloss: 0.0557307\n",
      "[441]\ttrain's binary_logloss: 0.055639\n",
      "[442]\ttrain's binary_logloss: 0.0554478\n",
      "[443]\ttrain's binary_logloss: 0.0553049\n",
      "[444]\ttrain's binary_logloss: 0.0551379\n",
      "[445]\ttrain's binary_logloss: 0.0549936\n",
      "[446]\ttrain's binary_logloss: 0.0548406\n",
      "[447]\ttrain's binary_logloss: 0.0546784\n",
      "[448]\ttrain's binary_logloss: 0.0545747\n",
      "[449]\ttrain's binary_logloss: 0.0544377\n",
      "[450]\ttrain's binary_logloss: 0.054326\n",
      "[451]\ttrain's binary_logloss: 0.0541696\n",
      "[452]\ttrain's binary_logloss: 0.0540874\n",
      "[453]\ttrain's binary_logloss: 0.0539605\n",
      "[454]\ttrain's binary_logloss: 0.0538119\n",
      "[455]\ttrain's binary_logloss: 0.0536672\n",
      "[456]\ttrain's binary_logloss: 0.0535799\n",
      "[457]\ttrain's binary_logloss: 0.0533833\n",
      "[458]\ttrain's binary_logloss: 0.0532557\n",
      "[459]\ttrain's binary_logloss: 0.0531591\n",
      "[460]\ttrain's binary_logloss: 0.0529716\n",
      "[461]\ttrain's binary_logloss: 0.0528433\n",
      "[462]\ttrain's binary_logloss: 0.0527358\n",
      "[463]\ttrain's binary_logloss: 0.0526425\n",
      "[464]\ttrain's binary_logloss: 0.0524576\n",
      "[465]\ttrain's binary_logloss: 0.0523841\n",
      "[466]\ttrain's binary_logloss: 0.0522507\n",
      "[467]\ttrain's binary_logloss: 0.0521395\n",
      "[468]\ttrain's binary_logloss: 0.051896\n",
      "[469]\ttrain's binary_logloss: 0.0517641\n",
      "[470]\ttrain's binary_logloss: 0.0516128\n",
      "[471]\ttrain's binary_logloss: 0.0514234\n",
      "[472]\ttrain's binary_logloss: 0.0512009\n",
      "[473]\ttrain's binary_logloss: 0.0510577\n",
      "[474]\ttrain's binary_logloss: 0.0509314\n",
      "[475]\ttrain's binary_logloss: 0.0507913\n",
      "[476]\ttrain's binary_logloss: 0.0507249\n",
      "[477]\ttrain's binary_logloss: 0.0505905\n",
      "[478]\ttrain's binary_logloss: 0.0504886\n",
      "[479]\ttrain's binary_logloss: 0.0503968\n",
      "[480]\ttrain's binary_logloss: 0.0501881\n",
      "[481]\ttrain's binary_logloss: 0.0500122\n",
      "[482]\ttrain's binary_logloss: 0.0497888\n",
      "[483]\ttrain's binary_logloss: 0.0496567\n",
      "[484]\ttrain's binary_logloss: 0.0495297\n",
      "[485]\ttrain's binary_logloss: 0.0493861\n",
      "[486]\ttrain's binary_logloss: 0.0492679\n",
      "[487]\ttrain's binary_logloss: 0.0491456\n",
      "[488]\ttrain's binary_logloss: 0.048953\n",
      "[489]\ttrain's binary_logloss: 0.0488285\n",
      "[490]\ttrain's binary_logloss: 0.0486891\n",
      "[491]\ttrain's binary_logloss: 0.0486347\n",
      "[492]\ttrain's binary_logloss: 0.0485155\n",
      "[493]\ttrain's binary_logloss: 0.0482789\n",
      "[494]\ttrain's binary_logloss: 0.0481425\n",
      "[495]\ttrain's binary_logloss: 0.047983\n",
      "[496]\ttrain's binary_logloss: 0.0478556\n",
      "[497]\ttrain's binary_logloss: 0.0476813\n",
      "[498]\ttrain's binary_logloss: 0.0475647\n",
      "[499]\ttrain's binary_logloss: 0.0475025\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "[0]\ttest-logloss:0.48809\n",
      "[1]\ttest-logloss:0.44679\n",
      "[2]\ttest-logloss:0.42412\n",
      "[3]\ttest-logloss:0.44016\n",
      "[4]\ttest-logloss:0.44331\n",
      "[5]\ttest-logloss:0.44183\n",
      "[6]\ttest-logloss:0.46534\n",
      "[7]\ttest-logloss:0.46678\n",
      "[8]\ttest-logloss:0.47348\n",
      "[9]\ttest-logloss:0.46493\n",
      "[10]\ttest-logloss:0.46420\n",
      "[11]\ttest-logloss:0.45894\n",
      "[12]\ttest-logloss:0.46860\n",
      "[13]\ttest-logloss:0.46470\n",
      "[14]\ttest-logloss:0.45878\n",
      "[15]\ttest-logloss:0.45910\n",
      "[16]\ttest-logloss:0.46146\n",
      "[17]\ttest-logloss:0.47669\n",
      "[18]\ttest-logloss:0.47311\n",
      "[19]\ttest-logloss:0.47043\n",
      "[20]\ttest-logloss:0.48647\n",
      "[21]\ttest-logloss:0.48392\n",
      "[22]\ttest-logloss:0.49170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trainの形状： (646, 43)  y_trainの形状： (646,)  X_testの形状： (278, 43)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.645979\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.607469\n",
      "[3]\ttrain's binary_logloss: 0.575587\n",
      "[4]\ttrain's binary_logloss: 0.54889\n",
      "[5]\ttrain's binary_logloss: 0.524775\n",
      "[6]\ttrain's binary_logloss: 0.505158\n",
      "[7]\ttrain's binary_logloss: 0.487333\n",
      "[8]\ttrain's binary_logloss: 0.473403\n",
      "[9]\ttrain's binary_logloss: 0.459756\n",
      "[10]\ttrain's binary_logloss: 0.447863\n",
      "[11]\ttrain's binary_logloss: 0.437382\n",
      "[12]\ttrain's binary_logloss: 0.42888\n",
      "[13]\ttrain's binary_logloss: 0.420697\n",
      "[14]\ttrain's binary_logloss: 0.413379\n",
      "[15]\ttrain's binary_logloss: 0.407086\n",
      "[16]\ttrain's binary_logloss: 0.400418\n",
      "[17]\ttrain's binary_logloss: 0.394532\n",
      "[18]\ttrain's binary_logloss: 0.389788\n",
      "[19]\ttrain's binary_logloss: 0.384675\n",
      "[20]\ttrain's binary_logloss: 0.380166\n",
      "[21]\ttrain's binary_logloss: 0.375858\n",
      "[22]\ttrain's binary_logloss: 0.371429\n",
      "[23]\ttrain's binary_logloss: 0.367647\n",
      "[24]\ttrain's binary_logloss: 0.362687\n",
      "[25]\ttrain's binary_logloss: 0.358916\n",
      "[26]\ttrain's binary_logloss: 0.3553\n",
      "[27]\ttrain's binary_logloss: 0.351454\n",
      "[28]\ttrain's binary_logloss: 0.347952\n",
      "[29]\ttrain's binary_logloss: 0.344491\n",
      "[30]\ttrain's binary_logloss: 0.341\n",
      "[31]\ttrain's binary_logloss: 0.338273\n",
      "[32]\ttrain's binary_logloss: 0.335374\n",
      "[33]\ttrain's binary_logloss: 0.332966\n",
      "[34]\ttrain's binary_logloss: 0.329758\n",
      "[35]\ttrain's binary_logloss: 0.327267\n",
      "[36]\ttrain's binary_logloss: 0.324796\n",
      "[37]\ttrain's binary_logloss: 0.322593\n",
      "[38]\ttrain's binary_logloss: 0.319497\n",
      "[39]\ttrain's binary_logloss: 0.316936\n",
      "[40]\ttrain's binary_logloss: 0.314706\n",
      "[41]\ttrain's binary_logloss: 0.312041\n",
      "[42]\ttrain's binary_logloss: 0.309377\n",
      "[43]\ttrain's binary_logloss: 0.307265\n",
      "[44]\ttrain's binary_logloss: 0.304797\n",
      "[45]\ttrain's binary_logloss: 0.302932\n",
      "[46]\ttrain's binary_logloss: 0.301226\n",
      "[47]\ttrain's binary_logloss: 0.299184\n",
      "[48]\ttrain's binary_logloss: 0.29694\n",
      "[49]\ttrain's binary_logloss: 0.295391\n",
      "[50]\ttrain's binary_logloss: 0.293026\n",
      "[51]\ttrain's binary_logloss: 0.291295\n",
      "[52]\ttrain's binary_logloss: 0.289817\n",
      "[53]\ttrain's binary_logloss: 0.28778\n",
      "[54]\ttrain's binary_logloss: 0.285807\n",
      "[55]\ttrain's binary_logloss: 0.283796\n",
      "[56]\ttrain's binary_logloss: 0.281902\n",
      "[57]\ttrain's binary_logloss: 0.280353\n",
      "[58]\ttrain's binary_logloss: 0.278133\n",
      "[59]\ttrain's binary_logloss: 0.276636\n",
      "[60]\ttrain's binary_logloss: 0.274882\n",
      "[61]\ttrain's binary_logloss: 0.272477\n",
      "[62]\ttrain's binary_logloss: 0.27115\n",
      "[63]\ttrain's binary_logloss: 0.268909\n",
      "[64]\ttrain's binary_logloss: 0.26711\n",
      "[65]\ttrain's binary_logloss: 0.265627\n",
      "[66]\ttrain's binary_logloss: 0.264103\n",
      "[67]\ttrain's binary_logloss: 0.262114\n",
      "[68]\ttrain's binary_logloss: 0.26011\n",
      "[69]\ttrain's binary_logloss: 0.258665\n",
      "[70]\ttrain's binary_logloss: 0.25738\n",
      "[71]\ttrain's binary_logloss: 0.255726\n",
      "[72]\ttrain's binary_logloss: 0.254223\n",
      "[73]\ttrain's binary_logloss: 0.252303\n",
      "[74]\ttrain's binary_logloss: 0.251051\n",
      "[75]\ttrain's binary_logloss: 0.249495\n",
      "[76]\ttrain's binary_logloss: 0.247928\n",
      "[77]\ttrain's binary_logloss: 0.246865\n",
      "[78]\ttrain's binary_logloss: 0.245542\n",
      "[79]\ttrain's binary_logloss: 0.24408\n",
      "[80]\ttrain's binary_logloss: 0.242746\n",
      "[81]\ttrain's binary_logloss: 0.241516\n",
      "[82]\ttrain's binary_logloss: 0.240294\n",
      "[83]\ttrain's binary_logloss: 0.238656\n",
      "[84]\ttrain's binary_logloss: 0.237595\n",
      "[85]\ttrain's binary_logloss: 0.236696\n",
      "[86]\ttrain's binary_logloss: 0.235792\n",
      "[87]\ttrain's binary_logloss: 0.234593\n",
      "[88]\ttrain's binary_logloss: 0.233253\n",
      "[89]\ttrain's binary_logloss: 0.232353\n",
      "[90]\ttrain's binary_logloss: 0.230887\n",
      "[91]\ttrain's binary_logloss: 0.229588\n",
      "[92]\ttrain's binary_logloss: 0.228103\n",
      "[93]\ttrain's binary_logloss: 0.227024\n",
      "[94]\ttrain's binary_logloss: 0.225505\n",
      "[95]\ttrain's binary_logloss: 0.224624\n",
      "[96]\ttrain's binary_logloss: 0.222889\n",
      "[97]\ttrain's binary_logloss: 0.221902\n",
      "[98]\ttrain's binary_logloss: 0.22063\n",
      "[99]\ttrain's binary_logloss: 0.218838\n",
      "[100]\ttrain's binary_logloss: 0.217476\n",
      "[101]\ttrain's binary_logloss: 0.21629\n",
      "[102]\ttrain's binary_logloss: 0.214851\n",
      "[103]\ttrain's binary_logloss: 0.213776\n",
      "[104]\ttrain's binary_logloss: 0.212298\n",
      "[105]\ttrain's binary_logloss: 0.211099\n",
      "[106]\ttrain's binary_logloss: 0.210155\n",
      "[107]\ttrain's binary_logloss: 0.209238\n",
      "[108]\ttrain's binary_logloss: 0.2083\n",
      "[109]\ttrain's binary_logloss: 0.207146\n",
      "[110]\ttrain's binary_logloss: 0.206077\n",
      "[111]\ttrain's binary_logloss: 0.204606\n",
      "[112]\ttrain's binary_logloss: 0.203562\n",
      "[113]\ttrain's binary_logloss: 0.202641\n",
      "[114]\ttrain's binary_logloss: 0.20154\n",
      "[115]\ttrain's binary_logloss: 0.200288\n",
      "[116]\ttrain's binary_logloss: 0.199032\n",
      "[117]\ttrain's binary_logloss: 0.197964\n",
      "[118]\ttrain's binary_logloss: 0.196656\n",
      "[119]\ttrain's binary_logloss: 0.195804\n",
      "[120]\ttrain's binary_logloss: 0.19452\n",
      "[121]\ttrain's binary_logloss: 0.193742\n",
      "[122]\ttrain's binary_logloss: 0.192721\n",
      "[123]\ttrain's binary_logloss: 0.191777\n",
      "[124]\ttrain's binary_logloss: 0.191043\n",
      "[125]\ttrain's binary_logloss: 0.190235\n",
      "[126]\ttrain's binary_logloss: 0.189519\n",
      "[127]\ttrain's binary_logloss: 0.188461\n",
      "[128]\ttrain's binary_logloss: 0.187743\n",
      "[129]\ttrain's binary_logloss: 0.186209\n",
      "[130]\ttrain's binary_logloss: 0.185589\n",
      "[131]\ttrain's binary_logloss: 0.184918\n",
      "[132]\ttrain's binary_logloss: 0.183813\n",
      "[133]\ttrain's binary_logloss: 0.182655\n",
      "[134]\ttrain's binary_logloss: 0.181989\n",
      "[135]\ttrain's binary_logloss: 0.181103\n",
      "[136]\ttrain's binary_logloss: 0.18046\n",
      "[137]\ttrain's binary_logloss: 0.179155\n",
      "[138]\ttrain's binary_logloss: 0.178649\n",
      "[139]\ttrain's binary_logloss: 0.177763\n",
      "[140]\ttrain's binary_logloss: 0.176758\n",
      "[141]\ttrain's binary_logloss: 0.175398\n",
      "[142]\ttrain's binary_logloss: 0.174555\n",
      "[143]\ttrain's binary_logloss: 0.173431\n",
      "[144]\ttrain's binary_logloss: 0.172795\n",
      "[145]\ttrain's binary_logloss: 0.171829\n",
      "[146]\ttrain's binary_logloss: 0.170794\n",
      "[147]\ttrain's binary_logloss: 0.16996\n",
      "[148]\ttrain's binary_logloss: 0.169299\n",
      "[149]\ttrain's binary_logloss: 0.168474\n",
      "[150]\ttrain's binary_logloss: 0.167255\n",
      "[151]\ttrain's binary_logloss: 0.166508\n",
      "[152]\ttrain's binary_logloss: 0.165976\n",
      "[153]\ttrain's binary_logloss: 0.165176\n",
      "[154]\ttrain's binary_logloss: 0.164243\n",
      "[155]\ttrain's binary_logloss: 0.163129\n",
      "[156]\ttrain's binary_logloss: 0.16261\n",
      "[157]\ttrain's binary_logloss: 0.161583\n",
      "[158]\ttrain's binary_logloss: 0.16081\n",
      "[159]\ttrain's binary_logloss: 0.159906\n",
      "[160]\ttrain's binary_logloss: 0.159349\n",
      "[161]\ttrain's binary_logloss: 0.158649\n",
      "[162]\ttrain's binary_logloss: 0.157701\n",
      "[163]\ttrain's binary_logloss: 0.15675\n",
      "[164]\ttrain's binary_logloss: 0.15578\n",
      "[165]\ttrain's binary_logloss: 0.154765\n",
      "[166]\ttrain's binary_logloss: 0.154205\n",
      "[167]\ttrain's binary_logloss: 0.153335\n",
      "[168]\ttrain's binary_logloss: 0.152659\n",
      "[169]\ttrain's binary_logloss: 0.151726\n",
      "[170]\ttrain's binary_logloss: 0.150959\n",
      "[171]\ttrain's binary_logloss: 0.150255\n",
      "[172]\ttrain's binary_logloss: 0.149312\n",
      "[173]\ttrain's binary_logloss: 0.148715\n",
      "[174]\ttrain's binary_logloss: 0.147935\n",
      "[175]\ttrain's binary_logloss: 0.147207\n",
      "[176]\ttrain's binary_logloss: 0.146467\n",
      "[177]\ttrain's binary_logloss: 0.145747\n",
      "[178]\ttrain's binary_logloss: 0.144968\n",
      "[179]\ttrain's binary_logloss: 0.143976\n",
      "[180]\ttrain's binary_logloss: 0.143349\n",
      "[181]\ttrain's binary_logloss: 0.142777\n",
      "[182]\ttrain's binary_logloss: 0.141895\n",
      "[183]\ttrain's binary_logloss: 0.14117\n",
      "[184]\ttrain's binary_logloss: 0.140235\n",
      "[185]\ttrain's binary_logloss: 0.139442\n",
      "[186]\ttrain's binary_logloss: 0.138812\n",
      "[187]\ttrain's binary_logloss: 0.138275\n",
      "[188]\ttrain's binary_logloss: 0.137689\n",
      "[189]\ttrain's binary_logloss: 0.137015\n",
      "[190]\ttrain's binary_logloss: 0.136435\n",
      "[191]\ttrain's binary_logloss: 0.135791\n",
      "[192]\ttrain's binary_logloss: 0.135149\n",
      "[193]\ttrain's binary_logloss: 0.134353\n",
      "[194]\ttrain's binary_logloss: 0.133886\n",
      "[195]\ttrain's binary_logloss: 0.133157\n",
      "[196]\ttrain's binary_logloss: 0.132694\n",
      "[197]\ttrain's binary_logloss: 0.13204\n",
      "[198]\ttrain's binary_logloss: 0.131377\n",
      "[199]\ttrain's binary_logloss: 0.130818\n",
      "[200]\ttrain's binary_logloss: 0.130261\n",
      "[201]\ttrain's binary_logloss: 0.129614\n",
      "[202]\ttrain's binary_logloss: 0.129119\n",
      "[203]\ttrain's binary_logloss: 0.128704\n",
      "[204]\ttrain's binary_logloss: 0.128289\n",
      "[205]\ttrain's binary_logloss: 0.127834\n",
      "[206]\ttrain's binary_logloss: 0.127428\n",
      "[207]\ttrain's binary_logloss: 0.126912\n",
      "[208]\ttrain's binary_logloss: 0.126199\n",
      "[209]\ttrain's binary_logloss: 0.125629\n",
      "[210]\ttrain's binary_logloss: 0.12503\n",
      "[211]\ttrain's binary_logloss: 0.124452\n",
      "[212]\ttrain's binary_logloss: 0.123912\n",
      "[213]\ttrain's binary_logloss: 0.123397\n",
      "[214]\ttrain's binary_logloss: 0.122826\n",
      "[215]\ttrain's binary_logloss: 0.122334\n",
      "[216]\ttrain's binary_logloss: 0.121682\n",
      "[217]\ttrain's binary_logloss: 0.121058\n",
      "[218]\ttrain's binary_logloss: 0.120728\n",
      "[219]\ttrain's binary_logloss: 0.120108\n",
      "[220]\ttrain's binary_logloss: 0.119467\n",
      "[221]\ttrain's binary_logloss: 0.119047\n",
      "[222]\ttrain's binary_logloss: 0.11837\n",
      "[223]\ttrain's binary_logloss: 0.117889\n",
      "[224]\ttrain's binary_logloss: 0.117508\n",
      "[225]\ttrain's binary_logloss: 0.116907\n",
      "[226]\ttrain's binary_logloss: 0.116397\n",
      "[227]\ttrain's binary_logloss: 0.115744\n",
      "[228]\ttrain's binary_logloss: 0.115241\n",
      "[229]\ttrain's binary_logloss: 0.114706\n",
      "[230]\ttrain's binary_logloss: 0.114348\n",
      "[231]\ttrain's binary_logloss: 0.113906\n",
      "[232]\ttrain's binary_logloss: 0.113534\n",
      "[233]\ttrain's binary_logloss: 0.113161\n",
      "[234]\ttrain's binary_logloss: 0.112658\n",
      "[235]\ttrain's binary_logloss: 0.11218\n",
      "[236]\ttrain's binary_logloss: 0.111752\n",
      "[237]\ttrain's binary_logloss: 0.111266\n",
      "[238]\ttrain's binary_logloss: 0.11082\n",
      "[239]\ttrain's binary_logloss: 0.110329\n",
      "[240]\ttrain's binary_logloss: 0.109861\n",
      "[241]\ttrain's binary_logloss: 0.109598\n",
      "[242]\ttrain's binary_logloss: 0.109082\n",
      "[243]\ttrain's binary_logloss: 0.108708\n",
      "[244]\ttrain's binary_logloss: 0.108284\n",
      "[245]\ttrain's binary_logloss: 0.107735\n",
      "[246]\ttrain's binary_logloss: 0.107267\n",
      "[247]\ttrain's binary_logloss: 0.106863\n",
      "[248]\ttrain's binary_logloss: 0.106298\n",
      "[249]\ttrain's binary_logloss: 0.105944\n",
      "[250]\ttrain's binary_logloss: 0.105679\n",
      "[251]\ttrain's binary_logloss: 0.105136\n",
      "[252]\ttrain's binary_logloss: 0.104807\n",
      "[253]\ttrain's binary_logloss: 0.10451\n",
      "[254]\ttrain's binary_logloss: 0.104076\n",
      "[255]\ttrain's binary_logloss: 0.103735\n",
      "[256]\ttrain's binary_logloss: 0.103418\n",
      "[257]\ttrain's binary_logloss: 0.103173\n",
      "[258]\ttrain's binary_logloss: 0.102829\n",
      "[259]\ttrain's binary_logloss: 0.102462\n",
      "[260]\ttrain's binary_logloss: 0.10204\n",
      "[261]\ttrain's binary_logloss: 0.101655\n",
      "[262]\ttrain's binary_logloss: 0.10139\n",
      "[263]\ttrain's binary_logloss: 0.100887\n",
      "[264]\ttrain's binary_logloss: 0.10056\n",
      "[265]\ttrain's binary_logloss: 0.100219\n",
      "[266]\ttrain's binary_logloss: 0.0998298\n",
      "[267]\ttrain's binary_logloss: 0.0996125\n",
      "[268]\ttrain's binary_logloss: 0.099272\n",
      "[269]\ttrain's binary_logloss: 0.0988129\n",
      "[270]\ttrain's binary_logloss: 0.0984263\n",
      "[271]\ttrain's binary_logloss: 0.0980475\n",
      "[272]\ttrain's binary_logloss: 0.0976559\n",
      "[273]\ttrain's binary_logloss: 0.0971706\n",
      "[274]\ttrain's binary_logloss: 0.0966521\n",
      "[275]\ttrain's binary_logloss: 0.0962974\n",
      "[276]\ttrain's binary_logloss: 0.0959101\n",
      "[277]\ttrain's binary_logloss: 0.0955168\n",
      "[278]\ttrain's binary_logloss: 0.09525\n",
      "[279]\ttrain's binary_logloss: 0.0949607\n",
      "[280]\ttrain's binary_logloss: 0.0945074\n",
      "[281]\ttrain's binary_logloss: 0.0942575\n",
      "[282]\ttrain's binary_logloss: 0.0940096\n",
      "[283]\ttrain's binary_logloss: 0.093557\n",
      "[284]\ttrain's binary_logloss: 0.093279\n",
      "[285]\ttrain's binary_logloss: 0.0929881\n",
      "[286]\ttrain's binary_logloss: 0.0925315\n",
      "[287]\ttrain's binary_logloss: 0.0922306\n",
      "[288]\ttrain's binary_logloss: 0.0919725\n",
      "[289]\ttrain's binary_logloss: 0.0917172\n",
      "[290]\ttrain's binary_logloss: 0.0912802\n",
      "[291]\ttrain's binary_logloss: 0.0910027\n",
      "[292]\ttrain's binary_logloss: 0.0905927\n",
      "[293]\ttrain's binary_logloss: 0.090328\n",
      "[294]\ttrain's binary_logloss: 0.0899746\n",
      "[295]\ttrain's binary_logloss: 0.0896888\n",
      "[296]\ttrain's binary_logloss: 0.0894817\n",
      "[297]\ttrain's binary_logloss: 0.0891636\n",
      "[298]\ttrain's binary_logloss: 0.0888349\n",
      "[299]\ttrain's binary_logloss: 0.0885953\n",
      "[300]\ttrain's binary_logloss: 0.088236\n",
      "[301]\ttrain's binary_logloss: 0.0879255\n",
      "[302]\ttrain's binary_logloss: 0.0875638\n",
      "[303]\ttrain's binary_logloss: 0.0872464\n",
      "[304]\ttrain's binary_logloss: 0.0869583\n",
      "[305]\ttrain's binary_logloss: 0.0865499\n",
      "[306]\ttrain's binary_logloss: 0.0862575\n",
      "[307]\ttrain's binary_logloss: 0.0859256\n",
      "[308]\ttrain's binary_logloss: 0.0856135\n",
      "[309]\ttrain's binary_logloss: 0.0852874\n",
      "[310]\ttrain's binary_logloss: 0.0849515\n",
      "[311]\ttrain's binary_logloss: 0.0845017\n",
      "[312]\ttrain's binary_logloss: 0.0842184\n",
      "[313]\ttrain's binary_logloss: 0.0838351\n",
      "[314]\ttrain's binary_logloss: 0.083489\n",
      "[315]\ttrain's binary_logloss: 0.0832336\n",
      "[316]\ttrain's binary_logloss: 0.0829025\n",
      "[317]\ttrain's binary_logloss: 0.0826862\n",
      "[318]\ttrain's binary_logloss: 0.0824436\n",
      "[319]\ttrain's binary_logloss: 0.0821922\n",
      "[320]\ttrain's binary_logloss: 0.0820017\n",
      "[321]\ttrain's binary_logloss: 0.0816868\n",
      "[322]\ttrain's binary_logloss: 0.0814244\n",
      "[323]\ttrain's binary_logloss: 0.0811457\n",
      "[324]\ttrain's binary_logloss: 0.0809554\n",
      "[325]\ttrain's binary_logloss: 0.0806175\n",
      "[326]\ttrain's binary_logloss: 0.080361\n",
      "[327]\ttrain's binary_logloss: 0.0799872\n",
      "[328]\ttrain's binary_logloss: 0.0796845\n",
      "[329]\ttrain's binary_logloss: 0.0794718\n",
      "[330]\ttrain's binary_logloss: 0.0791083\n",
      "[331]\ttrain's binary_logloss: 0.0789311\n",
      "[332]\ttrain's binary_logloss: 0.0787092\n",
      "[333]\ttrain's binary_logloss: 0.0784438\n",
      "[334]\ttrain's binary_logloss: 0.0782098\n",
      "[335]\ttrain's binary_logloss: 0.0778961\n",
      "[336]\ttrain's binary_logloss: 0.077684\n",
      "[337]\ttrain's binary_logloss: 0.0773722\n",
      "[338]\ttrain's binary_logloss: 0.0768648\n",
      "[339]\ttrain's binary_logloss: 0.0765069\n",
      "[340]\ttrain's binary_logloss: 0.0763368\n",
      "[341]\ttrain's binary_logloss: 0.0760971\n",
      "[342]\ttrain's binary_logloss: 0.075822\n",
      "[343]\ttrain's binary_logloss: 0.0755802\n",
      "[344]\ttrain's binary_logloss: 0.0752465\n",
      "[345]\ttrain's binary_logloss: 0.0749274\n",
      "[346]\ttrain's binary_logloss: 0.0746732\n",
      "[347]\ttrain's binary_logloss: 0.0742712\n",
      "[348]\ttrain's binary_logloss: 0.0739543\n",
      "[349]\ttrain's binary_logloss: 0.0736926\n",
      "[350]\ttrain's binary_logloss: 0.0734034\n",
      "[351]\ttrain's binary_logloss: 0.0731881\n",
      "[352]\ttrain's binary_logloss: 0.0729633\n",
      "[353]\ttrain's binary_logloss: 0.0727896\n",
      "[354]\ttrain's binary_logloss: 0.072562\n",
      "[355]\ttrain's binary_logloss: 0.0723966\n",
      "[356]\ttrain's binary_logloss: 0.0722166\n",
      "[357]\ttrain's binary_logloss: 0.0720762\n",
      "[358]\ttrain's binary_logloss: 0.0718436\n",
      "[359]\ttrain's binary_logloss: 0.0715495\n",
      "[360]\ttrain's binary_logloss: 0.0712312\n",
      "[361]\ttrain's binary_logloss: 0.0709383\n",
      "[362]\ttrain's binary_logloss: 0.0706654\n",
      "[363]\ttrain's binary_logloss: 0.0704478\n",
      "[364]\ttrain's binary_logloss: 0.0701822\n",
      "[365]\ttrain's binary_logloss: 0.0698736\n",
      "[366]\ttrain's binary_logloss: 0.0696692\n",
      "[367]\ttrain's binary_logloss: 0.0694489\n",
      "[368]\ttrain's binary_logloss: 0.0692292\n",
      "[369]\ttrain's binary_logloss: 0.0689507\n",
      "[370]\ttrain's binary_logloss: 0.0686758\n",
      "[371]\ttrain's binary_logloss: 0.068452\n",
      "[372]\ttrain's binary_logloss: 0.0683111\n",
      "[373]\ttrain's binary_logloss: 0.0681434\n",
      "[374]\ttrain's binary_logloss: 0.0679451\n",
      "[375]\ttrain's binary_logloss: 0.0678024\n",
      "[376]\ttrain's binary_logloss: 0.0676655\n",
      "[377]\ttrain's binary_logloss: 0.0675469\n",
      "[378]\ttrain's binary_logloss: 0.0673618\n",
      "[379]\ttrain's binary_logloss: 0.0670873\n",
      "[380]\ttrain's binary_logloss: 0.0668862\n",
      "[381]\ttrain's binary_logloss: 0.0666353\n",
      "[382]\ttrain's binary_logloss: 0.0664688\n",
      "[383]\ttrain's binary_logloss: 0.06623\n",
      "[384]\ttrain's binary_logloss: 0.0660523\n",
      "[385]\ttrain's binary_logloss: 0.0658824\n",
      "[386]\ttrain's binary_logloss: 0.0657147\n",
      "[387]\ttrain's binary_logloss: 0.0654769\n",
      "[388]\ttrain's binary_logloss: 0.065332\n",
      "[389]\ttrain's binary_logloss: 0.0649566\n",
      "[390]\ttrain's binary_logloss: 0.0647142\n",
      "[391]\ttrain's binary_logloss: 0.0645946\n",
      "[392]\ttrain's binary_logloss: 0.0644482\n",
      "[393]\ttrain's binary_logloss: 0.0642709\n",
      "[394]\ttrain's binary_logloss: 0.0641023\n",
      "[395]\ttrain's binary_logloss: 0.0638893\n",
      "[396]\ttrain's binary_logloss: 0.0636629\n",
      "[397]\ttrain's binary_logloss: 0.0635351\n",
      "[398]\ttrain's binary_logloss: 0.0633455\n",
      "[399]\ttrain's binary_logloss: 0.0630941\n",
      "[400]\ttrain's binary_logloss: 0.0629091\n",
      "[401]\ttrain's binary_logloss: 0.0626924\n",
      "[402]\ttrain's binary_logloss: 0.0625167\n",
      "[403]\ttrain's binary_logloss: 0.0622561\n",
      "[404]\ttrain's binary_logloss: 0.0619753\n",
      "[405]\ttrain's binary_logloss: 0.0618633\n",
      "[406]\ttrain's binary_logloss: 0.0617229\n",
      "[407]\ttrain's binary_logloss: 0.0615427\n",
      "[408]\ttrain's binary_logloss: 0.0612426\n",
      "[409]\ttrain's binary_logloss: 0.0610159\n",
      "[410]\ttrain's binary_logloss: 0.0608265\n",
      "[411]\ttrain's binary_logloss: 0.0606313\n",
      "[412]\ttrain's binary_logloss: 0.0604568\n",
      "[413]\ttrain's binary_logloss: 0.0603012\n",
      "[414]\ttrain's binary_logloss: 0.0601036\n",
      "[415]\ttrain's binary_logloss: 0.0599016\n",
      "[416]\ttrain's binary_logloss: 0.0597181\n",
      "[417]\ttrain's binary_logloss: 0.0595756\n",
      "[418]\ttrain's binary_logloss: 0.0594021\n",
      "[419]\ttrain's binary_logloss: 0.0592228\n",
      "[420]\ttrain's binary_logloss: 0.0590974\n",
      "[421]\ttrain's binary_logloss: 0.0589592\n",
      "[422]\ttrain's binary_logloss: 0.0587928\n",
      "[423]\ttrain's binary_logloss: 0.0585746\n",
      "[424]\ttrain's binary_logloss: 0.0584008\n",
      "[425]\ttrain's binary_logloss: 0.0581982\n",
      "[426]\ttrain's binary_logloss: 0.0579921\n",
      "[427]\ttrain's binary_logloss: 0.0578342\n",
      "[428]\ttrain's binary_logloss: 0.0577103\n",
      "[429]\ttrain's binary_logloss: 0.0575945\n",
      "[430]\ttrain's binary_logloss: 0.0573897\n",
      "[431]\ttrain's binary_logloss: 0.0572105\n",
      "[432]\ttrain's binary_logloss: 0.0570479\n",
      "[433]\ttrain's binary_logloss: 0.0567783\n",
      "[434]\ttrain's binary_logloss: 0.0566714\n",
      "[435]\ttrain's binary_logloss: 0.0565666\n",
      "[436]\ttrain's binary_logloss: 0.0563979\n",
      "[437]\ttrain's binary_logloss: 0.056224\n",
      "[438]\ttrain's binary_logloss: 0.0560582\n",
      "[439]\ttrain's binary_logloss: 0.0559133\n",
      "[440]\ttrain's binary_logloss: 0.0557307\n",
      "[441]\ttrain's binary_logloss: 0.055639\n",
      "[442]\ttrain's binary_logloss: 0.0554478\n",
      "[443]\ttrain's binary_logloss: 0.0553049\n",
      "[444]\ttrain's binary_logloss: 0.0551379\n",
      "[445]\ttrain's binary_logloss: 0.0549936\n",
      "[446]\ttrain's binary_logloss: 0.0548406\n",
      "[447]\ttrain's binary_logloss: 0.0546784\n",
      "[448]\ttrain's binary_logloss: 0.0545747\n",
      "[449]\ttrain's binary_logloss: 0.0544377\n",
      "[450]\ttrain's binary_logloss: 0.054326\n",
      "[451]\ttrain's binary_logloss: 0.0541696\n",
      "[452]\ttrain's binary_logloss: 0.0540874\n",
      "[453]\ttrain's binary_logloss: 0.0539605\n",
      "[454]\ttrain's binary_logloss: 0.0538119\n",
      "[455]\ttrain's binary_logloss: 0.0536672\n",
      "[456]\ttrain's binary_logloss: 0.0535799\n",
      "[457]\ttrain's binary_logloss: 0.0533833\n",
      "[458]\ttrain's binary_logloss: 0.0532557\n",
      "[459]\ttrain's binary_logloss: 0.0531591\n",
      "[460]\ttrain's binary_logloss: 0.0529716\n",
      "[461]\ttrain's binary_logloss: 0.0528433\n",
      "[462]\ttrain's binary_logloss: 0.0527358\n",
      "[463]\ttrain's binary_logloss: 0.0526425\n",
      "[464]\ttrain's binary_logloss: 0.0524576\n",
      "[465]\ttrain's binary_logloss: 0.0523841\n",
      "[466]\ttrain's binary_logloss: 0.0522507\n",
      "[467]\ttrain's binary_logloss: 0.0521395\n",
      "[468]\ttrain's binary_logloss: 0.051896\n",
      "[469]\ttrain's binary_logloss: 0.0517641\n",
      "[470]\ttrain's binary_logloss: 0.0516128\n",
      "[471]\ttrain's binary_logloss: 0.0514234\n",
      "[472]\ttrain's binary_logloss: 0.0512009\n",
      "[473]\ttrain's binary_logloss: 0.0510577\n",
      "[474]\ttrain's binary_logloss: 0.0509314\n",
      "[475]\ttrain's binary_logloss: 0.0507913\n",
      "[476]\ttrain's binary_logloss: 0.0507249\n",
      "[477]\ttrain's binary_logloss: 0.0505905\n",
      "[478]\ttrain's binary_logloss: 0.0504886\n",
      "[479]\ttrain's binary_logloss: 0.0503968\n",
      "[480]\ttrain's binary_logloss: 0.0501881\n",
      "[481]\ttrain's binary_logloss: 0.0500122\n",
      "[482]\ttrain's binary_logloss: 0.0497888\n",
      "[483]\ttrain's binary_logloss: 0.0496567\n",
      "[484]\ttrain's binary_logloss: 0.0495297\n",
      "[485]\ttrain's binary_logloss: 0.0493861\n",
      "[486]\ttrain's binary_logloss: 0.0492679\n",
      "[487]\ttrain's binary_logloss: 0.0491456\n",
      "[488]\ttrain's binary_logloss: 0.048953\n",
      "[489]\ttrain's binary_logloss: 0.0488285\n",
      "[490]\ttrain's binary_logloss: 0.0486891\n",
      "[491]\ttrain's binary_logloss: 0.0486347\n",
      "[492]\ttrain's binary_logloss: 0.0485155\n",
      "[493]\ttrain's binary_logloss: 0.0482789\n",
      "[494]\ttrain's binary_logloss: 0.0481425\n",
      "[495]\ttrain's binary_logloss: 0.047983\n",
      "[496]\ttrain's binary_logloss: 0.0478556\n",
      "[497]\ttrain's binary_logloss: 0.0476813\n",
      "[498]\ttrain's binary_logloss: 0.0475647\n",
      "[499]\ttrain's binary_logloss: 0.0475025\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "[0]\ttest-logloss:0.48809\n",
      "[1]\ttest-logloss:0.44679\n",
      "[2]\ttest-logloss:0.42412\n",
      "[3]\ttest-logloss:0.44016\n",
      "[4]\ttest-logloss:0.44331\n",
      "[5]\ttest-logloss:0.44183\n",
      "[6]\ttest-logloss:0.46534\n",
      "[7]\ttest-logloss:0.46678\n",
      "[8]\ttest-logloss:0.47348\n",
      "[9]\ttest-logloss:0.46493\n",
      "[10]\ttest-logloss:0.46420\n",
      "[11]\ttest-logloss:0.45894\n",
      "[12]\ttest-logloss:0.46860\n",
      "[13]\ttest-logloss:0.46470\n",
      "[14]\ttest-logloss:0.45878\n",
      "[15]\ttest-logloss:0.45910\n",
      "[16]\ttest-logloss:0.46146\n",
      "[17]\ttest-logloss:0.47669\n",
      "[18]\ttest-logloss:0.47311\n",
      "[19]\ttest-logloss:0.47043\n",
      "[20]\ttest-logloss:0.48647\n",
      "[21]\ttest-logloss:0.48392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trainの形状： (646, 43)  y_trainの形状： (646,)  X_testの形状： (278, 43)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.645979\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.607469\n",
      "[3]\ttrain's binary_logloss: 0.575587\n",
      "[4]\ttrain's binary_logloss: 0.54889\n",
      "[5]\ttrain's binary_logloss: 0.524775\n",
      "[6]\ttrain's binary_logloss: 0.505158\n",
      "[7]\ttrain's binary_logloss: 0.487333\n",
      "[8]\ttrain's binary_logloss: 0.473403\n",
      "[9]\ttrain's binary_logloss: 0.459756\n",
      "[10]\ttrain's binary_logloss: 0.447863\n",
      "[11]\ttrain's binary_logloss: 0.437382\n",
      "[12]\ttrain's binary_logloss: 0.42888\n",
      "[13]\ttrain's binary_logloss: 0.420697\n",
      "[14]\ttrain's binary_logloss: 0.413379\n",
      "[15]\ttrain's binary_logloss: 0.407086\n",
      "[16]\ttrain's binary_logloss: 0.400418\n",
      "[17]\ttrain's binary_logloss: 0.394532\n",
      "[18]\ttrain's binary_logloss: 0.389788\n",
      "[19]\ttrain's binary_logloss: 0.384675\n",
      "[20]\ttrain's binary_logloss: 0.380166\n",
      "[21]\ttrain's binary_logloss: 0.375858\n",
      "[22]\ttrain's binary_logloss: 0.371429\n",
      "[23]\ttrain's binary_logloss: 0.367647\n",
      "[24]\ttrain's binary_logloss: 0.362687\n",
      "[25]\ttrain's binary_logloss: 0.358916\n",
      "[26]\ttrain's binary_logloss: 0.3553\n",
      "[27]\ttrain's binary_logloss: 0.351454\n",
      "[28]\ttrain's binary_logloss: 0.347952\n",
      "[29]\ttrain's binary_logloss: 0.344491\n",
      "[30]\ttrain's binary_logloss: 0.341\n",
      "[31]\ttrain's binary_logloss: 0.338273\n",
      "[32]\ttrain's binary_logloss: 0.335374\n",
      "[33]\ttrain's binary_logloss: 0.332966\n",
      "[34]\ttrain's binary_logloss: 0.329758\n",
      "[35]\ttrain's binary_logloss: 0.327267\n",
      "[36]\ttrain's binary_logloss: 0.324796\n",
      "[37]\ttrain's binary_logloss: 0.322593\n",
      "[38]\ttrain's binary_logloss: 0.319497\n",
      "[39]\ttrain's binary_logloss: 0.316936\n",
      "[40]\ttrain's binary_logloss: 0.314706\n",
      "[41]\ttrain's binary_logloss: 0.312041\n",
      "[42]\ttrain's binary_logloss: 0.309377\n",
      "[43]\ttrain's binary_logloss: 0.307265\n",
      "[44]\ttrain's binary_logloss: 0.304797\n",
      "[45]\ttrain's binary_logloss: 0.302932\n",
      "[46]\ttrain's binary_logloss: 0.301226\n",
      "[47]\ttrain's binary_logloss: 0.299184\n",
      "[48]\ttrain's binary_logloss: 0.29694\n",
      "[49]\ttrain's binary_logloss: 0.295391\n",
      "[50]\ttrain's binary_logloss: 0.293026\n",
      "[51]\ttrain's binary_logloss: 0.291295\n",
      "[52]\ttrain's binary_logloss: 0.289817\n",
      "[53]\ttrain's binary_logloss: 0.28778\n",
      "[54]\ttrain's binary_logloss: 0.285807\n",
      "[55]\ttrain's binary_logloss: 0.283796\n",
      "[56]\ttrain's binary_logloss: 0.281902\n",
      "[57]\ttrain's binary_logloss: 0.280353\n",
      "[58]\ttrain's binary_logloss: 0.278133\n",
      "[59]\ttrain's binary_logloss: 0.276636\n",
      "[60]\ttrain's binary_logloss: 0.274882\n",
      "[61]\ttrain's binary_logloss: 0.272477\n",
      "[62]\ttrain's binary_logloss: 0.27115\n",
      "[63]\ttrain's binary_logloss: 0.268909\n",
      "[64]\ttrain's binary_logloss: 0.26711\n",
      "[65]\ttrain's binary_logloss: 0.265627\n",
      "[66]\ttrain's binary_logloss: 0.264103\n",
      "[67]\ttrain's binary_logloss: 0.262114\n",
      "[68]\ttrain's binary_logloss: 0.26011\n",
      "[69]\ttrain's binary_logloss: 0.258665\n",
      "[70]\ttrain's binary_logloss: 0.25738\n",
      "[71]\ttrain's binary_logloss: 0.255726\n",
      "[72]\ttrain's binary_logloss: 0.254223\n",
      "[73]\ttrain's binary_logloss: 0.252303\n",
      "[74]\ttrain's binary_logloss: 0.251051\n",
      "[75]\ttrain's binary_logloss: 0.249495\n",
      "[76]\ttrain's binary_logloss: 0.247928\n",
      "[77]\ttrain's binary_logloss: 0.246865\n",
      "[78]\ttrain's binary_logloss: 0.245542\n",
      "[79]\ttrain's binary_logloss: 0.24408\n",
      "[80]\ttrain's binary_logloss: 0.242746\n",
      "[81]\ttrain's binary_logloss: 0.241516\n",
      "[82]\ttrain's binary_logloss: 0.240294\n",
      "[83]\ttrain's binary_logloss: 0.238656\n",
      "[84]\ttrain's binary_logloss: 0.237595\n",
      "[85]\ttrain's binary_logloss: 0.236696\n",
      "[86]\ttrain's binary_logloss: 0.235792\n",
      "[87]\ttrain's binary_logloss: 0.234593\n",
      "[88]\ttrain's binary_logloss: 0.233253\n",
      "[89]\ttrain's binary_logloss: 0.232353\n",
      "[90]\ttrain's binary_logloss: 0.230887\n",
      "[91]\ttrain's binary_logloss: 0.229588\n",
      "[92]\ttrain's binary_logloss: 0.228103\n",
      "[93]\ttrain's binary_logloss: 0.227024\n",
      "[94]\ttrain's binary_logloss: 0.225505\n",
      "[95]\ttrain's binary_logloss: 0.224624\n",
      "[96]\ttrain's binary_logloss: 0.222889\n",
      "[97]\ttrain's binary_logloss: 0.221902\n",
      "[98]\ttrain's binary_logloss: 0.22063\n",
      "[99]\ttrain's binary_logloss: 0.218838\n",
      "[100]\ttrain's binary_logloss: 0.217476\n",
      "[101]\ttrain's binary_logloss: 0.21629\n",
      "[102]\ttrain's binary_logloss: 0.214851\n",
      "[103]\ttrain's binary_logloss: 0.213776\n",
      "[104]\ttrain's binary_logloss: 0.212298\n",
      "[105]\ttrain's binary_logloss: 0.211099\n",
      "[106]\ttrain's binary_logloss: 0.210155\n",
      "[107]\ttrain's binary_logloss: 0.209238\n",
      "[108]\ttrain's binary_logloss: 0.2083\n",
      "[109]\ttrain's binary_logloss: 0.207146\n",
      "[110]\ttrain's binary_logloss: 0.206077\n",
      "[111]\ttrain's binary_logloss: 0.204606\n",
      "[112]\ttrain's binary_logloss: 0.203562\n",
      "[113]\ttrain's binary_logloss: 0.202641\n",
      "[114]\ttrain's binary_logloss: 0.20154\n",
      "[115]\ttrain's binary_logloss: 0.200288\n",
      "[116]\ttrain's binary_logloss: 0.199032\n",
      "[117]\ttrain's binary_logloss: 0.197964\n",
      "[118]\ttrain's binary_logloss: 0.196656\n",
      "[119]\ttrain's binary_logloss: 0.195804\n",
      "[120]\ttrain's binary_logloss: 0.19452\n",
      "[121]\ttrain's binary_logloss: 0.193742\n",
      "[122]\ttrain's binary_logloss: 0.192721\n",
      "[123]\ttrain's binary_logloss: 0.191777\n",
      "[124]\ttrain's binary_logloss: 0.191043\n",
      "[125]\ttrain's binary_logloss: 0.190235\n",
      "[126]\ttrain's binary_logloss: 0.189519\n",
      "[127]\ttrain's binary_logloss: 0.188461\n",
      "[128]\ttrain's binary_logloss: 0.187743\n",
      "[129]\ttrain's binary_logloss: 0.186209\n",
      "[130]\ttrain's binary_logloss: 0.185589\n",
      "[131]\ttrain's binary_logloss: 0.184918\n",
      "[132]\ttrain's binary_logloss: 0.183813\n",
      "[133]\ttrain's binary_logloss: 0.182655\n",
      "[134]\ttrain's binary_logloss: 0.181989\n",
      "[135]\ttrain's binary_logloss: 0.181103\n",
      "[136]\ttrain's binary_logloss: 0.18046\n",
      "[137]\ttrain's binary_logloss: 0.179155\n",
      "[138]\ttrain's binary_logloss: 0.178649\n",
      "[139]\ttrain's binary_logloss: 0.177763\n",
      "[140]\ttrain's binary_logloss: 0.176758\n",
      "[141]\ttrain's binary_logloss: 0.175398\n",
      "[142]\ttrain's binary_logloss: 0.174555\n",
      "[143]\ttrain's binary_logloss: 0.173431\n",
      "[144]\ttrain's binary_logloss: 0.172795\n",
      "[145]\ttrain's binary_logloss: 0.171829\n",
      "[146]\ttrain's binary_logloss: 0.170794\n",
      "[147]\ttrain's binary_logloss: 0.16996\n",
      "[148]\ttrain's binary_logloss: 0.169299\n",
      "[149]\ttrain's binary_logloss: 0.168474\n",
      "[150]\ttrain's binary_logloss: 0.167255\n",
      "[151]\ttrain's binary_logloss: 0.166508\n",
      "[152]\ttrain's binary_logloss: 0.165976\n",
      "[153]\ttrain's binary_logloss: 0.165176\n",
      "[154]\ttrain's binary_logloss: 0.164243\n",
      "[155]\ttrain's binary_logloss: 0.163129\n",
      "[156]\ttrain's binary_logloss: 0.16261\n",
      "[157]\ttrain's binary_logloss: 0.161583\n",
      "[158]\ttrain's binary_logloss: 0.16081\n",
      "[159]\ttrain's binary_logloss: 0.159906\n",
      "[160]\ttrain's binary_logloss: 0.159349\n",
      "[161]\ttrain's binary_logloss: 0.158649\n",
      "[162]\ttrain's binary_logloss: 0.157701\n",
      "[163]\ttrain's binary_logloss: 0.15675\n",
      "[164]\ttrain's binary_logloss: 0.15578\n",
      "[165]\ttrain's binary_logloss: 0.154765\n",
      "[166]\ttrain's binary_logloss: 0.154205\n",
      "[167]\ttrain's binary_logloss: 0.153335\n",
      "[168]\ttrain's binary_logloss: 0.152659\n",
      "[169]\ttrain's binary_logloss: 0.151726\n",
      "[170]\ttrain's binary_logloss: 0.150959\n",
      "[171]\ttrain's binary_logloss: 0.150255\n",
      "[172]\ttrain's binary_logloss: 0.149312\n",
      "[173]\ttrain's binary_logloss: 0.148715\n",
      "[174]\ttrain's binary_logloss: 0.147935\n",
      "[175]\ttrain's binary_logloss: 0.147207\n",
      "[176]\ttrain's binary_logloss: 0.146467\n",
      "[177]\ttrain's binary_logloss: 0.145747\n",
      "[178]\ttrain's binary_logloss: 0.144968\n",
      "[179]\ttrain's binary_logloss: 0.143976\n",
      "[180]\ttrain's binary_logloss: 0.143349\n",
      "[181]\ttrain's binary_logloss: 0.142777\n",
      "[182]\ttrain's binary_logloss: 0.141895\n",
      "[183]\ttrain's binary_logloss: 0.14117\n",
      "[184]\ttrain's binary_logloss: 0.140235\n",
      "[185]\ttrain's binary_logloss: 0.139442\n",
      "[186]\ttrain's binary_logloss: 0.138812\n",
      "[187]\ttrain's binary_logloss: 0.138275\n",
      "[188]\ttrain's binary_logloss: 0.137689\n",
      "[189]\ttrain's binary_logloss: 0.137015\n",
      "[190]\ttrain's binary_logloss: 0.136435\n",
      "[191]\ttrain's binary_logloss: 0.135791\n",
      "[192]\ttrain's binary_logloss: 0.135149\n",
      "[193]\ttrain's binary_logloss: 0.134353\n",
      "[194]\ttrain's binary_logloss: 0.133886\n",
      "[195]\ttrain's binary_logloss: 0.133157\n",
      "[196]\ttrain's binary_logloss: 0.132694\n",
      "[197]\ttrain's binary_logloss: 0.13204\n",
      "[198]\ttrain's binary_logloss: 0.131377\n",
      "[199]\ttrain's binary_logloss: 0.130818\n",
      "[200]\ttrain's binary_logloss: 0.130261\n",
      "[201]\ttrain's binary_logloss: 0.129614\n",
      "[202]\ttrain's binary_logloss: 0.129119\n",
      "[203]\ttrain's binary_logloss: 0.128704\n",
      "[204]\ttrain's binary_logloss: 0.128289\n",
      "[205]\ttrain's binary_logloss: 0.127834\n",
      "[206]\ttrain's binary_logloss: 0.127428\n",
      "[207]\ttrain's binary_logloss: 0.126912\n",
      "[208]\ttrain's binary_logloss: 0.126199\n",
      "[209]\ttrain's binary_logloss: 0.125629\n",
      "[210]\ttrain's binary_logloss: 0.12503\n",
      "[211]\ttrain's binary_logloss: 0.124452\n",
      "[212]\ttrain's binary_logloss: 0.123912\n",
      "[213]\ttrain's binary_logloss: 0.123397\n",
      "[214]\ttrain's binary_logloss: 0.122826\n",
      "[215]\ttrain's binary_logloss: 0.122334\n",
      "[216]\ttrain's binary_logloss: 0.121682\n",
      "[217]\ttrain's binary_logloss: 0.121058\n",
      "[218]\ttrain's binary_logloss: 0.120728\n",
      "[219]\ttrain's binary_logloss: 0.120108\n",
      "[220]\ttrain's binary_logloss: 0.119467\n",
      "[221]\ttrain's binary_logloss: 0.119047\n",
      "[222]\ttrain's binary_logloss: 0.11837\n",
      "[223]\ttrain's binary_logloss: 0.117889\n",
      "[224]\ttrain's binary_logloss: 0.117508\n",
      "[225]\ttrain's binary_logloss: 0.116907\n",
      "[226]\ttrain's binary_logloss: 0.116397\n",
      "[227]\ttrain's binary_logloss: 0.115744\n",
      "[228]\ttrain's binary_logloss: 0.115241\n",
      "[229]\ttrain's binary_logloss: 0.114706\n",
      "[230]\ttrain's binary_logloss: 0.114348\n",
      "[231]\ttrain's binary_logloss: 0.113906\n",
      "[232]\ttrain's binary_logloss: 0.113534\n",
      "[233]\ttrain's binary_logloss: 0.113161\n",
      "[234]\ttrain's binary_logloss: 0.112658\n",
      "[235]\ttrain's binary_logloss: 0.11218\n",
      "[236]\ttrain's binary_logloss: 0.111752\n",
      "[237]\ttrain's binary_logloss: 0.111266\n",
      "[238]\ttrain's binary_logloss: 0.11082\n",
      "[239]\ttrain's binary_logloss: 0.110329\n",
      "[240]\ttrain's binary_logloss: 0.109861\n",
      "[241]\ttrain's binary_logloss: 0.109598\n",
      "[242]\ttrain's binary_logloss: 0.109082\n",
      "[243]\ttrain's binary_logloss: 0.108708\n",
      "[244]\ttrain's binary_logloss: 0.108284\n",
      "[245]\ttrain's binary_logloss: 0.107735\n",
      "[246]\ttrain's binary_logloss: 0.107267\n",
      "[247]\ttrain's binary_logloss: 0.106863\n",
      "[248]\ttrain's binary_logloss: 0.106298\n",
      "[249]\ttrain's binary_logloss: 0.105944\n",
      "[250]\ttrain's binary_logloss: 0.105679\n",
      "[251]\ttrain's binary_logloss: 0.105136\n",
      "[252]\ttrain's binary_logloss: 0.104807\n",
      "[253]\ttrain's binary_logloss: 0.10451\n",
      "[254]\ttrain's binary_logloss: 0.104076\n",
      "[255]\ttrain's binary_logloss: 0.103735\n",
      "[256]\ttrain's binary_logloss: 0.103418\n",
      "[257]\ttrain's binary_logloss: 0.103173\n",
      "[258]\ttrain's binary_logloss: 0.102829\n",
      "[259]\ttrain's binary_logloss: 0.102462\n",
      "[260]\ttrain's binary_logloss: 0.10204\n",
      "[261]\ttrain's binary_logloss: 0.101655\n",
      "[262]\ttrain's binary_logloss: 0.10139\n",
      "[263]\ttrain's binary_logloss: 0.100887\n",
      "[264]\ttrain's binary_logloss: 0.10056\n",
      "[265]\ttrain's binary_logloss: 0.100219\n",
      "[266]\ttrain's binary_logloss: 0.0998298\n",
      "[267]\ttrain's binary_logloss: 0.0996125\n",
      "[268]\ttrain's binary_logloss: 0.099272\n",
      "[269]\ttrain's binary_logloss: 0.0988129\n",
      "[270]\ttrain's binary_logloss: 0.0984263\n",
      "[271]\ttrain's binary_logloss: 0.0980475\n",
      "[272]\ttrain's binary_logloss: 0.0976559\n",
      "[273]\ttrain's binary_logloss: 0.0971706\n",
      "[274]\ttrain's binary_logloss: 0.0966521\n",
      "[275]\ttrain's binary_logloss: 0.0962974\n",
      "[276]\ttrain's binary_logloss: 0.0959101\n",
      "[277]\ttrain's binary_logloss: 0.0955168\n",
      "[278]\ttrain's binary_logloss: 0.09525\n",
      "[279]\ttrain's binary_logloss: 0.0949607\n",
      "[280]\ttrain's binary_logloss: 0.0945074\n",
      "[281]\ttrain's binary_logloss: 0.0942575\n",
      "[282]\ttrain's binary_logloss: 0.0940096\n",
      "[283]\ttrain's binary_logloss: 0.093557\n",
      "[284]\ttrain's binary_logloss: 0.093279\n",
      "[285]\ttrain's binary_logloss: 0.0929881\n",
      "[286]\ttrain's binary_logloss: 0.0925315\n",
      "[287]\ttrain's binary_logloss: 0.0922306\n",
      "[288]\ttrain's binary_logloss: 0.0919725\n",
      "[289]\ttrain's binary_logloss: 0.0917172\n",
      "[290]\ttrain's binary_logloss: 0.0912802\n",
      "[291]\ttrain's binary_logloss: 0.0910027\n",
      "[292]\ttrain's binary_logloss: 0.0905927\n",
      "[293]\ttrain's binary_logloss: 0.090328\n",
      "[294]\ttrain's binary_logloss: 0.0899746\n",
      "[295]\ttrain's binary_logloss: 0.0896888\n",
      "[296]\ttrain's binary_logloss: 0.0894817\n",
      "[297]\ttrain's binary_logloss: 0.0891636\n",
      "[298]\ttrain's binary_logloss: 0.0888349\n",
      "[299]\ttrain's binary_logloss: 0.0885953\n",
      "[300]\ttrain's binary_logloss: 0.088236\n",
      "[301]\ttrain's binary_logloss: 0.0879255\n",
      "[302]\ttrain's binary_logloss: 0.0875638\n",
      "[303]\ttrain's binary_logloss: 0.0872464\n",
      "[304]\ttrain's binary_logloss: 0.0869583\n",
      "[305]\ttrain's binary_logloss: 0.0865499\n",
      "[306]\ttrain's binary_logloss: 0.0862575\n",
      "[307]\ttrain's binary_logloss: 0.0859256\n",
      "[308]\ttrain's binary_logloss: 0.0856135\n",
      "[309]\ttrain's binary_logloss: 0.0852874\n",
      "[310]\ttrain's binary_logloss: 0.0849515\n",
      "[311]\ttrain's binary_logloss: 0.0845017\n",
      "[312]\ttrain's binary_logloss: 0.0842184\n",
      "[313]\ttrain's binary_logloss: 0.0838351\n",
      "[314]\ttrain's binary_logloss: 0.083489\n",
      "[315]\ttrain's binary_logloss: 0.0832336\n",
      "[316]\ttrain's binary_logloss: 0.0829025\n",
      "[317]\ttrain's binary_logloss: 0.0826862\n",
      "[318]\ttrain's binary_logloss: 0.0824436\n",
      "[319]\ttrain's binary_logloss: 0.0821922\n",
      "[320]\ttrain's binary_logloss: 0.0820017\n",
      "[321]\ttrain's binary_logloss: 0.0816868\n",
      "[322]\ttrain's binary_logloss: 0.0814244\n",
      "[323]\ttrain's binary_logloss: 0.0811457\n",
      "[324]\ttrain's binary_logloss: 0.0809554\n",
      "[325]\ttrain's binary_logloss: 0.0806175\n",
      "[326]\ttrain's binary_logloss: 0.080361\n",
      "[327]\ttrain's binary_logloss: 0.0799872\n",
      "[328]\ttrain's binary_logloss: 0.0796845\n",
      "[329]\ttrain's binary_logloss: 0.0794718\n",
      "[330]\ttrain's binary_logloss: 0.0791083\n",
      "[331]\ttrain's binary_logloss: 0.0789311\n",
      "[332]\ttrain's binary_logloss: 0.0787092\n",
      "[333]\ttrain's binary_logloss: 0.0784438\n",
      "[334]\ttrain's binary_logloss: 0.0782098\n",
      "[335]\ttrain's binary_logloss: 0.0778961\n",
      "[336]\ttrain's binary_logloss: 0.077684\n",
      "[337]\ttrain's binary_logloss: 0.0773722\n",
      "[338]\ttrain's binary_logloss: 0.0768648\n",
      "[339]\ttrain's binary_logloss: 0.0765069\n",
      "[340]\ttrain's binary_logloss: 0.0763368\n",
      "[341]\ttrain's binary_logloss: 0.0760971\n",
      "[342]\ttrain's binary_logloss: 0.075822\n",
      "[343]\ttrain's binary_logloss: 0.0755802\n",
      "[344]\ttrain's binary_logloss: 0.0752465\n",
      "[345]\ttrain's binary_logloss: 0.0749274\n",
      "[346]\ttrain's binary_logloss: 0.0746732\n",
      "[347]\ttrain's binary_logloss: 0.0742712\n",
      "[348]\ttrain's binary_logloss: 0.0739543\n",
      "[349]\ttrain's binary_logloss: 0.0736926\n",
      "[350]\ttrain's binary_logloss: 0.0734034\n",
      "[351]\ttrain's binary_logloss: 0.0731881\n",
      "[352]\ttrain's binary_logloss: 0.0729633\n",
      "[353]\ttrain's binary_logloss: 0.0727896\n",
      "[354]\ttrain's binary_logloss: 0.072562\n",
      "[355]\ttrain's binary_logloss: 0.0723966\n",
      "[356]\ttrain's binary_logloss: 0.0722166\n",
      "[357]\ttrain's binary_logloss: 0.0720762\n",
      "[358]\ttrain's binary_logloss: 0.0718436\n",
      "[359]\ttrain's binary_logloss: 0.0715495\n",
      "[360]\ttrain's binary_logloss: 0.0712312\n",
      "[361]\ttrain's binary_logloss: 0.0709383\n",
      "[362]\ttrain's binary_logloss: 0.0706654\n",
      "[363]\ttrain's binary_logloss: 0.0704478\n",
      "[364]\ttrain's binary_logloss: 0.0701822\n",
      "[365]\ttrain's binary_logloss: 0.0698736\n",
      "[366]\ttrain's binary_logloss: 0.0696692\n",
      "[367]\ttrain's binary_logloss: 0.0694489\n",
      "[368]\ttrain's binary_logloss: 0.0692292\n",
      "[369]\ttrain's binary_logloss: 0.0689507\n",
      "[370]\ttrain's binary_logloss: 0.0686758\n",
      "[371]\ttrain's binary_logloss: 0.068452\n",
      "[372]\ttrain's binary_logloss: 0.0683111\n",
      "[373]\ttrain's binary_logloss: 0.0681434\n",
      "[374]\ttrain's binary_logloss: 0.0679451\n",
      "[375]\ttrain's binary_logloss: 0.0678024\n",
      "[376]\ttrain's binary_logloss: 0.0676655\n",
      "[377]\ttrain's binary_logloss: 0.0675469\n",
      "[378]\ttrain's binary_logloss: 0.0673618\n",
      "[379]\ttrain's binary_logloss: 0.0670873\n",
      "[380]\ttrain's binary_logloss: 0.0668862\n",
      "[381]\ttrain's binary_logloss: 0.0666353\n",
      "[382]\ttrain's binary_logloss: 0.0664688\n",
      "[383]\ttrain's binary_logloss: 0.06623\n",
      "[384]\ttrain's binary_logloss: 0.0660523\n",
      "[385]\ttrain's binary_logloss: 0.0658824\n",
      "[386]\ttrain's binary_logloss: 0.0657147\n",
      "[387]\ttrain's binary_logloss: 0.0654769\n",
      "[388]\ttrain's binary_logloss: 0.065332\n",
      "[389]\ttrain's binary_logloss: 0.0649566\n",
      "[390]\ttrain's binary_logloss: 0.0647142\n",
      "[391]\ttrain's binary_logloss: 0.0645946\n",
      "[392]\ttrain's binary_logloss: 0.0644482\n",
      "[393]\ttrain's binary_logloss: 0.0642709\n",
      "[394]\ttrain's binary_logloss: 0.0641023\n",
      "[395]\ttrain's binary_logloss: 0.0638893\n",
      "[396]\ttrain's binary_logloss: 0.0636629\n",
      "[397]\ttrain's binary_logloss: 0.0635351\n",
      "[398]\ttrain's binary_logloss: 0.0633455\n",
      "[399]\ttrain's binary_logloss: 0.0630941\n",
      "[400]\ttrain's binary_logloss: 0.0629091\n",
      "[401]\ttrain's binary_logloss: 0.0626924\n",
      "[402]\ttrain's binary_logloss: 0.0625167\n",
      "[403]\ttrain's binary_logloss: 0.0622561\n",
      "[404]\ttrain's binary_logloss: 0.0619753\n",
      "[405]\ttrain's binary_logloss: 0.0618633\n",
      "[406]\ttrain's binary_logloss: 0.0617229\n",
      "[407]\ttrain's binary_logloss: 0.0615427\n",
      "[408]\ttrain's binary_logloss: 0.0612426\n",
      "[409]\ttrain's binary_logloss: 0.0610159\n",
      "[410]\ttrain's binary_logloss: 0.0608265\n",
      "[411]\ttrain's binary_logloss: 0.0606313\n",
      "[412]\ttrain's binary_logloss: 0.0604568\n",
      "[413]\ttrain's binary_logloss: 0.0603012\n",
      "[414]\ttrain's binary_logloss: 0.0601036\n",
      "[415]\ttrain's binary_logloss: 0.0599016\n",
      "[416]\ttrain's binary_logloss: 0.0597181\n",
      "[417]\ttrain's binary_logloss: 0.0595756\n",
      "[418]\ttrain's binary_logloss: 0.0594021\n",
      "[419]\ttrain's binary_logloss: 0.0592228\n",
      "[420]\ttrain's binary_logloss: 0.0590974\n",
      "[421]\ttrain's binary_logloss: 0.0589592\n",
      "[422]\ttrain's binary_logloss: 0.0587928\n",
      "[423]\ttrain's binary_logloss: 0.0585746\n",
      "[424]\ttrain's binary_logloss: 0.0584008\n",
      "[425]\ttrain's binary_logloss: 0.0581982\n",
      "[426]\ttrain's binary_logloss: 0.0579921\n",
      "[427]\ttrain's binary_logloss: 0.0578342\n",
      "[428]\ttrain's binary_logloss: 0.0577103\n",
      "[429]\ttrain's binary_logloss: 0.0575945\n",
      "[430]\ttrain's binary_logloss: 0.0573897\n",
      "[431]\ttrain's binary_logloss: 0.0572105\n",
      "[432]\ttrain's binary_logloss: 0.0570479\n",
      "[433]\ttrain's binary_logloss: 0.0567783\n",
      "[434]\ttrain's binary_logloss: 0.0566714\n",
      "[435]\ttrain's binary_logloss: 0.0565666\n",
      "[436]\ttrain's binary_logloss: 0.0563979\n",
      "[437]\ttrain's binary_logloss: 0.056224\n",
      "[438]\ttrain's binary_logloss: 0.0560582\n",
      "[439]\ttrain's binary_logloss: 0.0559133\n",
      "[440]\ttrain's binary_logloss: 0.0557307\n",
      "[441]\ttrain's binary_logloss: 0.055639\n",
      "[442]\ttrain's binary_logloss: 0.0554478\n",
      "[443]\ttrain's binary_logloss: 0.0553049\n",
      "[444]\ttrain's binary_logloss: 0.0551379\n",
      "[445]\ttrain's binary_logloss: 0.0549936\n",
      "[446]\ttrain's binary_logloss: 0.0548406\n",
      "[447]\ttrain's binary_logloss: 0.0546784\n",
      "[448]\ttrain's binary_logloss: 0.0545747\n",
      "[449]\ttrain's binary_logloss: 0.0544377\n",
      "[450]\ttrain's binary_logloss: 0.054326\n",
      "[451]\ttrain's binary_logloss: 0.0541696\n",
      "[452]\ttrain's binary_logloss: 0.0540874\n",
      "[453]\ttrain's binary_logloss: 0.0539605\n",
      "[454]\ttrain's binary_logloss: 0.0538119\n",
      "[455]\ttrain's binary_logloss: 0.0536672\n",
      "[456]\ttrain's binary_logloss: 0.0535799\n",
      "[457]\ttrain's binary_logloss: 0.0533833\n",
      "[458]\ttrain's binary_logloss: 0.0532557\n",
      "[459]\ttrain's binary_logloss: 0.0531591\n",
      "[460]\ttrain's binary_logloss: 0.0529716\n",
      "[461]\ttrain's binary_logloss: 0.0528433\n",
      "[462]\ttrain's binary_logloss: 0.0527358\n",
      "[463]\ttrain's binary_logloss: 0.0526425\n",
      "[464]\ttrain's binary_logloss: 0.0524576\n",
      "[465]\ttrain's binary_logloss: 0.0523841\n",
      "[466]\ttrain's binary_logloss: 0.0522507\n",
      "[467]\ttrain's binary_logloss: 0.0521395\n",
      "[468]\ttrain's binary_logloss: 0.051896\n",
      "[469]\ttrain's binary_logloss: 0.0517641\n",
      "[470]\ttrain's binary_logloss: 0.0516128\n",
      "[471]\ttrain's binary_logloss: 0.0514234\n",
      "[472]\ttrain's binary_logloss: 0.0512009\n",
      "[473]\ttrain's binary_logloss: 0.0510577\n",
      "[474]\ttrain's binary_logloss: 0.0509314\n",
      "[475]\ttrain's binary_logloss: 0.0507913\n",
      "[476]\ttrain's binary_logloss: 0.0507249\n",
      "[477]\ttrain's binary_logloss: 0.0505905\n",
      "[478]\ttrain's binary_logloss: 0.0504886\n",
      "[479]\ttrain's binary_logloss: 0.0503968\n",
      "[480]\ttrain's binary_logloss: 0.0501881\n",
      "[481]\ttrain's binary_logloss: 0.0500122\n",
      "[482]\ttrain's binary_logloss: 0.0497888\n",
      "[483]\ttrain's binary_logloss: 0.0496567\n",
      "[484]\ttrain's binary_logloss: 0.0495297\n",
      "[485]\ttrain's binary_logloss: 0.0493861\n",
      "[486]\ttrain's binary_logloss: 0.0492679\n",
      "[487]\ttrain's binary_logloss: 0.0491456\n",
      "[488]\ttrain's binary_logloss: 0.048953\n",
      "[489]\ttrain's binary_logloss: 0.0488285\n",
      "[490]\ttrain's binary_logloss: 0.0486891\n",
      "[491]\ttrain's binary_logloss: 0.0486347\n",
      "[492]\ttrain's binary_logloss: 0.0485155\n",
      "[493]\ttrain's binary_logloss: 0.0482789\n",
      "[494]\ttrain's binary_logloss: 0.0481425\n",
      "[495]\ttrain's binary_logloss: 0.047983\n",
      "[496]\ttrain's binary_logloss: 0.0478556\n",
      "[497]\ttrain's binary_logloss: 0.0476813\n",
      "[498]\ttrain's binary_logloss: 0.0475647\n",
      "[499]\ttrain's binary_logloss: 0.0475025\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "[0]\ttest-logloss:0.48809\n",
      "[1]\ttest-logloss:0.44679\n",
      "[2]\ttest-logloss:0.42412\n",
      "[3]\ttest-logloss:0.44016\n",
      "[4]\ttest-logloss:0.44331\n",
      "[5]\ttest-logloss:0.44183\n",
      "[6]\ttest-logloss:0.46534\n",
      "[7]\ttest-logloss:0.46678\n",
      "[8]\ttest-logloss:0.47348\n",
      "[9]\ttest-logloss:0.46493\n",
      "[10]\ttest-logloss:0.46420\n",
      "[11]\ttest-logloss:0.45894\n",
      "[12]\ttest-logloss:0.46860\n",
      "[13]\ttest-logloss:0.46470\n",
      "[14]\ttest-logloss:0.45878\n",
      "[15]\ttest-logloss:0.45910\n",
      "[16]\ttest-logloss:0.46146\n",
      "[17]\ttest-logloss:0.47669\n",
      "[18]\ttest-logloss:0.47311\n",
      "[19]\ttest-logloss:0.47043\n",
      "[20]\ttest-logloss:0.48647\n",
      "[21]\ttest-logloss:0.48392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trainの形状： (646, 43)  y_trainの形状： (646,)  X_testの形状： (278, 43)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.645979\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.607469\n",
      "[3]\ttrain's binary_logloss: 0.575587\n",
      "[4]\ttrain's binary_logloss: 0.54889\n",
      "[5]\ttrain's binary_logloss: 0.524775\n",
      "[6]\ttrain's binary_logloss: 0.505158\n",
      "[7]\ttrain's binary_logloss: 0.487333\n",
      "[8]\ttrain's binary_logloss: 0.473403\n",
      "[9]\ttrain's binary_logloss: 0.459756\n",
      "[10]\ttrain's binary_logloss: 0.447863\n",
      "[11]\ttrain's binary_logloss: 0.437382\n",
      "[12]\ttrain's binary_logloss: 0.42888\n",
      "[13]\ttrain's binary_logloss: 0.420697\n",
      "[14]\ttrain's binary_logloss: 0.413379\n",
      "[15]\ttrain's binary_logloss: 0.407086\n",
      "[16]\ttrain's binary_logloss: 0.400418\n",
      "[17]\ttrain's binary_logloss: 0.394532\n",
      "[18]\ttrain's binary_logloss: 0.389788\n",
      "[19]\ttrain's binary_logloss: 0.384675\n",
      "[20]\ttrain's binary_logloss: 0.380166\n",
      "[21]\ttrain's binary_logloss: 0.375858\n",
      "[22]\ttrain's binary_logloss: 0.371429\n",
      "[23]\ttrain's binary_logloss: 0.367647\n",
      "[24]\ttrain's binary_logloss: 0.362687\n",
      "[25]\ttrain's binary_logloss: 0.358916\n",
      "[26]\ttrain's binary_logloss: 0.3553\n",
      "[27]\ttrain's binary_logloss: 0.351454\n",
      "[28]\ttrain's binary_logloss: 0.347952\n",
      "[29]\ttrain's binary_logloss: 0.344491\n",
      "[30]\ttrain's binary_logloss: 0.341\n",
      "[31]\ttrain's binary_logloss: 0.338273\n",
      "[32]\ttrain's binary_logloss: 0.335374\n",
      "[33]\ttrain's binary_logloss: 0.332966\n",
      "[34]\ttrain's binary_logloss: 0.329758\n",
      "[35]\ttrain's binary_logloss: 0.327267\n",
      "[36]\ttrain's binary_logloss: 0.324796\n",
      "[37]\ttrain's binary_logloss: 0.322593\n",
      "[38]\ttrain's binary_logloss: 0.319497\n",
      "[39]\ttrain's binary_logloss: 0.316936\n",
      "[40]\ttrain's binary_logloss: 0.314706\n",
      "[41]\ttrain's binary_logloss: 0.312041\n",
      "[42]\ttrain's binary_logloss: 0.309377\n",
      "[43]\ttrain's binary_logloss: 0.307265\n",
      "[44]\ttrain's binary_logloss: 0.304797\n",
      "[45]\ttrain's binary_logloss: 0.302932\n",
      "[46]\ttrain's binary_logloss: 0.301226\n",
      "[47]\ttrain's binary_logloss: 0.299184\n",
      "[48]\ttrain's binary_logloss: 0.29694\n",
      "[49]\ttrain's binary_logloss: 0.295391\n",
      "[50]\ttrain's binary_logloss: 0.293026\n",
      "[51]\ttrain's binary_logloss: 0.291295\n",
      "[52]\ttrain's binary_logloss: 0.289817\n",
      "[53]\ttrain's binary_logloss: 0.28778\n",
      "[54]\ttrain's binary_logloss: 0.285807\n",
      "[55]\ttrain's binary_logloss: 0.283796\n",
      "[56]\ttrain's binary_logloss: 0.281902\n",
      "[57]\ttrain's binary_logloss: 0.280353\n",
      "[58]\ttrain's binary_logloss: 0.278133\n",
      "[59]\ttrain's binary_logloss: 0.276636\n",
      "[60]\ttrain's binary_logloss: 0.274882\n",
      "[61]\ttrain's binary_logloss: 0.272477\n",
      "[62]\ttrain's binary_logloss: 0.27115\n",
      "[63]\ttrain's binary_logloss: 0.268909\n",
      "[64]\ttrain's binary_logloss: 0.26711\n",
      "[65]\ttrain's binary_logloss: 0.265627\n",
      "[66]\ttrain's binary_logloss: 0.264103\n",
      "[67]\ttrain's binary_logloss: 0.262114\n",
      "[68]\ttrain's binary_logloss: 0.26011\n",
      "[69]\ttrain's binary_logloss: 0.258665\n",
      "[70]\ttrain's binary_logloss: 0.25738\n",
      "[71]\ttrain's binary_logloss: 0.255726\n",
      "[72]\ttrain's binary_logloss: 0.254223\n",
      "[73]\ttrain's binary_logloss: 0.252303\n",
      "[74]\ttrain's binary_logloss: 0.251051\n",
      "[75]\ttrain's binary_logloss: 0.249495\n",
      "[76]\ttrain's binary_logloss: 0.247928\n",
      "[77]\ttrain's binary_logloss: 0.246865\n",
      "[78]\ttrain's binary_logloss: 0.245542\n",
      "[79]\ttrain's binary_logloss: 0.24408\n",
      "[80]\ttrain's binary_logloss: 0.242746\n",
      "[81]\ttrain's binary_logloss: 0.241516\n",
      "[82]\ttrain's binary_logloss: 0.240294\n",
      "[83]\ttrain's binary_logloss: 0.238656\n",
      "[84]\ttrain's binary_logloss: 0.237595\n",
      "[85]\ttrain's binary_logloss: 0.236696\n",
      "[86]\ttrain's binary_logloss: 0.235792\n",
      "[87]\ttrain's binary_logloss: 0.234593\n",
      "[88]\ttrain's binary_logloss: 0.233253\n",
      "[89]\ttrain's binary_logloss: 0.232353\n",
      "[90]\ttrain's binary_logloss: 0.230887\n",
      "[91]\ttrain's binary_logloss: 0.229588\n",
      "[92]\ttrain's binary_logloss: 0.228103\n",
      "[93]\ttrain's binary_logloss: 0.227024\n",
      "[94]\ttrain's binary_logloss: 0.225505\n",
      "[95]\ttrain's binary_logloss: 0.224624\n",
      "[96]\ttrain's binary_logloss: 0.222889\n",
      "[97]\ttrain's binary_logloss: 0.221902\n",
      "[98]\ttrain's binary_logloss: 0.22063\n",
      "[99]\ttrain's binary_logloss: 0.218838\n",
      "[100]\ttrain's binary_logloss: 0.217476\n",
      "[101]\ttrain's binary_logloss: 0.21629\n",
      "[102]\ttrain's binary_logloss: 0.214851\n",
      "[103]\ttrain's binary_logloss: 0.213776\n",
      "[104]\ttrain's binary_logloss: 0.212298\n",
      "[105]\ttrain's binary_logloss: 0.211099\n",
      "[106]\ttrain's binary_logloss: 0.210155\n",
      "[107]\ttrain's binary_logloss: 0.209238\n",
      "[108]\ttrain's binary_logloss: 0.2083\n",
      "[109]\ttrain's binary_logloss: 0.207146\n",
      "[110]\ttrain's binary_logloss: 0.206077\n",
      "[111]\ttrain's binary_logloss: 0.204606\n",
      "[112]\ttrain's binary_logloss: 0.203562\n",
      "[113]\ttrain's binary_logloss: 0.202641\n",
      "[114]\ttrain's binary_logloss: 0.20154\n",
      "[115]\ttrain's binary_logloss: 0.200288\n",
      "[116]\ttrain's binary_logloss: 0.199032\n",
      "[117]\ttrain's binary_logloss: 0.197964\n",
      "[118]\ttrain's binary_logloss: 0.196656\n",
      "[119]\ttrain's binary_logloss: 0.195804\n",
      "[120]\ttrain's binary_logloss: 0.19452\n",
      "[121]\ttrain's binary_logloss: 0.193742\n",
      "[122]\ttrain's binary_logloss: 0.192721\n",
      "[123]\ttrain's binary_logloss: 0.191777\n",
      "[124]\ttrain's binary_logloss: 0.191043\n",
      "[125]\ttrain's binary_logloss: 0.190235\n",
      "[126]\ttrain's binary_logloss: 0.189519\n",
      "[127]\ttrain's binary_logloss: 0.188461\n",
      "[128]\ttrain's binary_logloss: 0.187743\n",
      "[129]\ttrain's binary_logloss: 0.186209\n",
      "[130]\ttrain's binary_logloss: 0.185589\n",
      "[131]\ttrain's binary_logloss: 0.184918\n",
      "[132]\ttrain's binary_logloss: 0.183813\n",
      "[133]\ttrain's binary_logloss: 0.182655\n",
      "[134]\ttrain's binary_logloss: 0.181989\n",
      "[135]\ttrain's binary_logloss: 0.181103\n",
      "[136]\ttrain's binary_logloss: 0.18046\n",
      "[137]\ttrain's binary_logloss: 0.179155\n",
      "[138]\ttrain's binary_logloss: 0.178649\n",
      "[139]\ttrain's binary_logloss: 0.177763\n",
      "[140]\ttrain's binary_logloss: 0.176758\n",
      "[141]\ttrain's binary_logloss: 0.175398\n",
      "[142]\ttrain's binary_logloss: 0.174555\n",
      "[143]\ttrain's binary_logloss: 0.173431\n",
      "[144]\ttrain's binary_logloss: 0.172795\n",
      "[145]\ttrain's binary_logloss: 0.171829\n",
      "[146]\ttrain's binary_logloss: 0.170794\n",
      "[147]\ttrain's binary_logloss: 0.16996\n",
      "[148]\ttrain's binary_logloss: 0.169299\n",
      "[149]\ttrain's binary_logloss: 0.168474\n",
      "[150]\ttrain's binary_logloss: 0.167255\n",
      "[151]\ttrain's binary_logloss: 0.166508\n",
      "[152]\ttrain's binary_logloss: 0.165976\n",
      "[153]\ttrain's binary_logloss: 0.165176\n",
      "[154]\ttrain's binary_logloss: 0.164243\n",
      "[155]\ttrain's binary_logloss: 0.163129\n",
      "[156]\ttrain's binary_logloss: 0.16261\n",
      "[157]\ttrain's binary_logloss: 0.161583\n",
      "[158]\ttrain's binary_logloss: 0.16081\n",
      "[159]\ttrain's binary_logloss: 0.159906\n",
      "[160]\ttrain's binary_logloss: 0.159349\n",
      "[161]\ttrain's binary_logloss: 0.158649\n",
      "[162]\ttrain's binary_logloss: 0.157701\n",
      "[163]\ttrain's binary_logloss: 0.15675\n",
      "[164]\ttrain's binary_logloss: 0.15578\n",
      "[165]\ttrain's binary_logloss: 0.154765\n",
      "[166]\ttrain's binary_logloss: 0.154205\n",
      "[167]\ttrain's binary_logloss: 0.153335\n",
      "[168]\ttrain's binary_logloss: 0.152659\n",
      "[169]\ttrain's binary_logloss: 0.151726\n",
      "[170]\ttrain's binary_logloss: 0.150959\n",
      "[171]\ttrain's binary_logloss: 0.150255\n",
      "[172]\ttrain's binary_logloss: 0.149312\n",
      "[173]\ttrain's binary_logloss: 0.148715\n",
      "[174]\ttrain's binary_logloss: 0.147935\n",
      "[175]\ttrain's binary_logloss: 0.147207\n",
      "[176]\ttrain's binary_logloss: 0.146467\n",
      "[177]\ttrain's binary_logloss: 0.145747\n",
      "[178]\ttrain's binary_logloss: 0.144968\n",
      "[179]\ttrain's binary_logloss: 0.143976\n",
      "[180]\ttrain's binary_logloss: 0.143349\n",
      "[181]\ttrain's binary_logloss: 0.142777\n",
      "[182]\ttrain's binary_logloss: 0.141895\n",
      "[183]\ttrain's binary_logloss: 0.14117\n",
      "[184]\ttrain's binary_logloss: 0.140235\n",
      "[185]\ttrain's binary_logloss: 0.139442\n",
      "[186]\ttrain's binary_logloss: 0.138812\n",
      "[187]\ttrain's binary_logloss: 0.138275\n",
      "[188]\ttrain's binary_logloss: 0.137689\n",
      "[189]\ttrain's binary_logloss: 0.137015\n",
      "[190]\ttrain's binary_logloss: 0.136435\n",
      "[191]\ttrain's binary_logloss: 0.135791\n",
      "[192]\ttrain's binary_logloss: 0.135149\n",
      "[193]\ttrain's binary_logloss: 0.134353\n",
      "[194]\ttrain's binary_logloss: 0.133886\n",
      "[195]\ttrain's binary_logloss: 0.133157\n",
      "[196]\ttrain's binary_logloss: 0.132694\n",
      "[197]\ttrain's binary_logloss: 0.13204\n",
      "[198]\ttrain's binary_logloss: 0.131377\n",
      "[199]\ttrain's binary_logloss: 0.130818\n",
      "[200]\ttrain's binary_logloss: 0.130261\n",
      "[201]\ttrain's binary_logloss: 0.129614\n",
      "[202]\ttrain's binary_logloss: 0.129119\n",
      "[203]\ttrain's binary_logloss: 0.128704\n",
      "[204]\ttrain's binary_logloss: 0.128289\n",
      "[205]\ttrain's binary_logloss: 0.127834\n",
      "[206]\ttrain's binary_logloss: 0.127428\n",
      "[207]\ttrain's binary_logloss: 0.126912\n",
      "[208]\ttrain's binary_logloss: 0.126199\n",
      "[209]\ttrain's binary_logloss: 0.125629\n",
      "[210]\ttrain's binary_logloss: 0.12503\n",
      "[211]\ttrain's binary_logloss: 0.124452\n",
      "[212]\ttrain's binary_logloss: 0.123912\n",
      "[213]\ttrain's binary_logloss: 0.123397\n",
      "[214]\ttrain's binary_logloss: 0.122826\n",
      "[215]\ttrain's binary_logloss: 0.122334\n",
      "[216]\ttrain's binary_logloss: 0.121682\n",
      "[217]\ttrain's binary_logloss: 0.121058\n",
      "[218]\ttrain's binary_logloss: 0.120728\n",
      "[219]\ttrain's binary_logloss: 0.120108\n",
      "[220]\ttrain's binary_logloss: 0.119467\n",
      "[221]\ttrain's binary_logloss: 0.119047\n",
      "[222]\ttrain's binary_logloss: 0.11837\n",
      "[223]\ttrain's binary_logloss: 0.117889\n",
      "[224]\ttrain's binary_logloss: 0.117508\n",
      "[225]\ttrain's binary_logloss: 0.116907\n",
      "[226]\ttrain's binary_logloss: 0.116397\n",
      "[227]\ttrain's binary_logloss: 0.115744\n",
      "[228]\ttrain's binary_logloss: 0.115241\n",
      "[229]\ttrain's binary_logloss: 0.114706\n",
      "[230]\ttrain's binary_logloss: 0.114348\n",
      "[231]\ttrain's binary_logloss: 0.113906\n",
      "[232]\ttrain's binary_logloss: 0.113534\n",
      "[233]\ttrain's binary_logloss: 0.113161\n",
      "[234]\ttrain's binary_logloss: 0.112658\n",
      "[235]\ttrain's binary_logloss: 0.11218\n",
      "[236]\ttrain's binary_logloss: 0.111752\n",
      "[237]\ttrain's binary_logloss: 0.111266\n",
      "[238]\ttrain's binary_logloss: 0.11082\n",
      "[239]\ttrain's binary_logloss: 0.110329\n",
      "[240]\ttrain's binary_logloss: 0.109861\n",
      "[241]\ttrain's binary_logloss: 0.109598\n",
      "[242]\ttrain's binary_logloss: 0.109082\n",
      "[243]\ttrain's binary_logloss: 0.108708\n",
      "[244]\ttrain's binary_logloss: 0.108284\n",
      "[245]\ttrain's binary_logloss: 0.107735\n",
      "[246]\ttrain's binary_logloss: 0.107267\n",
      "[247]\ttrain's binary_logloss: 0.106863\n",
      "[248]\ttrain's binary_logloss: 0.106298\n",
      "[249]\ttrain's binary_logloss: 0.105944\n",
      "[250]\ttrain's binary_logloss: 0.105679\n",
      "[251]\ttrain's binary_logloss: 0.105136\n",
      "[252]\ttrain's binary_logloss: 0.104807\n",
      "[253]\ttrain's binary_logloss: 0.10451\n",
      "[254]\ttrain's binary_logloss: 0.104076\n",
      "[255]\ttrain's binary_logloss: 0.103735\n",
      "[256]\ttrain's binary_logloss: 0.103418\n",
      "[257]\ttrain's binary_logloss: 0.103173\n",
      "[258]\ttrain's binary_logloss: 0.102829\n",
      "[259]\ttrain's binary_logloss: 0.102462\n",
      "[260]\ttrain's binary_logloss: 0.10204\n",
      "[261]\ttrain's binary_logloss: 0.101655\n",
      "[262]\ttrain's binary_logloss: 0.10139\n",
      "[263]\ttrain's binary_logloss: 0.100887\n",
      "[264]\ttrain's binary_logloss: 0.10056\n",
      "[265]\ttrain's binary_logloss: 0.100219\n",
      "[266]\ttrain's binary_logloss: 0.0998298\n",
      "[267]\ttrain's binary_logloss: 0.0996125\n",
      "[268]\ttrain's binary_logloss: 0.099272\n",
      "[269]\ttrain's binary_logloss: 0.0988129\n",
      "[270]\ttrain's binary_logloss: 0.0984263\n",
      "[271]\ttrain's binary_logloss: 0.0980475\n",
      "[272]\ttrain's binary_logloss: 0.0976559\n",
      "[273]\ttrain's binary_logloss: 0.0971706\n",
      "[274]\ttrain's binary_logloss: 0.0966521\n",
      "[275]\ttrain's binary_logloss: 0.0962974\n",
      "[276]\ttrain's binary_logloss: 0.0959101\n",
      "[277]\ttrain's binary_logloss: 0.0955168\n",
      "[278]\ttrain's binary_logloss: 0.09525\n",
      "[279]\ttrain's binary_logloss: 0.0949607\n",
      "[280]\ttrain's binary_logloss: 0.0945074\n",
      "[281]\ttrain's binary_logloss: 0.0942575\n",
      "[282]\ttrain's binary_logloss: 0.0940096\n",
      "[283]\ttrain's binary_logloss: 0.093557\n",
      "[284]\ttrain's binary_logloss: 0.093279\n",
      "[285]\ttrain's binary_logloss: 0.0929881\n",
      "[286]\ttrain's binary_logloss: 0.0925315\n",
      "[287]\ttrain's binary_logloss: 0.0922306\n",
      "[288]\ttrain's binary_logloss: 0.0919725\n",
      "[289]\ttrain's binary_logloss: 0.0917172\n",
      "[290]\ttrain's binary_logloss: 0.0912802\n",
      "[291]\ttrain's binary_logloss: 0.0910027\n",
      "[292]\ttrain's binary_logloss: 0.0905927\n",
      "[293]\ttrain's binary_logloss: 0.090328\n",
      "[294]\ttrain's binary_logloss: 0.0899746\n",
      "[295]\ttrain's binary_logloss: 0.0896888\n",
      "[296]\ttrain's binary_logloss: 0.0894817\n",
      "[297]\ttrain's binary_logloss: 0.0891636\n",
      "[298]\ttrain's binary_logloss: 0.0888349\n",
      "[299]\ttrain's binary_logloss: 0.0885953\n",
      "[300]\ttrain's binary_logloss: 0.088236\n",
      "[301]\ttrain's binary_logloss: 0.0879255\n",
      "[302]\ttrain's binary_logloss: 0.0875638\n",
      "[303]\ttrain's binary_logloss: 0.0872464\n",
      "[304]\ttrain's binary_logloss: 0.0869583\n",
      "[305]\ttrain's binary_logloss: 0.0865499\n",
      "[306]\ttrain's binary_logloss: 0.0862575\n",
      "[307]\ttrain's binary_logloss: 0.0859256\n",
      "[308]\ttrain's binary_logloss: 0.0856135\n",
      "[309]\ttrain's binary_logloss: 0.0852874\n",
      "[310]\ttrain's binary_logloss: 0.0849515\n",
      "[311]\ttrain's binary_logloss: 0.0845017\n",
      "[312]\ttrain's binary_logloss: 0.0842184\n",
      "[313]\ttrain's binary_logloss: 0.0838351\n",
      "[314]\ttrain's binary_logloss: 0.083489\n",
      "[315]\ttrain's binary_logloss: 0.0832336\n",
      "[316]\ttrain's binary_logloss: 0.0829025\n",
      "[317]\ttrain's binary_logloss: 0.0826862\n",
      "[318]\ttrain's binary_logloss: 0.0824436\n",
      "[319]\ttrain's binary_logloss: 0.0821922\n",
      "[320]\ttrain's binary_logloss: 0.0820017\n",
      "[321]\ttrain's binary_logloss: 0.0816868\n",
      "[322]\ttrain's binary_logloss: 0.0814244\n",
      "[323]\ttrain's binary_logloss: 0.0811457\n",
      "[324]\ttrain's binary_logloss: 0.0809554\n",
      "[325]\ttrain's binary_logloss: 0.0806175\n",
      "[326]\ttrain's binary_logloss: 0.080361\n",
      "[327]\ttrain's binary_logloss: 0.0799872\n",
      "[328]\ttrain's binary_logloss: 0.0796845\n",
      "[329]\ttrain's binary_logloss: 0.0794718\n",
      "[330]\ttrain's binary_logloss: 0.0791083\n",
      "[331]\ttrain's binary_logloss: 0.0789311\n",
      "[332]\ttrain's binary_logloss: 0.0787092\n",
      "[333]\ttrain's binary_logloss: 0.0784438\n",
      "[334]\ttrain's binary_logloss: 0.0782098\n",
      "[335]\ttrain's binary_logloss: 0.0778961\n",
      "[336]\ttrain's binary_logloss: 0.077684\n",
      "[337]\ttrain's binary_logloss: 0.0773722\n",
      "[338]\ttrain's binary_logloss: 0.0768648\n",
      "[339]\ttrain's binary_logloss: 0.0765069\n",
      "[340]\ttrain's binary_logloss: 0.0763368\n",
      "[341]\ttrain's binary_logloss: 0.0760971\n",
      "[342]\ttrain's binary_logloss: 0.075822\n",
      "[343]\ttrain's binary_logloss: 0.0755802\n",
      "[344]\ttrain's binary_logloss: 0.0752465\n",
      "[345]\ttrain's binary_logloss: 0.0749274\n",
      "[346]\ttrain's binary_logloss: 0.0746732\n",
      "[347]\ttrain's binary_logloss: 0.0742712\n",
      "[348]\ttrain's binary_logloss: 0.0739543\n",
      "[349]\ttrain's binary_logloss: 0.0736926\n",
      "[350]\ttrain's binary_logloss: 0.0734034\n",
      "[351]\ttrain's binary_logloss: 0.0731881\n",
      "[352]\ttrain's binary_logloss: 0.0729633\n",
      "[353]\ttrain's binary_logloss: 0.0727896\n",
      "[354]\ttrain's binary_logloss: 0.072562\n",
      "[355]\ttrain's binary_logloss: 0.0723966\n",
      "[356]\ttrain's binary_logloss: 0.0722166\n",
      "[357]\ttrain's binary_logloss: 0.0720762\n",
      "[358]\ttrain's binary_logloss: 0.0718436\n",
      "[359]\ttrain's binary_logloss: 0.0715495\n",
      "[360]\ttrain's binary_logloss: 0.0712312\n",
      "[361]\ttrain's binary_logloss: 0.0709383\n",
      "[362]\ttrain's binary_logloss: 0.0706654\n",
      "[363]\ttrain's binary_logloss: 0.0704478\n",
      "[364]\ttrain's binary_logloss: 0.0701822\n",
      "[365]\ttrain's binary_logloss: 0.0698736\n",
      "[366]\ttrain's binary_logloss: 0.0696692\n",
      "[367]\ttrain's binary_logloss: 0.0694489\n",
      "[368]\ttrain's binary_logloss: 0.0692292\n",
      "[369]\ttrain's binary_logloss: 0.0689507\n",
      "[370]\ttrain's binary_logloss: 0.0686758\n",
      "[371]\ttrain's binary_logloss: 0.068452\n",
      "[372]\ttrain's binary_logloss: 0.0683111\n",
      "[373]\ttrain's binary_logloss: 0.0681434\n",
      "[374]\ttrain's binary_logloss: 0.0679451\n",
      "[375]\ttrain's binary_logloss: 0.0678024\n",
      "[376]\ttrain's binary_logloss: 0.0676655\n",
      "[377]\ttrain's binary_logloss: 0.0675469\n",
      "[378]\ttrain's binary_logloss: 0.0673618\n",
      "[379]\ttrain's binary_logloss: 0.0670873\n",
      "[380]\ttrain's binary_logloss: 0.0668862\n",
      "[381]\ttrain's binary_logloss: 0.0666353\n",
      "[382]\ttrain's binary_logloss: 0.0664688\n",
      "[383]\ttrain's binary_logloss: 0.06623\n",
      "[384]\ttrain's binary_logloss: 0.0660523\n",
      "[385]\ttrain's binary_logloss: 0.0658824\n",
      "[386]\ttrain's binary_logloss: 0.0657147\n",
      "[387]\ttrain's binary_logloss: 0.0654769\n",
      "[388]\ttrain's binary_logloss: 0.065332\n",
      "[389]\ttrain's binary_logloss: 0.0649566\n",
      "[390]\ttrain's binary_logloss: 0.0647142\n",
      "[391]\ttrain's binary_logloss: 0.0645946\n",
      "[392]\ttrain's binary_logloss: 0.0644482\n",
      "[393]\ttrain's binary_logloss: 0.0642709\n",
      "[394]\ttrain's binary_logloss: 0.0641023\n",
      "[395]\ttrain's binary_logloss: 0.0638893\n",
      "[396]\ttrain's binary_logloss: 0.0636629\n",
      "[397]\ttrain's binary_logloss: 0.0635351\n",
      "[398]\ttrain's binary_logloss: 0.0633455\n",
      "[399]\ttrain's binary_logloss: 0.0630941\n",
      "[400]\ttrain's binary_logloss: 0.0629091\n",
      "[401]\ttrain's binary_logloss: 0.0626924\n",
      "[402]\ttrain's binary_logloss: 0.0625167\n",
      "[403]\ttrain's binary_logloss: 0.0622561\n",
      "[404]\ttrain's binary_logloss: 0.0619753\n",
      "[405]\ttrain's binary_logloss: 0.0618633\n",
      "[406]\ttrain's binary_logloss: 0.0617229\n",
      "[407]\ttrain's binary_logloss: 0.0615427\n",
      "[408]\ttrain's binary_logloss: 0.0612426\n",
      "[409]\ttrain's binary_logloss: 0.0610159\n",
      "[410]\ttrain's binary_logloss: 0.0608265\n",
      "[411]\ttrain's binary_logloss: 0.0606313\n",
      "[412]\ttrain's binary_logloss: 0.0604568\n",
      "[413]\ttrain's binary_logloss: 0.0603012\n",
      "[414]\ttrain's binary_logloss: 0.0601036\n",
      "[415]\ttrain's binary_logloss: 0.0599016\n",
      "[416]\ttrain's binary_logloss: 0.0597181\n",
      "[417]\ttrain's binary_logloss: 0.0595756\n",
      "[418]\ttrain's binary_logloss: 0.0594021\n",
      "[419]\ttrain's binary_logloss: 0.0592228\n",
      "[420]\ttrain's binary_logloss: 0.0590974\n",
      "[421]\ttrain's binary_logloss: 0.0589592\n",
      "[422]\ttrain's binary_logloss: 0.0587928\n",
      "[423]\ttrain's binary_logloss: 0.0585746\n",
      "[424]\ttrain's binary_logloss: 0.0584008\n",
      "[425]\ttrain's binary_logloss: 0.0581982\n",
      "[426]\ttrain's binary_logloss: 0.0579921\n",
      "[427]\ttrain's binary_logloss: 0.0578342\n",
      "[428]\ttrain's binary_logloss: 0.0577103\n",
      "[429]\ttrain's binary_logloss: 0.0575945\n",
      "[430]\ttrain's binary_logloss: 0.0573897\n",
      "[431]\ttrain's binary_logloss: 0.0572105\n",
      "[432]\ttrain's binary_logloss: 0.0570479\n",
      "[433]\ttrain's binary_logloss: 0.0567783\n",
      "[434]\ttrain's binary_logloss: 0.0566714\n",
      "[435]\ttrain's binary_logloss: 0.0565666\n",
      "[436]\ttrain's binary_logloss: 0.0563979\n",
      "[437]\ttrain's binary_logloss: 0.056224\n",
      "[438]\ttrain's binary_logloss: 0.0560582\n",
      "[439]\ttrain's binary_logloss: 0.0559133\n",
      "[440]\ttrain's binary_logloss: 0.0557307\n",
      "[441]\ttrain's binary_logloss: 0.055639\n",
      "[442]\ttrain's binary_logloss: 0.0554478\n",
      "[443]\ttrain's binary_logloss: 0.0553049\n",
      "[444]\ttrain's binary_logloss: 0.0551379\n",
      "[445]\ttrain's binary_logloss: 0.0549936\n",
      "[446]\ttrain's binary_logloss: 0.0548406\n",
      "[447]\ttrain's binary_logloss: 0.0546784\n",
      "[448]\ttrain's binary_logloss: 0.0545747\n",
      "[449]\ttrain's binary_logloss: 0.0544377\n",
      "[450]\ttrain's binary_logloss: 0.054326\n",
      "[451]\ttrain's binary_logloss: 0.0541696\n",
      "[452]\ttrain's binary_logloss: 0.0540874\n",
      "[453]\ttrain's binary_logloss: 0.0539605\n",
      "[454]\ttrain's binary_logloss: 0.0538119\n",
      "[455]\ttrain's binary_logloss: 0.0536672\n",
      "[456]\ttrain's binary_logloss: 0.0535799\n",
      "[457]\ttrain's binary_logloss: 0.0533833\n",
      "[458]\ttrain's binary_logloss: 0.0532557\n",
      "[459]\ttrain's binary_logloss: 0.0531591\n",
      "[460]\ttrain's binary_logloss: 0.0529716\n",
      "[461]\ttrain's binary_logloss: 0.0528433\n",
      "[462]\ttrain's binary_logloss: 0.0527358\n",
      "[463]\ttrain's binary_logloss: 0.0526425\n",
      "[464]\ttrain's binary_logloss: 0.0524576\n",
      "[465]\ttrain's binary_logloss: 0.0523841\n",
      "[466]\ttrain's binary_logloss: 0.0522507\n",
      "[467]\ttrain's binary_logloss: 0.0521395\n",
      "[468]\ttrain's binary_logloss: 0.051896\n",
      "[469]\ttrain's binary_logloss: 0.0517641\n",
      "[470]\ttrain's binary_logloss: 0.0516128\n",
      "[471]\ttrain's binary_logloss: 0.0514234\n",
      "[472]\ttrain's binary_logloss: 0.0512009\n",
      "[473]\ttrain's binary_logloss: 0.0510577\n",
      "[474]\ttrain's binary_logloss: 0.0509314\n",
      "[475]\ttrain's binary_logloss: 0.0507913\n",
      "[476]\ttrain's binary_logloss: 0.0507249\n",
      "[477]\ttrain's binary_logloss: 0.0505905\n",
      "[478]\ttrain's binary_logloss: 0.0504886\n",
      "[479]\ttrain's binary_logloss: 0.0503968\n",
      "[480]\ttrain's binary_logloss: 0.0501881\n",
      "[481]\ttrain's binary_logloss: 0.0500122\n",
      "[482]\ttrain's binary_logloss: 0.0497888\n",
      "[483]\ttrain's binary_logloss: 0.0496567\n",
      "[484]\ttrain's binary_logloss: 0.0495297\n",
      "[485]\ttrain's binary_logloss: 0.0493861\n",
      "[486]\ttrain's binary_logloss: 0.0492679\n",
      "[487]\ttrain's binary_logloss: 0.0491456\n",
      "[488]\ttrain's binary_logloss: 0.048953\n",
      "[489]\ttrain's binary_logloss: 0.0488285\n",
      "[490]\ttrain's binary_logloss: 0.0486891\n",
      "[491]\ttrain's binary_logloss: 0.0486347\n",
      "[492]\ttrain's binary_logloss: 0.0485155\n",
      "[493]\ttrain's binary_logloss: 0.0482789\n",
      "[494]\ttrain's binary_logloss: 0.0481425\n",
      "[495]\ttrain's binary_logloss: 0.047983\n",
      "[496]\ttrain's binary_logloss: 0.0478556\n",
      "[497]\ttrain's binary_logloss: 0.0476813\n",
      "[498]\ttrain's binary_logloss: 0.0475647\n",
      "[499]\ttrain's binary_logloss: 0.0475025\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "[0]\ttest-logloss:0.48809\n",
      "[1]\ttest-logloss:0.44679\n",
      "[2]\ttest-logloss:0.42412\n",
      "[3]\ttest-logloss:0.44016\n",
      "[4]\ttest-logloss:0.44331\n",
      "[5]\ttest-logloss:0.44183\n",
      "[6]\ttest-logloss:0.46534\n",
      "[7]\ttest-logloss:0.46678\n",
      "[8]\ttest-logloss:0.47348\n",
      "[9]\ttest-logloss:0.46493\n",
      "[10]\ttest-logloss:0.46420\n",
      "[11]\ttest-logloss:0.45894\n",
      "[12]\ttest-logloss:0.46860\n",
      "[13]\ttest-logloss:0.46470\n",
      "[14]\ttest-logloss:0.45878\n",
      "[15]\ttest-logloss:0.45910\n",
      "[16]\ttest-logloss:0.46146\n",
      "[17]\ttest-logloss:0.47669\n",
      "[18]\ttest-logloss:0.47311\n",
      "[19]\ttest-logloss:0.47043\n",
      "[20]\ttest-logloss:0.48647\n",
      "[21]\ttest-logloss:0.48392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trainの形状： (646, 43)  y_trainの形状： (646,)  X_testの形状： (278, 43)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.645979\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.607469\n",
      "[3]\ttrain's binary_logloss: 0.575587\n",
      "[4]\ttrain's binary_logloss: 0.54889\n",
      "[5]\ttrain's binary_logloss: 0.524775\n",
      "[6]\ttrain's binary_logloss: 0.505158\n",
      "[7]\ttrain's binary_logloss: 0.487333\n",
      "[8]\ttrain's binary_logloss: 0.473403\n",
      "[9]\ttrain's binary_logloss: 0.459756\n",
      "[10]\ttrain's binary_logloss: 0.447863\n",
      "[11]\ttrain's binary_logloss: 0.437382\n",
      "[12]\ttrain's binary_logloss: 0.42888\n",
      "[13]\ttrain's binary_logloss: 0.420697\n",
      "[14]\ttrain's binary_logloss: 0.413379\n",
      "[15]\ttrain's binary_logloss: 0.407086\n",
      "[16]\ttrain's binary_logloss: 0.400418\n",
      "[17]\ttrain's binary_logloss: 0.394532\n",
      "[18]\ttrain's binary_logloss: 0.389788\n",
      "[19]\ttrain's binary_logloss: 0.384675\n",
      "[20]\ttrain's binary_logloss: 0.380166\n",
      "[21]\ttrain's binary_logloss: 0.375858\n",
      "[22]\ttrain's binary_logloss: 0.371429\n",
      "[23]\ttrain's binary_logloss: 0.367647\n",
      "[24]\ttrain's binary_logloss: 0.362687\n",
      "[25]\ttrain's binary_logloss: 0.358916\n",
      "[26]\ttrain's binary_logloss: 0.3553\n",
      "[27]\ttrain's binary_logloss: 0.351454\n",
      "[28]\ttrain's binary_logloss: 0.347952\n",
      "[29]\ttrain's binary_logloss: 0.344491\n",
      "[30]\ttrain's binary_logloss: 0.341\n",
      "[31]\ttrain's binary_logloss: 0.338273\n",
      "[32]\ttrain's binary_logloss: 0.335374\n",
      "[33]\ttrain's binary_logloss: 0.332966\n",
      "[34]\ttrain's binary_logloss: 0.329758\n",
      "[35]\ttrain's binary_logloss: 0.327267\n",
      "[36]\ttrain's binary_logloss: 0.324796\n",
      "[37]\ttrain's binary_logloss: 0.322593\n",
      "[38]\ttrain's binary_logloss: 0.319497\n",
      "[39]\ttrain's binary_logloss: 0.316936\n",
      "[40]\ttrain's binary_logloss: 0.314706\n",
      "[41]\ttrain's binary_logloss: 0.312041\n",
      "[42]\ttrain's binary_logloss: 0.309377\n",
      "[43]\ttrain's binary_logloss: 0.307265\n",
      "[44]\ttrain's binary_logloss: 0.304797\n",
      "[45]\ttrain's binary_logloss: 0.302932\n",
      "[46]\ttrain's binary_logloss: 0.301226\n",
      "[47]\ttrain's binary_logloss: 0.299184\n",
      "[48]\ttrain's binary_logloss: 0.29694\n",
      "[49]\ttrain's binary_logloss: 0.295391\n",
      "[50]\ttrain's binary_logloss: 0.293026\n",
      "[51]\ttrain's binary_logloss: 0.291295\n",
      "[52]\ttrain's binary_logloss: 0.289817\n",
      "[53]\ttrain's binary_logloss: 0.28778\n",
      "[54]\ttrain's binary_logloss: 0.285807\n",
      "[55]\ttrain's binary_logloss: 0.283796\n",
      "[56]\ttrain's binary_logloss: 0.281902\n",
      "[57]\ttrain's binary_logloss: 0.280353\n",
      "[58]\ttrain's binary_logloss: 0.278133\n",
      "[59]\ttrain's binary_logloss: 0.276636\n",
      "[60]\ttrain's binary_logloss: 0.274882\n",
      "[61]\ttrain's binary_logloss: 0.272477\n",
      "[62]\ttrain's binary_logloss: 0.27115\n",
      "[63]\ttrain's binary_logloss: 0.268909\n",
      "[64]\ttrain's binary_logloss: 0.26711\n",
      "[65]\ttrain's binary_logloss: 0.265627\n",
      "[66]\ttrain's binary_logloss: 0.264103\n",
      "[67]\ttrain's binary_logloss: 0.262114\n",
      "[68]\ttrain's binary_logloss: 0.26011\n",
      "[69]\ttrain's binary_logloss: 0.258665\n",
      "[70]\ttrain's binary_logloss: 0.25738\n",
      "[71]\ttrain's binary_logloss: 0.255726\n",
      "[72]\ttrain's binary_logloss: 0.254223\n",
      "[73]\ttrain's binary_logloss: 0.252303\n",
      "[74]\ttrain's binary_logloss: 0.251051\n",
      "[75]\ttrain's binary_logloss: 0.249495\n",
      "[76]\ttrain's binary_logloss: 0.247928\n",
      "[77]\ttrain's binary_logloss: 0.246865\n",
      "[78]\ttrain's binary_logloss: 0.245542\n",
      "[79]\ttrain's binary_logloss: 0.24408\n",
      "[80]\ttrain's binary_logloss: 0.242746\n",
      "[81]\ttrain's binary_logloss: 0.241516\n",
      "[82]\ttrain's binary_logloss: 0.240294\n",
      "[83]\ttrain's binary_logloss: 0.238656\n",
      "[84]\ttrain's binary_logloss: 0.237595\n",
      "[85]\ttrain's binary_logloss: 0.236696\n",
      "[86]\ttrain's binary_logloss: 0.235792\n",
      "[87]\ttrain's binary_logloss: 0.234593\n",
      "[88]\ttrain's binary_logloss: 0.233253\n",
      "[89]\ttrain's binary_logloss: 0.232353\n",
      "[90]\ttrain's binary_logloss: 0.230887\n",
      "[91]\ttrain's binary_logloss: 0.229588\n",
      "[92]\ttrain's binary_logloss: 0.228103\n",
      "[93]\ttrain's binary_logloss: 0.227024\n",
      "[94]\ttrain's binary_logloss: 0.225505\n",
      "[95]\ttrain's binary_logloss: 0.224624\n",
      "[96]\ttrain's binary_logloss: 0.222889\n",
      "[97]\ttrain's binary_logloss: 0.221902\n",
      "[98]\ttrain's binary_logloss: 0.22063\n",
      "[99]\ttrain's binary_logloss: 0.218838\n",
      "[100]\ttrain's binary_logloss: 0.217476\n",
      "[101]\ttrain's binary_logloss: 0.21629\n",
      "[102]\ttrain's binary_logloss: 0.214851\n",
      "[103]\ttrain's binary_logloss: 0.213776\n",
      "[104]\ttrain's binary_logloss: 0.212298\n",
      "[105]\ttrain's binary_logloss: 0.211099\n",
      "[106]\ttrain's binary_logloss: 0.210155\n",
      "[107]\ttrain's binary_logloss: 0.209238\n",
      "[108]\ttrain's binary_logloss: 0.2083\n",
      "[109]\ttrain's binary_logloss: 0.207146\n",
      "[110]\ttrain's binary_logloss: 0.206077\n",
      "[111]\ttrain's binary_logloss: 0.204606\n",
      "[112]\ttrain's binary_logloss: 0.203562\n",
      "[113]\ttrain's binary_logloss: 0.202641\n",
      "[114]\ttrain's binary_logloss: 0.20154\n",
      "[115]\ttrain's binary_logloss: 0.200288\n",
      "[116]\ttrain's binary_logloss: 0.199032\n",
      "[117]\ttrain's binary_logloss: 0.197964\n",
      "[118]\ttrain's binary_logloss: 0.196656\n",
      "[119]\ttrain's binary_logloss: 0.195804\n",
      "[120]\ttrain's binary_logloss: 0.19452\n",
      "[121]\ttrain's binary_logloss: 0.193742\n",
      "[122]\ttrain's binary_logloss: 0.192721\n",
      "[123]\ttrain's binary_logloss: 0.191777\n",
      "[124]\ttrain's binary_logloss: 0.191043\n",
      "[125]\ttrain's binary_logloss: 0.190235\n",
      "[126]\ttrain's binary_logloss: 0.189519\n",
      "[127]\ttrain's binary_logloss: 0.188461\n",
      "[128]\ttrain's binary_logloss: 0.187743\n",
      "[129]\ttrain's binary_logloss: 0.186209\n",
      "[130]\ttrain's binary_logloss: 0.185589\n",
      "[131]\ttrain's binary_logloss: 0.184918\n",
      "[132]\ttrain's binary_logloss: 0.183813\n",
      "[133]\ttrain's binary_logloss: 0.182655\n",
      "[134]\ttrain's binary_logloss: 0.181989\n",
      "[135]\ttrain's binary_logloss: 0.181103\n",
      "[136]\ttrain's binary_logloss: 0.18046\n",
      "[137]\ttrain's binary_logloss: 0.179155\n",
      "[138]\ttrain's binary_logloss: 0.178649\n",
      "[139]\ttrain's binary_logloss: 0.177763\n",
      "[140]\ttrain's binary_logloss: 0.176758\n",
      "[141]\ttrain's binary_logloss: 0.175398\n",
      "[142]\ttrain's binary_logloss: 0.174555\n",
      "[143]\ttrain's binary_logloss: 0.173431\n",
      "[144]\ttrain's binary_logloss: 0.172795\n",
      "[145]\ttrain's binary_logloss: 0.171829\n",
      "[146]\ttrain's binary_logloss: 0.170794\n",
      "[147]\ttrain's binary_logloss: 0.16996\n",
      "[148]\ttrain's binary_logloss: 0.169299\n",
      "[149]\ttrain's binary_logloss: 0.168474\n",
      "[150]\ttrain's binary_logloss: 0.167255\n",
      "[151]\ttrain's binary_logloss: 0.166508\n",
      "[152]\ttrain's binary_logloss: 0.165976\n",
      "[153]\ttrain's binary_logloss: 0.165176\n",
      "[154]\ttrain's binary_logloss: 0.164243\n",
      "[155]\ttrain's binary_logloss: 0.163129\n",
      "[156]\ttrain's binary_logloss: 0.16261\n",
      "[157]\ttrain's binary_logloss: 0.161583\n",
      "[158]\ttrain's binary_logloss: 0.16081\n",
      "[159]\ttrain's binary_logloss: 0.159906\n",
      "[160]\ttrain's binary_logloss: 0.159349\n",
      "[161]\ttrain's binary_logloss: 0.158649\n",
      "[162]\ttrain's binary_logloss: 0.157701\n",
      "[163]\ttrain's binary_logloss: 0.15675\n",
      "[164]\ttrain's binary_logloss: 0.15578\n",
      "[165]\ttrain's binary_logloss: 0.154765\n",
      "[166]\ttrain's binary_logloss: 0.154205\n",
      "[167]\ttrain's binary_logloss: 0.153335\n",
      "[168]\ttrain's binary_logloss: 0.152659\n",
      "[169]\ttrain's binary_logloss: 0.151726\n",
      "[170]\ttrain's binary_logloss: 0.150959\n",
      "[171]\ttrain's binary_logloss: 0.150255\n",
      "[172]\ttrain's binary_logloss: 0.149312\n",
      "[173]\ttrain's binary_logloss: 0.148715\n",
      "[174]\ttrain's binary_logloss: 0.147935\n",
      "[175]\ttrain's binary_logloss: 0.147207\n",
      "[176]\ttrain's binary_logloss: 0.146467\n",
      "[177]\ttrain's binary_logloss: 0.145747\n",
      "[178]\ttrain's binary_logloss: 0.144968\n",
      "[179]\ttrain's binary_logloss: 0.143976\n",
      "[180]\ttrain's binary_logloss: 0.143349\n",
      "[181]\ttrain's binary_logloss: 0.142777\n",
      "[182]\ttrain's binary_logloss: 0.141895\n",
      "[183]\ttrain's binary_logloss: 0.14117\n",
      "[184]\ttrain's binary_logloss: 0.140235\n",
      "[185]\ttrain's binary_logloss: 0.139442\n",
      "[186]\ttrain's binary_logloss: 0.138812\n",
      "[187]\ttrain's binary_logloss: 0.138275\n",
      "[188]\ttrain's binary_logloss: 0.137689\n",
      "[189]\ttrain's binary_logloss: 0.137015\n",
      "[190]\ttrain's binary_logloss: 0.136435\n",
      "[191]\ttrain's binary_logloss: 0.135791\n",
      "[192]\ttrain's binary_logloss: 0.135149\n",
      "[193]\ttrain's binary_logloss: 0.134353\n",
      "[194]\ttrain's binary_logloss: 0.133886\n",
      "[195]\ttrain's binary_logloss: 0.133157\n",
      "[196]\ttrain's binary_logloss: 0.132694\n",
      "[197]\ttrain's binary_logloss: 0.13204\n",
      "[198]\ttrain's binary_logloss: 0.131377\n",
      "[199]\ttrain's binary_logloss: 0.130818\n",
      "[200]\ttrain's binary_logloss: 0.130261\n",
      "[201]\ttrain's binary_logloss: 0.129614\n",
      "[202]\ttrain's binary_logloss: 0.129119\n",
      "[203]\ttrain's binary_logloss: 0.128704\n",
      "[204]\ttrain's binary_logloss: 0.128289\n",
      "[205]\ttrain's binary_logloss: 0.127834\n",
      "[206]\ttrain's binary_logloss: 0.127428\n",
      "[207]\ttrain's binary_logloss: 0.126912\n",
      "[208]\ttrain's binary_logloss: 0.126199\n",
      "[209]\ttrain's binary_logloss: 0.125629\n",
      "[210]\ttrain's binary_logloss: 0.12503\n",
      "[211]\ttrain's binary_logloss: 0.124452\n",
      "[212]\ttrain's binary_logloss: 0.123912\n",
      "[213]\ttrain's binary_logloss: 0.123397\n",
      "[214]\ttrain's binary_logloss: 0.122826\n",
      "[215]\ttrain's binary_logloss: 0.122334\n",
      "[216]\ttrain's binary_logloss: 0.121682\n",
      "[217]\ttrain's binary_logloss: 0.121058\n",
      "[218]\ttrain's binary_logloss: 0.120728\n",
      "[219]\ttrain's binary_logloss: 0.120108\n",
      "[220]\ttrain's binary_logloss: 0.119467\n",
      "[221]\ttrain's binary_logloss: 0.119047\n",
      "[222]\ttrain's binary_logloss: 0.11837\n",
      "[223]\ttrain's binary_logloss: 0.117889\n",
      "[224]\ttrain's binary_logloss: 0.117508\n",
      "[225]\ttrain's binary_logloss: 0.116907\n",
      "[226]\ttrain's binary_logloss: 0.116397\n",
      "[227]\ttrain's binary_logloss: 0.115744\n",
      "[228]\ttrain's binary_logloss: 0.115241\n",
      "[229]\ttrain's binary_logloss: 0.114706\n",
      "[230]\ttrain's binary_logloss: 0.114348\n",
      "[231]\ttrain's binary_logloss: 0.113906\n",
      "[232]\ttrain's binary_logloss: 0.113534\n",
      "[233]\ttrain's binary_logloss: 0.113161\n",
      "[234]\ttrain's binary_logloss: 0.112658\n",
      "[235]\ttrain's binary_logloss: 0.11218\n",
      "[236]\ttrain's binary_logloss: 0.111752\n",
      "[237]\ttrain's binary_logloss: 0.111266\n",
      "[238]\ttrain's binary_logloss: 0.11082\n",
      "[239]\ttrain's binary_logloss: 0.110329\n",
      "[240]\ttrain's binary_logloss: 0.109861\n",
      "[241]\ttrain's binary_logloss: 0.109598\n",
      "[242]\ttrain's binary_logloss: 0.109082\n",
      "[243]\ttrain's binary_logloss: 0.108708\n",
      "[244]\ttrain's binary_logloss: 0.108284\n",
      "[245]\ttrain's binary_logloss: 0.107735\n",
      "[246]\ttrain's binary_logloss: 0.107267\n",
      "[247]\ttrain's binary_logloss: 0.106863\n",
      "[248]\ttrain's binary_logloss: 0.106298\n",
      "[249]\ttrain's binary_logloss: 0.105944\n",
      "[250]\ttrain's binary_logloss: 0.105679\n",
      "[251]\ttrain's binary_logloss: 0.105136\n",
      "[252]\ttrain's binary_logloss: 0.104807\n",
      "[253]\ttrain's binary_logloss: 0.10451\n",
      "[254]\ttrain's binary_logloss: 0.104076\n",
      "[255]\ttrain's binary_logloss: 0.103735\n",
      "[256]\ttrain's binary_logloss: 0.103418\n",
      "[257]\ttrain's binary_logloss: 0.103173\n",
      "[258]\ttrain's binary_logloss: 0.102829\n",
      "[259]\ttrain's binary_logloss: 0.102462\n",
      "[260]\ttrain's binary_logloss: 0.10204\n",
      "[261]\ttrain's binary_logloss: 0.101655\n",
      "[262]\ttrain's binary_logloss: 0.10139\n",
      "[263]\ttrain's binary_logloss: 0.100887\n",
      "[264]\ttrain's binary_logloss: 0.10056\n",
      "[265]\ttrain's binary_logloss: 0.100219\n",
      "[266]\ttrain's binary_logloss: 0.0998298\n",
      "[267]\ttrain's binary_logloss: 0.0996125\n",
      "[268]\ttrain's binary_logloss: 0.099272\n",
      "[269]\ttrain's binary_logloss: 0.0988129\n",
      "[270]\ttrain's binary_logloss: 0.0984263\n",
      "[271]\ttrain's binary_logloss: 0.0980475\n",
      "[272]\ttrain's binary_logloss: 0.0976559\n",
      "[273]\ttrain's binary_logloss: 0.0971706\n",
      "[274]\ttrain's binary_logloss: 0.0966521\n",
      "[275]\ttrain's binary_logloss: 0.0962974\n",
      "[276]\ttrain's binary_logloss: 0.0959101\n",
      "[277]\ttrain's binary_logloss: 0.0955168\n",
      "[278]\ttrain's binary_logloss: 0.09525\n",
      "[279]\ttrain's binary_logloss: 0.0949607\n",
      "[280]\ttrain's binary_logloss: 0.0945074\n",
      "[281]\ttrain's binary_logloss: 0.0942575\n",
      "[282]\ttrain's binary_logloss: 0.0940096\n",
      "[283]\ttrain's binary_logloss: 0.093557\n",
      "[284]\ttrain's binary_logloss: 0.093279\n",
      "[285]\ttrain's binary_logloss: 0.0929881\n",
      "[286]\ttrain's binary_logloss: 0.0925315\n",
      "[287]\ttrain's binary_logloss: 0.0922306\n",
      "[288]\ttrain's binary_logloss: 0.0919725\n",
      "[289]\ttrain's binary_logloss: 0.0917172\n",
      "[290]\ttrain's binary_logloss: 0.0912802\n",
      "[291]\ttrain's binary_logloss: 0.0910027\n",
      "[292]\ttrain's binary_logloss: 0.0905927\n",
      "[293]\ttrain's binary_logloss: 0.090328\n",
      "[294]\ttrain's binary_logloss: 0.0899746\n",
      "[295]\ttrain's binary_logloss: 0.0896888\n",
      "[296]\ttrain's binary_logloss: 0.0894817\n",
      "[297]\ttrain's binary_logloss: 0.0891636\n",
      "[298]\ttrain's binary_logloss: 0.0888349\n",
      "[299]\ttrain's binary_logloss: 0.0885953\n",
      "[300]\ttrain's binary_logloss: 0.088236\n",
      "[301]\ttrain's binary_logloss: 0.0879255\n",
      "[302]\ttrain's binary_logloss: 0.0875638\n",
      "[303]\ttrain's binary_logloss: 0.0872464\n",
      "[304]\ttrain's binary_logloss: 0.0869583\n",
      "[305]\ttrain's binary_logloss: 0.0865499\n",
      "[306]\ttrain's binary_logloss: 0.0862575\n",
      "[307]\ttrain's binary_logloss: 0.0859256\n",
      "[308]\ttrain's binary_logloss: 0.0856135\n",
      "[309]\ttrain's binary_logloss: 0.0852874\n",
      "[310]\ttrain's binary_logloss: 0.0849515\n",
      "[311]\ttrain's binary_logloss: 0.0845017\n",
      "[312]\ttrain's binary_logloss: 0.0842184\n",
      "[313]\ttrain's binary_logloss: 0.0838351\n",
      "[314]\ttrain's binary_logloss: 0.083489\n",
      "[315]\ttrain's binary_logloss: 0.0832336\n",
      "[316]\ttrain's binary_logloss: 0.0829025\n",
      "[317]\ttrain's binary_logloss: 0.0826862\n",
      "[318]\ttrain's binary_logloss: 0.0824436\n",
      "[319]\ttrain's binary_logloss: 0.0821922\n",
      "[320]\ttrain's binary_logloss: 0.0820017\n",
      "[321]\ttrain's binary_logloss: 0.0816868\n",
      "[322]\ttrain's binary_logloss: 0.0814244\n",
      "[323]\ttrain's binary_logloss: 0.0811457\n",
      "[324]\ttrain's binary_logloss: 0.0809554\n",
      "[325]\ttrain's binary_logloss: 0.0806175\n",
      "[326]\ttrain's binary_logloss: 0.080361\n",
      "[327]\ttrain's binary_logloss: 0.0799872\n",
      "[328]\ttrain's binary_logloss: 0.0796845\n",
      "[329]\ttrain's binary_logloss: 0.0794718\n",
      "[330]\ttrain's binary_logloss: 0.0791083\n",
      "[331]\ttrain's binary_logloss: 0.0789311\n",
      "[332]\ttrain's binary_logloss: 0.0787092\n",
      "[333]\ttrain's binary_logloss: 0.0784438\n",
      "[334]\ttrain's binary_logloss: 0.0782098\n",
      "[335]\ttrain's binary_logloss: 0.0778961\n",
      "[336]\ttrain's binary_logloss: 0.077684\n",
      "[337]\ttrain's binary_logloss: 0.0773722\n",
      "[338]\ttrain's binary_logloss: 0.0768648\n",
      "[339]\ttrain's binary_logloss: 0.0765069\n",
      "[340]\ttrain's binary_logloss: 0.0763368\n",
      "[341]\ttrain's binary_logloss: 0.0760971\n",
      "[342]\ttrain's binary_logloss: 0.075822\n",
      "[343]\ttrain's binary_logloss: 0.0755802\n",
      "[344]\ttrain's binary_logloss: 0.0752465\n",
      "[345]\ttrain's binary_logloss: 0.0749274\n",
      "[346]\ttrain's binary_logloss: 0.0746732\n",
      "[347]\ttrain's binary_logloss: 0.0742712\n",
      "[348]\ttrain's binary_logloss: 0.0739543\n",
      "[349]\ttrain's binary_logloss: 0.0736926\n",
      "[350]\ttrain's binary_logloss: 0.0734034\n",
      "[351]\ttrain's binary_logloss: 0.0731881\n",
      "[352]\ttrain's binary_logloss: 0.0729633\n",
      "[353]\ttrain's binary_logloss: 0.0727896\n",
      "[354]\ttrain's binary_logloss: 0.072562\n",
      "[355]\ttrain's binary_logloss: 0.0723966\n",
      "[356]\ttrain's binary_logloss: 0.0722166\n",
      "[357]\ttrain's binary_logloss: 0.0720762\n",
      "[358]\ttrain's binary_logloss: 0.0718436\n",
      "[359]\ttrain's binary_logloss: 0.0715495\n",
      "[360]\ttrain's binary_logloss: 0.0712312\n",
      "[361]\ttrain's binary_logloss: 0.0709383\n",
      "[362]\ttrain's binary_logloss: 0.0706654\n",
      "[363]\ttrain's binary_logloss: 0.0704478\n",
      "[364]\ttrain's binary_logloss: 0.0701822\n",
      "[365]\ttrain's binary_logloss: 0.0698736\n",
      "[366]\ttrain's binary_logloss: 0.0696692\n",
      "[367]\ttrain's binary_logloss: 0.0694489\n",
      "[368]\ttrain's binary_logloss: 0.0692292\n",
      "[369]\ttrain's binary_logloss: 0.0689507\n",
      "[370]\ttrain's binary_logloss: 0.0686758\n",
      "[371]\ttrain's binary_logloss: 0.068452\n",
      "[372]\ttrain's binary_logloss: 0.0683111\n",
      "[373]\ttrain's binary_logloss: 0.0681434\n",
      "[374]\ttrain's binary_logloss: 0.0679451\n",
      "[375]\ttrain's binary_logloss: 0.0678024\n",
      "[376]\ttrain's binary_logloss: 0.0676655\n",
      "[377]\ttrain's binary_logloss: 0.0675469\n",
      "[378]\ttrain's binary_logloss: 0.0673618\n",
      "[379]\ttrain's binary_logloss: 0.0670873\n",
      "[380]\ttrain's binary_logloss: 0.0668862\n",
      "[381]\ttrain's binary_logloss: 0.0666353\n",
      "[382]\ttrain's binary_logloss: 0.0664688\n",
      "[383]\ttrain's binary_logloss: 0.06623\n",
      "[384]\ttrain's binary_logloss: 0.0660523\n",
      "[385]\ttrain's binary_logloss: 0.0658824\n",
      "[386]\ttrain's binary_logloss: 0.0657147\n",
      "[387]\ttrain's binary_logloss: 0.0654769\n",
      "[388]\ttrain's binary_logloss: 0.065332\n",
      "[389]\ttrain's binary_logloss: 0.0649566\n",
      "[390]\ttrain's binary_logloss: 0.0647142\n",
      "[391]\ttrain's binary_logloss: 0.0645946\n",
      "[392]\ttrain's binary_logloss: 0.0644482\n",
      "[393]\ttrain's binary_logloss: 0.0642709\n",
      "[394]\ttrain's binary_logloss: 0.0641023\n",
      "[395]\ttrain's binary_logloss: 0.0638893\n",
      "[396]\ttrain's binary_logloss: 0.0636629\n",
      "[397]\ttrain's binary_logloss: 0.0635351\n",
      "[398]\ttrain's binary_logloss: 0.0633455\n",
      "[399]\ttrain's binary_logloss: 0.0630941\n",
      "[400]\ttrain's binary_logloss: 0.0629091\n",
      "[401]\ttrain's binary_logloss: 0.0626924\n",
      "[402]\ttrain's binary_logloss: 0.0625167\n",
      "[403]\ttrain's binary_logloss: 0.0622561\n",
      "[404]\ttrain's binary_logloss: 0.0619753\n",
      "[405]\ttrain's binary_logloss: 0.0618633\n",
      "[406]\ttrain's binary_logloss: 0.0617229\n",
      "[407]\ttrain's binary_logloss: 0.0615427\n",
      "[408]\ttrain's binary_logloss: 0.0612426\n",
      "[409]\ttrain's binary_logloss: 0.0610159\n",
      "[410]\ttrain's binary_logloss: 0.0608265\n",
      "[411]\ttrain's binary_logloss: 0.0606313\n",
      "[412]\ttrain's binary_logloss: 0.0604568\n",
      "[413]\ttrain's binary_logloss: 0.0603012\n",
      "[414]\ttrain's binary_logloss: 0.0601036\n",
      "[415]\ttrain's binary_logloss: 0.0599016\n",
      "[416]\ttrain's binary_logloss: 0.0597181\n",
      "[417]\ttrain's binary_logloss: 0.0595756\n",
      "[418]\ttrain's binary_logloss: 0.0594021\n",
      "[419]\ttrain's binary_logloss: 0.0592228\n",
      "[420]\ttrain's binary_logloss: 0.0590974\n",
      "[421]\ttrain's binary_logloss: 0.0589592\n",
      "[422]\ttrain's binary_logloss: 0.0587928\n",
      "[423]\ttrain's binary_logloss: 0.0585746\n",
      "[424]\ttrain's binary_logloss: 0.0584008\n",
      "[425]\ttrain's binary_logloss: 0.0581982\n",
      "[426]\ttrain's binary_logloss: 0.0579921\n",
      "[427]\ttrain's binary_logloss: 0.0578342\n",
      "[428]\ttrain's binary_logloss: 0.0577103\n",
      "[429]\ttrain's binary_logloss: 0.0575945\n",
      "[430]\ttrain's binary_logloss: 0.0573897\n",
      "[431]\ttrain's binary_logloss: 0.0572105\n",
      "[432]\ttrain's binary_logloss: 0.0570479\n",
      "[433]\ttrain's binary_logloss: 0.0567783\n",
      "[434]\ttrain's binary_logloss: 0.0566714\n",
      "[435]\ttrain's binary_logloss: 0.0565666\n",
      "[436]\ttrain's binary_logloss: 0.0563979\n",
      "[437]\ttrain's binary_logloss: 0.056224\n",
      "[438]\ttrain's binary_logloss: 0.0560582\n",
      "[439]\ttrain's binary_logloss: 0.0559133\n",
      "[440]\ttrain's binary_logloss: 0.0557307\n",
      "[441]\ttrain's binary_logloss: 0.055639\n",
      "[442]\ttrain's binary_logloss: 0.0554478\n",
      "[443]\ttrain's binary_logloss: 0.0553049\n",
      "[444]\ttrain's binary_logloss: 0.0551379\n",
      "[445]\ttrain's binary_logloss: 0.0549936\n",
      "[446]\ttrain's binary_logloss: 0.0548406\n",
      "[447]\ttrain's binary_logloss: 0.0546784\n",
      "[448]\ttrain's binary_logloss: 0.0545747\n",
      "[449]\ttrain's binary_logloss: 0.0544377\n",
      "[450]\ttrain's binary_logloss: 0.054326\n",
      "[451]\ttrain's binary_logloss: 0.0541696\n",
      "[452]\ttrain's binary_logloss: 0.0540874\n",
      "[453]\ttrain's binary_logloss: 0.0539605\n",
      "[454]\ttrain's binary_logloss: 0.0538119\n",
      "[455]\ttrain's binary_logloss: 0.0536672\n",
      "[456]\ttrain's binary_logloss: 0.0535799\n",
      "[457]\ttrain's binary_logloss: 0.0533833\n",
      "[458]\ttrain's binary_logloss: 0.0532557\n",
      "[459]\ttrain's binary_logloss: 0.0531591\n",
      "[460]\ttrain's binary_logloss: 0.0529716\n",
      "[461]\ttrain's binary_logloss: 0.0528433\n",
      "[462]\ttrain's binary_logloss: 0.0527358\n",
      "[463]\ttrain's binary_logloss: 0.0526425\n",
      "[464]\ttrain's binary_logloss: 0.0524576\n",
      "[465]\ttrain's binary_logloss: 0.0523841\n",
      "[466]\ttrain's binary_logloss: 0.0522507\n",
      "[467]\ttrain's binary_logloss: 0.0521395\n",
      "[468]\ttrain's binary_logloss: 0.051896\n",
      "[469]\ttrain's binary_logloss: 0.0517641\n",
      "[470]\ttrain's binary_logloss: 0.0516128\n",
      "[471]\ttrain's binary_logloss: 0.0514234\n",
      "[472]\ttrain's binary_logloss: 0.0512009\n",
      "[473]\ttrain's binary_logloss: 0.0510577\n",
      "[474]\ttrain's binary_logloss: 0.0509314\n",
      "[475]\ttrain's binary_logloss: 0.0507913\n",
      "[476]\ttrain's binary_logloss: 0.0507249\n",
      "[477]\ttrain's binary_logloss: 0.0505905\n",
      "[478]\ttrain's binary_logloss: 0.0504886\n",
      "[479]\ttrain's binary_logloss: 0.0503968\n",
      "[480]\ttrain's binary_logloss: 0.0501881\n",
      "[481]\ttrain's binary_logloss: 0.0500122\n",
      "[482]\ttrain's binary_logloss: 0.0497888\n",
      "[483]\ttrain's binary_logloss: 0.0496567\n",
      "[484]\ttrain's binary_logloss: 0.0495297\n",
      "[485]\ttrain's binary_logloss: 0.0493861\n",
      "[486]\ttrain's binary_logloss: 0.0492679\n",
      "[487]\ttrain's binary_logloss: 0.0491456\n",
      "[488]\ttrain's binary_logloss: 0.048953\n",
      "[489]\ttrain's binary_logloss: 0.0488285\n",
      "[490]\ttrain's binary_logloss: 0.0486891\n",
      "[491]\ttrain's binary_logloss: 0.0486347\n",
      "[492]\ttrain's binary_logloss: 0.0485155\n",
      "[493]\ttrain's binary_logloss: 0.0482789\n",
      "[494]\ttrain's binary_logloss: 0.0481425\n",
      "[495]\ttrain's binary_logloss: 0.047983\n",
      "[496]\ttrain's binary_logloss: 0.0478556\n",
      "[497]\ttrain's binary_logloss: 0.0476813\n",
      "[498]\ttrain's binary_logloss: 0.0475647\n",
      "[499]\ttrain's binary_logloss: 0.0475025\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.0474035\n",
      "[0]\ttest-logloss:0.48809\n",
      "[1]\ttest-logloss:0.44679\n",
      "[2]\ttest-logloss:0.42412\n",
      "[3]\ttest-logloss:0.44016\n",
      "[4]\ttest-logloss:0.44331\n",
      "[5]\ttest-logloss:0.44183\n",
      "[6]\ttest-logloss:0.46534\n",
      "[7]\ttest-logloss:0.46678\n",
      "[8]\ttest-logloss:0.47348\n",
      "[9]\ttest-logloss:0.46493\n",
      "[10]\ttest-logloss:0.46420\n",
      "[11]\ttest-logloss:0.45894\n",
      "[12]\ttest-logloss:0.46860\n",
      "[13]\ttest-logloss:0.46470\n",
      "[14]\ttest-logloss:0.45878\n",
      "[15]\ttest-logloss:0.45910\n",
      "[16]\ttest-logloss:0.46146\n",
      "[17]\ttest-logloss:0.47669\n",
      "[18]\ttest-logloss:0.47311\n",
      "[19]\ttest-logloss:0.47043\n",
      "[20]\ttest-logloss:0.48647\n",
      "[21]\ttest-logloss:0.48392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM accuracy = 0.79\n",
      "LightGBM F1-score = 0.78\n",
      "LightGBM Precision = 0.80\n",
      "XGboost accuracy = 0.77\n",
      "XGboost F1-score = 0.76\n",
      "XGboost Precision = 0.78\n",
      "Logistic Regression accuracy = 0.67\n",
      "Logistic Regression F1-score = 0.68\n",
      "Logistic Regression Precision = 0.65\n"
     ]
    }
   ],
   "source": [
    "# ライブラリのインポート\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb  #lightGBMを入れる\n",
    "import xgboost as xgb  #XGboostを入れる\n",
    "from sklearn.linear_model import LogisticRegression  # ロジスティック回帰を入れる\n",
    "\n",
    "import shap\n",
    "\n",
    "# データの読み込み\n",
    "df = pd.read_excel('lightGBM_data_standard.xlsx')\n",
    "df_lr = pd.read_excel('補完データ_test07.xlsx') #　ロジスティック回帰のデータ読み込み\n",
    "\n",
    "# カテゴリ変数のデータ型を変換\n",
    "cat_cols = ['FBS', 'HbA1c', 'US', 'HbA1c_NGSP']\n",
    "df[cat_cols] = df[cat_cols].astype(str)\n",
    "df_lr[cat_cols] = df_lr[cat_cols].astype(str)\n",
    "\n",
    "\n",
    "# ラベルエンコーディングを実行\n",
    "le = LabelEncoder()\n",
    "df[cat_cols] = df[cat_cols].apply(le.fit_transform)\n",
    "df_lr[cat_cols] = df_lr[cat_cols].apply(le.fit_transform)\n",
    "\n",
    "\n",
    "# 特徴量とターゲットに分割\n",
    "X = df.drop('T2db', axis=1)\n",
    "y = df['T2db']\n",
    "\n",
    "X_lr = df_lr.drop('T2db', axis=1)\n",
    "y_lr = df_lr['T2db']\n",
    "\n",
    "# 特定の列を削除\n",
    "# df = df.drop(['TG', 'HDL', 'LDL', 'GOT', 'GPT', 'γ_GT', 'Ht', 'Hb', 'RBC', 'chewing', 'Medication1_Blood Pressure', 'Time of blood collection _after meal', 'Medication2_Blood Sugar', 'Eating style3_midnight snack', 'One-year weight change', 'HbA1c', 'FBS', 'US', 'HbA1c_NGSP'], axis=1)\n",
    "\n",
    "# 削除した結果を反映した特徴量を再作成\n",
    "# X = df.drop('T2db', axis=1)\n",
    "\n",
    "# アンダーサンプリング\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "X_resampled_lr, y_resampled_lr = rus.fit_resample(X_lr, y_lr)\n",
    "\n",
    "# バギングによるモデルの学習と評価\n",
    "# lightGBM\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []  # 適合率を格納するリスト\n",
    "confusion_matrices = []\n",
    "\n",
    "# XGboost\n",
    "accuracy_scores_xgb = []\n",
    "f1_scores_xgb = []\n",
    "precision_scores_xgb = []  # 適合率を格納するリスト\n",
    "confusion_matrices_xgb = []\n",
    "\n",
    "# ロジスティック回帰\n",
    "accuracy_scores_lr = []\n",
    "f1_scores_lr = []\n",
    "precision_scores_lr = []  # 適合率を格納するリスト\n",
    "confusion_matrices_lr = []\n",
    "auc_scores_lr = []\n",
    "\n",
    "n_estimators = 10  # バギングの回数\n",
    "\n",
    "for _ in range(n_estimators):\n",
    "    # 学習データとテストデータに分割\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, shuffle=True, stratify=y_resampled, random_state=0)\n",
    "    print('X_trainの形状：', X_train.shape, ' y_trainの形状：', y_train.shape, ' X_testの形状：', X_test.shape, ' y_testの形状：', y_test.shape)\n",
    "    \n",
    "    # 学習データとテストデータに分割（ロジスティック回帰）\n",
    "    X_train_lr, X_test_lr, y_train_lr, y_test_lr = train_test_split(X_resampled_lr, y_resampled_lr, test_size=0.3, shuffle=True, stratify=y_resampled, random_state=0)\n",
    "\n",
    "    # LightGBM用のデータセットを作成\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "\n",
    "    # xgboost用のデータセットを作成\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    # ハイパーパラメータの設定\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'num_leaves': 5,\n",
    "        'seed': 0,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "\n",
    "    params_xgb = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'max_depth': 2,\n",
    "        'learning_rate': 0.8,\n",
    "        'base_score': 0.5,\n",
    "        'min_split_loss': 0,\n",
    "        'reg_lambda': 0,\n",
    "        'reg_alpha': 0,\n",
    "        'seed': 0,\n",
    "    }\n",
    "\n",
    "    # LightGBMモデルの学習\n",
    "    model = lgb.train(params,\n",
    "                      lgb_train,\n",
    "                      num_boost_round=500,\n",
    "                      valid_sets=[lgb_train],\n",
    "                      valid_names=['train'],\n",
    "                      early_stopping_rounds=20)\n",
    "\n",
    "    # xgboostモデルの学習\n",
    "    model_xgb = xgb.train(params_xgb,\n",
    "                          dtrain,\n",
    "                          num_boost_round=500,\n",
    "                          early_stopping_rounds=20,\n",
    "                          evals=[(dtest, 'test')])\n",
    "    \n",
    "    # ロジスティック回帰の学習\n",
    "    model_lr = LogisticRegression()\n",
    "    model_lr.fit(X_train_lr, y_train_lr)\n",
    "    \n",
    "\n",
    "    # テストデータの予測と評価(lightGBM)\n",
    "    y_test_pred_proba = model.predict(X_test)  # ラベル1の確率\n",
    "    y_test_pred = np.round(y_test_pred_proba)  # 確率をラベル0 or 1に変換\n",
    "    ac_score = accuracy_score(y_test, y_test_pred)\n",
    "    f1 = f1_score(y_test, y_test_pred)\n",
    "    precision = precision_score(y_test, y_test_pred)  # 適合率の計算\n",
    "\n",
    "    # 混同行列(lightGBM)\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 20})\n",
    "    plt.xlabel('pred')\n",
    "    plt.ylabel('label')\n",
    "    plt.savefig('confusion_matrix.png', dpi=300)\n",
    "    plt.close()\n",
    "    accuracy_scores.append(ac_score)\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)  # 適合率\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "    # XGboostモデルのテストデータの予測と評価\n",
    "    y_test_pred_proba_xgb = model_xgb.predict(dtest)  # ラベル1の確率\n",
    "    y_test_pred_xgb = np.round(y_test_pred_proba_xgb)  # 確率をラベル0 or 1に変換\n",
    "    ac_score_xgb = accuracy_score(y_test, y_test_pred_xgb)\n",
    "    f1_xgb = f1_score(y_test, y_test_pred_xgb)\n",
    "    precision_xgb = precision_score(y_test, y_test_pred_xgb)  # 適合率の計算\n",
    "    \n",
    "    # 混同行列(XGboost)\n",
    "    cm_xgb = confusion_matrix(y_test, y_test_pred_xgb)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 20})\n",
    "    plt.xlabel('pred')\n",
    "    plt.ylabel('label')\n",
    "    plt.savefig('confusion_matrix_xgb.png', dpi=300)\n",
    "    plt.close()\n",
    "    accuracy_scores_xgb.append(ac_score_xgb)\n",
    "    f1_scores_xgb.append(f1_xgb)\n",
    "    precision_scores_xgb.append(precision_xgb)  # 適合率\n",
    "    confusion_matrices_xgb.append(cm_xgb)\n",
    "    \n",
    "    \n",
    "    #ロジスティック回帰による予測と評価\n",
    "    y_test_pred_proba_lr = model.predict(X_test_lr)  # ラベル1の確率\n",
    "    y_test_pred_lr = np.round(y_test_pred_proba_lr)  # 確率をラベル0 or 1に変換\n",
    "    ac_score_lr = accuracy_score(y_test_lr, y_test_pred_lr)\n",
    "    f1_lr = f1_score(y_test_lr, y_test_pred_lr)\n",
    "    precision_lr = precision_score(y_test_lr, y_test_pred_lr)  # 適合率の計算\n",
    "\n",
    "    # 混同行列(ロジスティック回帰)\n",
    "    cm_lr = confusion_matrix(y_test_lr, y_test_pred_lr)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 20})\n",
    "    plt.xlabel('pred')\n",
    "    plt.ylabel('label')\n",
    "    plt.savefig('confusion_matrix_lr.png', dpi=300)\n",
    "    plt.close()\n",
    "    accuracy_scores_lr.append(ac_score_lr)\n",
    "    f1_scores_lr.append(f1_lr)\n",
    "    precision_scores_lr.append(precision_lr)  # 適合率\n",
    "    confusion_matrices_lr.append(cm_lr)\n",
    "    \n",
    "\n",
    "# 結果の表示\n",
    "print('LightGBM accuracy = %.2f' % np.mean(accuracy_scores))\n",
    "print('LightGBM F1-score = %.2f' % np.mean(f1_scores))\n",
    "print('LightGBM Precision = %.2f' % np.mean(precision_scores))\n",
    "# print('LightGBM AUC = %.2f' % np.mean(auc_scores))\n",
    "\n",
    "print('XGboost accuracy = %.2f' % np.mean(accuracy_scores_xgb))\n",
    "print('XGboost F1-score = %.2f' % np.mean(f1_scores_xgb))\n",
    "print('XGboost Precision = %.2f' % np.mean(precision_scores_xgb))\n",
    "# print('XGboost AUC = %.2f' % np.mean(auc_scores_xgb))\n",
    "\n",
    "print('Logistic Regression accuracy = %.2f' % np.mean(accuracy_scores_lr))\n",
    "print('Logistic Regression F1-score = %.2f' % np.mean(f1_scores_lr))\n",
    "print('Logistic Regression Precision = %.2f' % np.mean(precision_scores_lr))\n",
    "# print('Logistic Regression AUC = %.2f' % np.mean(auc_scores_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db8cbff-f784-4495-8613-05a81bfab835",
   "metadata": {},
   "source": [
    "## 血液データ削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73dd10e3-ceec-4511-9ec8-35395adaf6db",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trainの形状： (646, 24)  y_trainの形状： (646,)  X_testの形状： (278, 24)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.662906\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.638297\n",
      "[3]\ttrain's binary_logloss: 0.617479\n",
      "[4]\ttrain's binary_logloss: 0.600501\n",
      "[5]\ttrain's binary_logloss: 0.585878\n",
      "[6]\ttrain's binary_logloss: 0.573603\n",
      "[7]\ttrain's binary_logloss: 0.562965\n",
      "[8]\ttrain's binary_logloss: 0.553485\n",
      "[9]\ttrain's binary_logloss: 0.545568\n",
      "[10]\ttrain's binary_logloss: 0.538341\n",
      "[11]\ttrain's binary_logloss: 0.53218\n",
      "[12]\ttrain's binary_logloss: 0.526888\n",
      "[13]\ttrain's binary_logloss: 0.521507\n",
      "[14]\ttrain's binary_logloss: 0.516283\n",
      "[15]\ttrain's binary_logloss: 0.511686\n",
      "[16]\ttrain's binary_logloss: 0.507458\n",
      "[17]\ttrain's binary_logloss: 0.502668\n",
      "[18]\ttrain's binary_logloss: 0.498687\n",
      "[19]\ttrain's binary_logloss: 0.494656\n",
      "[20]\ttrain's binary_logloss: 0.491561\n",
      "[21]\ttrain's binary_logloss: 0.488351\n",
      "[22]\ttrain's binary_logloss: 0.485573\n",
      "[23]\ttrain's binary_logloss: 0.482171\n",
      "[24]\ttrain's binary_logloss: 0.479149\n",
      "[25]\ttrain's binary_logloss: 0.476664\n",
      "[26]\ttrain's binary_logloss: 0.473929\n",
      "[27]\ttrain's binary_logloss: 0.471448\n",
      "[28]\ttrain's binary_logloss: 0.469294\n",
      "[29]\ttrain's binary_logloss: 0.466646\n",
      "[30]\ttrain's binary_logloss: 0.463765\n",
      "[31]\ttrain's binary_logloss: 0.461489\n",
      "[32]\ttrain's binary_logloss: 0.45924\n",
      "[33]\ttrain's binary_logloss: 0.456848\n",
      "[34]\ttrain's binary_logloss: 0.454888\n",
      "[35]\ttrain's binary_logloss: 0.452506\n",
      "[36]\ttrain's binary_logloss: 0.450764\n",
      "[37]\ttrain's binary_logloss: 0.448826\n",
      "[38]\ttrain's binary_logloss: 0.446645\n",
      "[39]\ttrain's binary_logloss: 0.444878\n",
      "[40]\ttrain's binary_logloss: 0.44312\n",
      "[41]\ttrain's binary_logloss: 0.441225\n",
      "[42]\ttrain's binary_logloss: 0.43862\n",
      "[43]\ttrain's binary_logloss: 0.43714\n",
      "[44]\ttrain's binary_logloss: 0.435454\n",
      "[45]\ttrain's binary_logloss: 0.433442\n",
      "[46]\ttrain's binary_logloss: 0.431905\n",
      "[47]\ttrain's binary_logloss: 0.430126\n",
      "[48]\ttrain's binary_logloss: 0.428234\n",
      "[49]\ttrain's binary_logloss: 0.42696\n",
      "[50]\ttrain's binary_logloss: 0.424765\n",
      "[51]\ttrain's binary_logloss: 0.423088\n",
      "[52]\ttrain's binary_logloss: 0.421902\n",
      "[53]\ttrain's binary_logloss: 0.420318\n",
      "[54]\ttrain's binary_logloss: 0.418909\n",
      "[55]\ttrain's binary_logloss: 0.417007\n",
      "[56]\ttrain's binary_logloss: 0.415208\n",
      "[57]\ttrain's binary_logloss: 0.413514\n",
      "[58]\ttrain's binary_logloss: 0.412293\n",
      "[59]\ttrain's binary_logloss: 0.411102\n",
      "[60]\ttrain's binary_logloss: 0.40967\n",
      "[61]\ttrain's binary_logloss: 0.407243\n",
      "[62]\ttrain's binary_logloss: 0.40599\n",
      "[63]\ttrain's binary_logloss: 0.404919\n",
      "[64]\ttrain's binary_logloss: 0.403409\n",
      "[65]\ttrain's binary_logloss: 0.402214\n",
      "[66]\ttrain's binary_logloss: 0.400646\n",
      "[67]\ttrain's binary_logloss: 0.398702\n",
      "[68]\ttrain's binary_logloss: 0.397395\n",
      "[69]\ttrain's binary_logloss: 0.395586\n",
      "[70]\ttrain's binary_logloss: 0.393765\n",
      "[71]\ttrain's binary_logloss: 0.392805\n",
      "[72]\ttrain's binary_logloss: 0.391712\n",
      "[73]\ttrain's binary_logloss: 0.390657\n",
      "[74]\ttrain's binary_logloss: 0.388989\n",
      "[75]\ttrain's binary_logloss: 0.38764\n",
      "[76]\ttrain's binary_logloss: 0.386751\n",
      "[77]\ttrain's binary_logloss: 0.384699\n",
      "[78]\ttrain's binary_logloss: 0.382528\n",
      "[79]\ttrain's binary_logloss: 0.381192\n",
      "[80]\ttrain's binary_logloss: 0.380259\n",
      "[81]\ttrain's binary_logloss: 0.378934\n",
      "[82]\ttrain's binary_logloss: 0.377976\n",
      "[83]\ttrain's binary_logloss: 0.376874\n",
      "[84]\ttrain's binary_logloss: 0.375969\n",
      "[85]\ttrain's binary_logloss: 0.374852\n",
      "[86]\ttrain's binary_logloss: 0.373135\n",
      "[87]\ttrain's binary_logloss: 0.371574\n",
      "[88]\ttrain's binary_logloss: 0.370593\n",
      "[89]\ttrain's binary_logloss: 0.369757\n",
      "[90]\ttrain's binary_logloss: 0.368328\n",
      "[91]\ttrain's binary_logloss: 0.367325\n",
      "[92]\ttrain's binary_logloss: 0.36639\n",
      "[93]\ttrain's binary_logloss: 0.365162\n",
      "[94]\ttrain's binary_logloss: 0.364408\n",
      "[95]\ttrain's binary_logloss: 0.362858\n",
      "[96]\ttrain's binary_logloss: 0.360926\n",
      "[97]\ttrain's binary_logloss: 0.35941\n",
      "[98]\ttrain's binary_logloss: 0.358207\n",
      "[99]\ttrain's binary_logloss: 0.357537\n",
      "[100]\ttrain's binary_logloss: 0.356465\n",
      "[101]\ttrain's binary_logloss: 0.355643\n",
      "[102]\ttrain's binary_logloss: 0.354476\n",
      "[103]\ttrain's binary_logloss: 0.353127\n",
      "[104]\ttrain's binary_logloss: 0.352091\n",
      "[105]\ttrain's binary_logloss: 0.350762\n",
      "[106]\ttrain's binary_logloss: 0.349704\n",
      "[107]\ttrain's binary_logloss: 0.348859\n",
      "[108]\ttrain's binary_logloss: 0.347836\n",
      "[109]\ttrain's binary_logloss: 0.346703\n",
      "[110]\ttrain's binary_logloss: 0.345726\n",
      "[111]\ttrain's binary_logloss: 0.344929\n",
      "[112]\ttrain's binary_logloss: 0.344232\n",
      "[113]\ttrain's binary_logloss: 0.343464\n",
      "[114]\ttrain's binary_logloss: 0.342828\n",
      "[115]\ttrain's binary_logloss: 0.341282\n",
      "[116]\ttrain's binary_logloss: 0.339423\n",
      "[117]\ttrain's binary_logloss: 0.338747\n",
      "[118]\ttrain's binary_logloss: 0.337414\n",
      "[119]\ttrain's binary_logloss: 0.336814\n",
      "[120]\ttrain's binary_logloss: 0.335958\n",
      "[121]\ttrain's binary_logloss: 0.335146\n",
      "[122]\ttrain's binary_logloss: 0.333571\n",
      "[123]\ttrain's binary_logloss: 0.332564\n",
      "[124]\ttrain's binary_logloss: 0.331984\n",
      "[125]\ttrain's binary_logloss: 0.331224\n",
      "[126]\ttrain's binary_logloss: 0.33044\n",
      "[127]\ttrain's binary_logloss: 0.32974\n",
      "[128]\ttrain's binary_logloss: 0.328766\n",
      "[129]\ttrain's binary_logloss: 0.327988\n",
      "[130]\ttrain's binary_logloss: 0.327226\n",
      "[131]\ttrain's binary_logloss: 0.326293\n",
      "[132]\ttrain's binary_logloss: 0.325219\n",
      "[133]\ttrain's binary_logloss: 0.323711\n",
      "[134]\ttrain's binary_logloss: 0.323081\n",
      "[135]\ttrain's binary_logloss: 0.321718\n",
      "[136]\ttrain's binary_logloss: 0.321142\n",
      "[137]\ttrain's binary_logloss: 0.320328\n",
      "[138]\ttrain's binary_logloss: 0.319378\n",
      "[139]\ttrain's binary_logloss: 0.318822\n",
      "[140]\ttrain's binary_logloss: 0.317859\n",
      "[141]\ttrain's binary_logloss: 0.31729\n",
      "[142]\ttrain's binary_logloss: 0.316314\n",
      "[143]\ttrain's binary_logloss: 0.315594\n",
      "[144]\ttrain's binary_logloss: 0.314675\n",
      "[145]\ttrain's binary_logloss: 0.313575\n",
      "[146]\ttrain's binary_logloss: 0.312904\n",
      "[147]\ttrain's binary_logloss: 0.31207\n",
      "[148]\ttrain's binary_logloss: 0.311461\n",
      "[149]\ttrain's binary_logloss: 0.310867\n",
      "[150]\ttrain's binary_logloss: 0.309872\n",
      "[151]\ttrain's binary_logloss: 0.309071\n",
      "[152]\ttrain's binary_logloss: 0.308102\n",
      "[153]\ttrain's binary_logloss: 0.307219\n",
      "[154]\ttrain's binary_logloss: 0.306427\n",
      "[155]\ttrain's binary_logloss: 0.305771\n",
      "[156]\ttrain's binary_logloss: 0.304692\n",
      "[157]\ttrain's binary_logloss: 0.303829\n",
      "[158]\ttrain's binary_logloss: 0.302958\n",
      "[159]\ttrain's binary_logloss: 0.302515\n",
      "[160]\ttrain's binary_logloss: 0.301781\n",
      "[161]\ttrain's binary_logloss: 0.301218\n",
      "[162]\ttrain's binary_logloss: 0.30076\n",
      "[163]\ttrain's binary_logloss: 0.299788\n",
      "[164]\ttrain's binary_logloss: 0.299011\n",
      "[165]\ttrain's binary_logloss: 0.298209\n",
      "[166]\ttrain's binary_logloss: 0.297688\n",
      "[167]\ttrain's binary_logloss: 0.296928\n",
      "[168]\ttrain's binary_logloss: 0.296486\n",
      "[169]\ttrain's binary_logloss: 0.295689\n",
      "[170]\ttrain's binary_logloss: 0.295135\n",
      "[171]\ttrain's binary_logloss: 0.293992\n",
      "[172]\ttrain's binary_logloss: 0.293065\n",
      "[173]\ttrain's binary_logloss: 0.292238\n",
      "[174]\ttrain's binary_logloss: 0.291605\n",
      "[175]\ttrain's binary_logloss: 0.290909\n",
      "[176]\ttrain's binary_logloss: 0.290163\n",
      "[177]\ttrain's binary_logloss: 0.289679\n",
      "[178]\ttrain's binary_logloss: 0.288876\n",
      "[179]\ttrain's binary_logloss: 0.287826\n",
      "[180]\ttrain's binary_logloss: 0.286768\n",
      "[181]\ttrain's binary_logloss: 0.2861\n",
      "[182]\ttrain's binary_logloss: 0.285568\n",
      "[183]\ttrain's binary_logloss: 0.285031\n",
      "[184]\ttrain's binary_logloss: 0.284179\n",
      "[185]\ttrain's binary_logloss: 0.28348\n",
      "[186]\ttrain's binary_logloss: 0.282782\n",
      "[187]\ttrain's binary_logloss: 0.282188\n",
      "[188]\ttrain's binary_logloss: 0.281734\n",
      "[189]\ttrain's binary_logloss: 0.28121\n",
      "[190]\ttrain's binary_logloss: 0.280441\n",
      "[191]\ttrain's binary_logloss: 0.279909\n",
      "[192]\ttrain's binary_logloss: 0.27899\n",
      "[193]\ttrain's binary_logloss: 0.278616\n",
      "[194]\ttrain's binary_logloss: 0.278\n",
      "[195]\ttrain's binary_logloss: 0.277302\n",
      "[196]\ttrain's binary_logloss: 0.276416\n",
      "[197]\ttrain's binary_logloss: 0.275802\n",
      "[198]\ttrain's binary_logloss: 0.275207\n",
      "[199]\ttrain's binary_logloss: 0.274815\n",
      "[200]\ttrain's binary_logloss: 0.274167\n",
      "[201]\ttrain's binary_logloss: 0.273716\n",
      "[202]\ttrain's binary_logloss: 0.272815\n",
      "[203]\ttrain's binary_logloss: 0.272177\n",
      "[204]\ttrain's binary_logloss: 0.271436\n",
      "[205]\ttrain's binary_logloss: 0.270776\n",
      "[206]\ttrain's binary_logloss: 0.270229\n",
      "[207]\ttrain's binary_logloss: 0.269779\n",
      "[208]\ttrain's binary_logloss: 0.269004\n",
      "[209]\ttrain's binary_logloss: 0.267872\n",
      "[210]\ttrain's binary_logloss: 0.267196\n",
      "[211]\ttrain's binary_logloss: 0.266571\n",
      "[212]\ttrain's binary_logloss: 0.26598\n",
      "[213]\ttrain's binary_logloss: 0.265654\n",
      "[214]\ttrain's binary_logloss: 0.264831\n",
      "[215]\ttrain's binary_logloss: 0.263983\n",
      "[216]\ttrain's binary_logloss: 0.262875\n",
      "[217]\ttrain's binary_logloss: 0.26229\n",
      "[218]\ttrain's binary_logloss: 0.26172\n",
      "[219]\ttrain's binary_logloss: 0.260831\n",
      "[220]\ttrain's binary_logloss: 0.260221\n",
      "[221]\ttrain's binary_logloss: 0.259489\n",
      "[222]\ttrain's binary_logloss: 0.258778\n",
      "[223]\ttrain's binary_logloss: 0.25811\n",
      "[224]\ttrain's binary_logloss: 0.257694\n",
      "[225]\ttrain's binary_logloss: 0.257083\n",
      "[226]\ttrain's binary_logloss: 0.256652\n",
      "[227]\ttrain's binary_logloss: 0.255637\n",
      "[228]\ttrain's binary_logloss: 0.255275\n",
      "[229]\ttrain's binary_logloss: 0.25436\n",
      "[230]\ttrain's binary_logloss: 0.253792\n",
      "[231]\ttrain's binary_logloss: 0.253338\n",
      "[232]\ttrain's binary_logloss: 0.252984\n",
      "[233]\ttrain's binary_logloss: 0.252331\n",
      "[234]\ttrain's binary_logloss: 0.251858\n",
      "[235]\ttrain's binary_logloss: 0.251312\n",
      "[236]\ttrain's binary_logloss: 0.250489\n",
      "[237]\ttrain's binary_logloss: 0.250099\n",
      "[238]\ttrain's binary_logloss: 0.249802\n",
      "[239]\ttrain's binary_logloss: 0.249211\n",
      "[240]\ttrain's binary_logloss: 0.24873\n",
      "[241]\ttrain's binary_logloss: 0.248368\n",
      "[242]\ttrain's binary_logloss: 0.247962\n",
      "[243]\ttrain's binary_logloss: 0.247223\n",
      "[244]\ttrain's binary_logloss: 0.246523\n",
      "[245]\ttrain's binary_logloss: 0.245704\n",
      "[246]\ttrain's binary_logloss: 0.245339\n",
      "[247]\ttrain's binary_logloss: 0.244785\n",
      "[248]\ttrain's binary_logloss: 0.244489\n",
      "[249]\ttrain's binary_logloss: 0.244123\n",
      "[250]\ttrain's binary_logloss: 0.243491\n",
      "[251]\ttrain's binary_logloss: 0.242877\n",
      "[252]\ttrain's binary_logloss: 0.24253\n",
      "[253]\ttrain's binary_logloss: 0.242084\n",
      "[254]\ttrain's binary_logloss: 0.241631\n",
      "[255]\ttrain's binary_logloss: 0.241128\n",
      "[256]\ttrain's binary_logloss: 0.240535\n",
      "[257]\ttrain's binary_logloss: 0.240056\n",
      "[258]\ttrain's binary_logloss: 0.23977\n",
      "[259]\ttrain's binary_logloss: 0.239386\n",
      "[260]\ttrain's binary_logloss: 0.238696\n",
      "[261]\ttrain's binary_logloss: 0.238307\n",
      "[262]\ttrain's binary_logloss: 0.237724\n",
      "[263]\ttrain's binary_logloss: 0.23714\n",
      "[264]\ttrain's binary_logloss: 0.236582\n",
      "[265]\ttrain's binary_logloss: 0.236232\n",
      "[266]\ttrain's binary_logloss: 0.235868\n",
      "[267]\ttrain's binary_logloss: 0.235129\n",
      "[268]\ttrain's binary_logloss: 0.234585\n",
      "[269]\ttrain's binary_logloss: 0.23423\n",
      "[270]\ttrain's binary_logloss: 0.233736\n",
      "[271]\ttrain's binary_logloss: 0.233189\n",
      "[272]\ttrain's binary_logloss: 0.232941\n",
      "[273]\ttrain's binary_logloss: 0.23242\n",
      "[274]\ttrain's binary_logloss: 0.231679\n",
      "[275]\ttrain's binary_logloss: 0.231218\n",
      "[276]\ttrain's binary_logloss: 0.23099\n",
      "[277]\ttrain's binary_logloss: 0.230563\n",
      "[278]\ttrain's binary_logloss: 0.229942\n",
      "[279]\ttrain's binary_logloss: 0.229532\n",
      "[280]\ttrain's binary_logloss: 0.22913\n",
      "[281]\ttrain's binary_logloss: 0.228747\n",
      "[282]\ttrain's binary_logloss: 0.227907\n",
      "[283]\ttrain's binary_logloss: 0.227236\n",
      "[284]\ttrain's binary_logloss: 0.226918\n",
      "[285]\ttrain's binary_logloss: 0.226609\n",
      "[286]\ttrain's binary_logloss: 0.226241\n",
      "[287]\ttrain's binary_logloss: 0.2259\n",
      "[288]\ttrain's binary_logloss: 0.225565\n",
      "[289]\ttrain's binary_logloss: 0.225198\n",
      "[290]\ttrain's binary_logloss: 0.224945\n",
      "[291]\ttrain's binary_logloss: 0.224465\n",
      "[292]\ttrain's binary_logloss: 0.224152\n",
      "[293]\ttrain's binary_logloss: 0.223747\n",
      "[294]\ttrain's binary_logloss: 0.223332\n",
      "[295]\ttrain's binary_logloss: 0.223046\n",
      "[296]\ttrain's binary_logloss: 0.222285\n",
      "[297]\ttrain's binary_logloss: 0.221907\n",
      "[298]\ttrain's binary_logloss: 0.221567\n",
      "[299]\ttrain's binary_logloss: 0.221273\n",
      "[300]\ttrain's binary_logloss: 0.220611\n",
      "[301]\ttrain's binary_logloss: 0.220213\n",
      "[302]\ttrain's binary_logloss: 0.21992\n",
      "[303]\ttrain's binary_logloss: 0.219641\n",
      "[304]\ttrain's binary_logloss: 0.219161\n",
      "[305]\ttrain's binary_logloss: 0.218723\n",
      "[306]\ttrain's binary_logloss: 0.218309\n",
      "[307]\ttrain's binary_logloss: 0.21755\n",
      "[308]\ttrain's binary_logloss: 0.217223\n",
      "[309]\ttrain's binary_logloss: 0.216722\n",
      "[310]\ttrain's binary_logloss: 0.216242\n",
      "[311]\ttrain's binary_logloss: 0.216004\n",
      "[312]\ttrain's binary_logloss: 0.215234\n",
      "[313]\ttrain's binary_logloss: 0.214731\n",
      "[314]\ttrain's binary_logloss: 0.214299\n",
      "[315]\ttrain's binary_logloss: 0.213988\n",
      "[316]\ttrain's binary_logloss: 0.213743\n",
      "[317]\ttrain's binary_logloss: 0.21342\n",
      "[318]\ttrain's binary_logloss: 0.212993\n",
      "[319]\ttrain's binary_logloss: 0.212576\n",
      "[320]\ttrain's binary_logloss: 0.21198\n",
      "[321]\ttrain's binary_logloss: 0.211424\n",
      "[322]\ttrain's binary_logloss: 0.21098\n",
      "[323]\ttrain's binary_logloss: 0.210717\n",
      "[324]\ttrain's binary_logloss: 0.210308\n",
      "[325]\ttrain's binary_logloss: 0.209841\n",
      "[326]\ttrain's binary_logloss: 0.208946\n",
      "[327]\ttrain's binary_logloss: 0.208284\n",
      "[328]\ttrain's binary_logloss: 0.207906\n",
      "[329]\ttrain's binary_logloss: 0.207541\n",
      "[330]\ttrain's binary_logloss: 0.207287\n",
      "[331]\ttrain's binary_logloss: 0.206782\n",
      "[332]\ttrain's binary_logloss: 0.206542\n",
      "[333]\ttrain's binary_logloss: 0.205731\n",
      "[334]\ttrain's binary_logloss: 0.20523\n",
      "[335]\ttrain's binary_logloss: 0.204782\n",
      "[336]\ttrain's binary_logloss: 0.204562\n",
      "[337]\ttrain's binary_logloss: 0.204267\n",
      "[338]\ttrain's binary_logloss: 0.204085\n",
      "[339]\ttrain's binary_logloss: 0.203701\n",
      "[340]\ttrain's binary_logloss: 0.203224\n",
      "[341]\ttrain's binary_logloss: 0.202829\n",
      "[342]\ttrain's binary_logloss: 0.202252\n",
      "[343]\ttrain's binary_logloss: 0.201751\n",
      "[344]\ttrain's binary_logloss: 0.201267\n",
      "[345]\ttrain's binary_logloss: 0.200805\n",
      "[346]\ttrain's binary_logloss: 0.200549\n",
      "[347]\ttrain's binary_logloss: 0.200051\n",
      "[348]\ttrain's binary_logloss: 0.199563\n",
      "[349]\ttrain's binary_logloss: 0.199131\n",
      "[350]\ttrain's binary_logloss: 0.198731\n",
      "[351]\ttrain's binary_logloss: 0.1983\n",
      "[352]\ttrain's binary_logloss: 0.197941\n",
      "[353]\ttrain's binary_logloss: 0.197673\n",
      "[354]\ttrain's binary_logloss: 0.197497\n",
      "[355]\ttrain's binary_logloss: 0.197346\n",
      "[356]\ttrain's binary_logloss: 0.196909\n",
      "[357]\ttrain's binary_logloss: 0.196737\n",
      "[358]\ttrain's binary_logloss: 0.196233\n",
      "[359]\ttrain's binary_logloss: 0.195819\n",
      "[360]\ttrain's binary_logloss: 0.195374\n",
      "[361]\ttrain's binary_logloss: 0.194856\n",
      "[362]\ttrain's binary_logloss: 0.194501\n",
      "[363]\ttrain's binary_logloss: 0.194192\n",
      "[364]\ttrain's binary_logloss: 0.193896\n",
      "[365]\ttrain's binary_logloss: 0.193524\n",
      "[366]\ttrain's binary_logloss: 0.193074\n",
      "[367]\ttrain's binary_logloss: 0.192726\n",
      "[368]\ttrain's binary_logloss: 0.192346\n",
      "[369]\ttrain's binary_logloss: 0.19207\n",
      "[370]\ttrain's binary_logloss: 0.191551\n",
      "[371]\ttrain's binary_logloss: 0.19121\n",
      "[372]\ttrain's binary_logloss: 0.190668\n",
      "[373]\ttrain's binary_logloss: 0.190357\n",
      "[374]\ttrain's binary_logloss: 0.189708\n",
      "[375]\ttrain's binary_logloss: 0.189166\n",
      "[376]\ttrain's binary_logloss: 0.188481\n",
      "[377]\ttrain's binary_logloss: 0.187923\n",
      "[378]\ttrain's binary_logloss: 0.187387\n",
      "[379]\ttrain's binary_logloss: 0.186829\n",
      "[380]\ttrain's binary_logloss: 0.186359\n",
      "[381]\ttrain's binary_logloss: 0.186049\n",
      "[382]\ttrain's binary_logloss: 0.185431\n",
      "[383]\ttrain's binary_logloss: 0.184966\n",
      "[384]\ttrain's binary_logloss: 0.184586\n",
      "[385]\ttrain's binary_logloss: 0.183982\n",
      "[386]\ttrain's binary_logloss: 0.183568\n",
      "[387]\ttrain's binary_logloss: 0.183413\n",
      "[388]\ttrain's binary_logloss: 0.182946\n",
      "[389]\ttrain's binary_logloss: 0.182525\n",
      "[390]\ttrain's binary_logloss: 0.181952\n",
      "[391]\ttrain's binary_logloss: 0.181528\n",
      "[392]\ttrain's binary_logloss: 0.18083\n",
      "[393]\ttrain's binary_logloss: 0.180543\n",
      "[394]\ttrain's binary_logloss: 0.180241\n",
      "[395]\ttrain's binary_logloss: 0.179704\n",
      "[396]\ttrain's binary_logloss: 0.179356\n",
      "[397]\ttrain's binary_logloss: 0.179073\n",
      "[398]\ttrain's binary_logloss: 0.178589\n",
      "[399]\ttrain's binary_logloss: 0.178339\n",
      "[400]\ttrain's binary_logloss: 0.17809\n",
      "[401]\ttrain's binary_logloss: 0.177719\n",
      "[402]\ttrain's binary_logloss: 0.177188\n",
      "[403]\ttrain's binary_logloss: 0.176908\n",
      "[404]\ttrain's binary_logloss: 0.176348\n",
      "[405]\ttrain's binary_logloss: 0.176101\n",
      "[406]\ttrain's binary_logloss: 0.175761\n",
      "[407]\ttrain's binary_logloss: 0.175526\n",
      "[408]\ttrain's binary_logloss: 0.175253\n",
      "[409]\ttrain's binary_logloss: 0.174833\n",
      "[410]\ttrain's binary_logloss: 0.174486\n",
      "[411]\ttrain's binary_logloss: 0.174289\n",
      "[412]\ttrain's binary_logloss: 0.173642\n",
      "[413]\ttrain's binary_logloss: 0.173361\n",
      "[414]\ttrain's binary_logloss: 0.172989\n",
      "[415]\ttrain's binary_logloss: 0.172507\n",
      "[416]\ttrain's binary_logloss: 0.17226\n",
      "[417]\ttrain's binary_logloss: 0.171865\n",
      "[418]\ttrain's binary_logloss: 0.171421\n",
      "[419]\ttrain's binary_logloss: 0.171136\n",
      "[420]\ttrain's binary_logloss: 0.170918\n",
      "[421]\ttrain's binary_logloss: 0.170276\n",
      "[422]\ttrain's binary_logloss: 0.169918\n",
      "[423]\ttrain's binary_logloss: 0.169643\n",
      "[424]\ttrain's binary_logloss: 0.169293\n",
      "[425]\ttrain's binary_logloss: 0.169112\n",
      "[426]\ttrain's binary_logloss: 0.16862\n",
      "[427]\ttrain's binary_logloss: 0.168273\n",
      "[428]\ttrain's binary_logloss: 0.167871\n",
      "[429]\ttrain's binary_logloss: 0.167623\n",
      "[430]\ttrain's binary_logloss: 0.167426\n",
      "[431]\ttrain's binary_logloss: 0.166944\n",
      "[432]\ttrain's binary_logloss: 0.166616\n",
      "[433]\ttrain's binary_logloss: 0.166257\n",
      "[434]\ttrain's binary_logloss: 0.166075\n",
      "[435]\ttrain's binary_logloss: 0.165558\n",
      "[436]\ttrain's binary_logloss: 0.165281\n",
      "[437]\ttrain's binary_logloss: 0.165056\n",
      "[438]\ttrain's binary_logloss: 0.164855\n",
      "[439]\ttrain's binary_logloss: 0.164418\n",
      "[440]\ttrain's binary_logloss: 0.163917\n",
      "[441]\ttrain's binary_logloss: 0.163484\n",
      "[442]\ttrain's binary_logloss: 0.163367\n",
      "[443]\ttrain's binary_logloss: 0.163146\n",
      "[444]\ttrain's binary_logloss: 0.162918\n",
      "[445]\ttrain's binary_logloss: 0.1626\n",
      "[446]\ttrain's binary_logloss: 0.162193\n",
      "[447]\ttrain's binary_logloss: 0.16195\n",
      "[448]\ttrain's binary_logloss: 0.161755\n",
      "[449]\ttrain's binary_logloss: 0.16139\n",
      "[450]\ttrain's binary_logloss: 0.16113\n",
      "[451]\ttrain's binary_logloss: 0.160798\n",
      "[452]\ttrain's binary_logloss: 0.160367\n",
      "[453]\ttrain's binary_logloss: 0.160173\n",
      "[454]\ttrain's binary_logloss: 0.160004\n",
      "[455]\ttrain's binary_logloss: 0.159851\n",
      "[456]\ttrain's binary_logloss: 0.15963\n",
      "[457]\ttrain's binary_logloss: 0.159342\n",
      "[458]\ttrain's binary_logloss: 0.158956\n",
      "[459]\ttrain's binary_logloss: 0.158747\n",
      "[460]\ttrain's binary_logloss: 0.158549\n",
      "[461]\ttrain's binary_logloss: 0.158198\n",
      "[462]\ttrain's binary_logloss: 0.157527\n",
      "[463]\ttrain's binary_logloss: 0.157263\n",
      "[464]\ttrain's binary_logloss: 0.157004\n",
      "[465]\ttrain's binary_logloss: 0.156493\n",
      "[466]\ttrain's binary_logloss: 0.156155\n",
      "[467]\ttrain's binary_logloss: 0.156\n",
      "[468]\ttrain's binary_logloss: 0.155591\n",
      "[469]\ttrain's binary_logloss: 0.154938\n",
      "[470]\ttrain's binary_logloss: 0.154755\n",
      "[471]\ttrain's binary_logloss: 0.154591\n",
      "[472]\ttrain's binary_logloss: 0.154373\n",
      "[473]\ttrain's binary_logloss: 0.154156\n",
      "[474]\ttrain's binary_logloss: 0.153797\n",
      "[475]\ttrain's binary_logloss: 0.153479\n",
      "[476]\ttrain's binary_logloss: 0.153004\n",
      "[477]\ttrain's binary_logloss: 0.152814\n",
      "[478]\ttrain's binary_logloss: 0.152484\n",
      "[479]\ttrain's binary_logloss: 0.152381\n",
      "[480]\ttrain's binary_logloss: 0.15209\n",
      "[481]\ttrain's binary_logloss: 0.151521\n",
      "[482]\ttrain's binary_logloss: 0.151195\n",
      "[483]\ttrain's binary_logloss: 0.150919\n",
      "[484]\ttrain's binary_logloss: 0.150498\n",
      "[485]\ttrain's binary_logloss: 0.150235\n",
      "[486]\ttrain's binary_logloss: 0.15008\n",
      "[487]\ttrain's binary_logloss: 0.149875\n",
      "[488]\ttrain's binary_logloss: 0.1497\n",
      "[489]\ttrain's binary_logloss: 0.149427\n",
      "[490]\ttrain's binary_logloss: 0.148995\n",
      "[491]\ttrain's binary_logloss: 0.148707\n",
      "[492]\ttrain's binary_logloss: 0.148535\n",
      "[493]\ttrain's binary_logloss: 0.148291\n",
      "[494]\ttrain's binary_logloss: 0.148023\n",
      "[495]\ttrain's binary_logloss: 0.1476\n",
      "[496]\ttrain's binary_logloss: 0.147413\n",
      "[497]\ttrain's binary_logloss: 0.147097\n",
      "[498]\ttrain's binary_logloss: 0.146752\n",
      "[499]\ttrain's binary_logloss: 0.146375\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "[0]\ttest-logloss:0.59573\n",
      "[1]\ttest-logloss:0.58371\n",
      "[2]\ttest-logloss:0.57642\n",
      "[3]\ttest-logloss:0.58736\n",
      "[4]\ttest-logloss:0.58414\n",
      "[5]\ttest-logloss:0.58967\n",
      "[6]\ttest-logloss:0.59291\n",
      "[7]\ttest-logloss:0.59738\n",
      "[8]\ttest-logloss:0.59849\n",
      "[9]\ttest-logloss:0.59946\n",
      "[10]\ttest-logloss:0.60594\n",
      "[11]\ttest-logloss:0.60589\n",
      "[12]\ttest-logloss:0.60974\n",
      "[13]\ttest-logloss:0.60995\n",
      "[14]\ttest-logloss:0.61244\n",
      "[15]\ttest-logloss:0.61994\n",
      "[16]\ttest-logloss:0.62884\n",
      "[17]\ttest-logloss:0.63393\n",
      "[18]\ttest-logloss:0.63189\n",
      "[19]\ttest-logloss:0.62428\n",
      "[20]\ttest-logloss:0.63861\n",
      "[21]\ttest-logloss:0.63952\n",
      "X_trainの形状： (646, 24)  y_trainの形状： (646,)  X_testの形状： (278, 24)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.662906\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.638297\n",
      "[3]\ttrain's binary_logloss: 0.617479\n",
      "[4]\ttrain's binary_logloss: 0.600501\n",
      "[5]\ttrain's binary_logloss: 0.585878\n",
      "[6]\ttrain's binary_logloss: 0.573603\n",
      "[7]\ttrain's binary_logloss: 0.562965\n",
      "[8]\ttrain's binary_logloss: 0.553485\n",
      "[9]\ttrain's binary_logloss: 0.545568\n",
      "[10]\ttrain's binary_logloss: 0.538341\n",
      "[11]\ttrain's binary_logloss: 0.53218\n",
      "[12]\ttrain's binary_logloss: 0.526888\n",
      "[13]\ttrain's binary_logloss: 0.521507\n",
      "[14]\ttrain's binary_logloss: 0.516283\n",
      "[15]\ttrain's binary_logloss: 0.511686\n",
      "[16]\ttrain's binary_logloss: 0.507458\n",
      "[17]\ttrain's binary_logloss: 0.502668\n",
      "[18]\ttrain's binary_logloss: 0.498687\n",
      "[19]\ttrain's binary_logloss: 0.494656\n",
      "[20]\ttrain's binary_logloss: 0.491561\n",
      "[21]\ttrain's binary_logloss: 0.488351\n",
      "[22]\ttrain's binary_logloss: 0.485573\n",
      "[23]\ttrain's binary_logloss: 0.482171\n",
      "[24]\ttrain's binary_logloss: 0.479149\n",
      "[25]\ttrain's binary_logloss: 0.476664\n",
      "[26]\ttrain's binary_logloss: 0.473929\n",
      "[27]\ttrain's binary_logloss: 0.471448\n",
      "[28]\ttrain's binary_logloss: 0.469294\n",
      "[29]\ttrain's binary_logloss: 0.466646\n",
      "[30]\ttrain's binary_logloss: 0.463765\n",
      "[31]\ttrain's binary_logloss: 0.461489\n",
      "[32]\ttrain's binary_logloss: 0.45924\n",
      "[33]\ttrain's binary_logloss: 0.456848\n",
      "[34]\ttrain's binary_logloss: 0.454888\n",
      "[35]\ttrain's binary_logloss: 0.452506\n",
      "[36]\ttrain's binary_logloss: 0.450764\n",
      "[37]\ttrain's binary_logloss: 0.448826\n",
      "[38]\ttrain's binary_logloss: 0.446645\n",
      "[39]\ttrain's binary_logloss: 0.444878\n",
      "[40]\ttrain's binary_logloss: 0.44312\n",
      "[41]\ttrain's binary_logloss: 0.441225\n",
      "[42]\ttrain's binary_logloss: 0.43862\n",
      "[43]\ttrain's binary_logloss: 0.43714\n",
      "[44]\ttrain's binary_logloss: 0.435454\n",
      "[45]\ttrain's binary_logloss: 0.433442\n",
      "[46]\ttrain's binary_logloss: 0.431905\n",
      "[47]\ttrain's binary_logloss: 0.430126\n",
      "[48]\ttrain's binary_logloss: 0.428234\n",
      "[49]\ttrain's binary_logloss: 0.42696\n",
      "[50]\ttrain's binary_logloss: 0.424765\n",
      "[51]\ttrain's binary_logloss: 0.423088\n",
      "[52]\ttrain's binary_logloss: 0.421902\n",
      "[53]\ttrain's binary_logloss: 0.420318\n",
      "[54]\ttrain's binary_logloss: 0.418909\n",
      "[55]\ttrain's binary_logloss: 0.417007\n",
      "[56]\ttrain's binary_logloss: 0.415208\n",
      "[57]\ttrain's binary_logloss: 0.413514\n",
      "[58]\ttrain's binary_logloss: 0.412293\n",
      "[59]\ttrain's binary_logloss: 0.411102\n",
      "[60]\ttrain's binary_logloss: 0.40967\n",
      "[61]\ttrain's binary_logloss: 0.407243\n",
      "[62]\ttrain's binary_logloss: 0.40599\n",
      "[63]\ttrain's binary_logloss: 0.404919\n",
      "[64]\ttrain's binary_logloss: 0.403409\n",
      "[65]\ttrain's binary_logloss: 0.402214\n",
      "[66]\ttrain's binary_logloss: 0.400646\n",
      "[67]\ttrain's binary_logloss: 0.398702\n",
      "[68]\ttrain's binary_logloss: 0.397395\n",
      "[69]\ttrain's binary_logloss: 0.395586\n",
      "[70]\ttrain's binary_logloss: 0.393765\n",
      "[71]\ttrain's binary_logloss: 0.392805\n",
      "[72]\ttrain's binary_logloss: 0.391712\n",
      "[73]\ttrain's binary_logloss: 0.390657\n",
      "[74]\ttrain's binary_logloss: 0.388989\n",
      "[75]\ttrain's binary_logloss: 0.38764\n",
      "[76]\ttrain's binary_logloss: 0.386751\n",
      "[77]\ttrain's binary_logloss: 0.384699\n",
      "[78]\ttrain's binary_logloss: 0.382528\n",
      "[79]\ttrain's binary_logloss: 0.381192\n",
      "[80]\ttrain's binary_logloss: 0.380259\n",
      "[81]\ttrain's binary_logloss: 0.378934\n",
      "[82]\ttrain's binary_logloss: 0.377976\n",
      "[83]\ttrain's binary_logloss: 0.376874\n",
      "[84]\ttrain's binary_logloss: 0.375969\n",
      "[85]\ttrain's binary_logloss: 0.374852\n",
      "[86]\ttrain's binary_logloss: 0.373135\n",
      "[87]\ttrain's binary_logloss: 0.371574\n",
      "[88]\ttrain's binary_logloss: 0.370593\n",
      "[89]\ttrain's binary_logloss: 0.369757\n",
      "[90]\ttrain's binary_logloss: 0.368328\n",
      "[91]\ttrain's binary_logloss: 0.367325\n",
      "[92]\ttrain's binary_logloss: 0.36639\n",
      "[93]\ttrain's binary_logloss: 0.365162\n",
      "[94]\ttrain's binary_logloss: 0.364408\n",
      "[95]\ttrain's binary_logloss: 0.362858\n",
      "[96]\ttrain's binary_logloss: 0.360926\n",
      "[97]\ttrain's binary_logloss: 0.35941\n",
      "[98]\ttrain's binary_logloss: 0.358207\n",
      "[99]\ttrain's binary_logloss: 0.357537\n",
      "[100]\ttrain's binary_logloss: 0.356465\n",
      "[101]\ttrain's binary_logloss: 0.355643\n",
      "[102]\ttrain's binary_logloss: 0.354476\n",
      "[103]\ttrain's binary_logloss: 0.353127\n",
      "[104]\ttrain's binary_logloss: 0.352091\n",
      "[105]\ttrain's binary_logloss: 0.350762\n",
      "[106]\ttrain's binary_logloss: 0.349704\n",
      "[107]\ttrain's binary_logloss: 0.348859\n",
      "[108]\ttrain's binary_logloss: 0.347836\n",
      "[109]\ttrain's binary_logloss: 0.346703\n",
      "[110]\ttrain's binary_logloss: 0.345726\n",
      "[111]\ttrain's binary_logloss: 0.344929\n",
      "[112]\ttrain's binary_logloss: 0.344232\n",
      "[113]\ttrain's binary_logloss: 0.343464\n",
      "[114]\ttrain's binary_logloss: 0.342828\n",
      "[115]\ttrain's binary_logloss: 0.341282\n",
      "[116]\ttrain's binary_logloss: 0.339423\n",
      "[117]\ttrain's binary_logloss: 0.338747\n",
      "[118]\ttrain's binary_logloss: 0.337414\n",
      "[119]\ttrain's binary_logloss: 0.336814\n",
      "[120]\ttrain's binary_logloss: 0.335958\n",
      "[121]\ttrain's binary_logloss: 0.335146\n",
      "[122]\ttrain's binary_logloss: 0.333571\n",
      "[123]\ttrain's binary_logloss: 0.332564\n",
      "[124]\ttrain's binary_logloss: 0.331984\n",
      "[125]\ttrain's binary_logloss: 0.331224\n",
      "[126]\ttrain's binary_logloss: 0.33044\n",
      "[127]\ttrain's binary_logloss: 0.32974\n",
      "[128]\ttrain's binary_logloss: 0.328766\n",
      "[129]\ttrain's binary_logloss: 0.327988\n",
      "[130]\ttrain's binary_logloss: 0.327226\n",
      "[131]\ttrain's binary_logloss: 0.326293\n",
      "[132]\ttrain's binary_logloss: 0.325219\n",
      "[133]\ttrain's binary_logloss: 0.323711\n",
      "[134]\ttrain's binary_logloss: 0.323081\n",
      "[135]\ttrain's binary_logloss: 0.321718\n",
      "[136]\ttrain's binary_logloss: 0.321142\n",
      "[137]\ttrain's binary_logloss: 0.320328\n",
      "[138]\ttrain's binary_logloss: 0.319378\n",
      "[139]\ttrain's binary_logloss: 0.318822\n",
      "[140]\ttrain's binary_logloss: 0.317859\n",
      "[141]\ttrain's binary_logloss: 0.31729\n",
      "[142]\ttrain's binary_logloss: 0.316314\n",
      "[143]\ttrain's binary_logloss: 0.315594\n",
      "[144]\ttrain's binary_logloss: 0.314675\n",
      "[145]\ttrain's binary_logloss: 0.313575\n",
      "[146]\ttrain's binary_logloss: 0.312904\n",
      "[147]\ttrain's binary_logloss: 0.31207\n",
      "[148]\ttrain's binary_logloss: 0.311461\n",
      "[149]\ttrain's binary_logloss: 0.310867\n",
      "[150]\ttrain's binary_logloss: 0.309872\n",
      "[151]\ttrain's binary_logloss: 0.309071\n",
      "[152]\ttrain's binary_logloss: 0.308102\n",
      "[153]\ttrain's binary_logloss: 0.307219\n",
      "[154]\ttrain's binary_logloss: 0.306427\n",
      "[155]\ttrain's binary_logloss: 0.305771\n",
      "[156]\ttrain's binary_logloss: 0.304692\n",
      "[157]\ttrain's binary_logloss: 0.303829\n",
      "[158]\ttrain's binary_logloss: 0.302958\n",
      "[159]\ttrain's binary_logloss: 0.302515\n",
      "[160]\ttrain's binary_logloss: 0.301781\n",
      "[161]\ttrain's binary_logloss: 0.301218\n",
      "[162]\ttrain's binary_logloss: 0.30076\n",
      "[163]\ttrain's binary_logloss: 0.299788\n",
      "[164]\ttrain's binary_logloss: 0.299011\n",
      "[165]\ttrain's binary_logloss: 0.298209\n",
      "[166]\ttrain's binary_logloss: 0.297688\n",
      "[167]\ttrain's binary_logloss: 0.296928\n",
      "[168]\ttrain's binary_logloss: 0.296486\n",
      "[169]\ttrain's binary_logloss: 0.295689\n",
      "[170]\ttrain's binary_logloss: 0.295135\n",
      "[171]\ttrain's binary_logloss: 0.293992\n",
      "[172]\ttrain's binary_logloss: 0.293065\n",
      "[173]\ttrain's binary_logloss: 0.292238\n",
      "[174]\ttrain's binary_logloss: 0.291605\n",
      "[175]\ttrain's binary_logloss: 0.290909\n",
      "[176]\ttrain's binary_logloss: 0.290163\n",
      "[177]\ttrain's binary_logloss: 0.289679\n",
      "[178]\ttrain's binary_logloss: 0.288876\n",
      "[179]\ttrain's binary_logloss: 0.287826\n",
      "[180]\ttrain's binary_logloss: 0.286768\n",
      "[181]\ttrain's binary_logloss: 0.2861\n",
      "[182]\ttrain's binary_logloss: 0.285568\n",
      "[183]\ttrain's binary_logloss: 0.285031\n",
      "[184]\ttrain's binary_logloss: 0.284179\n",
      "[185]\ttrain's binary_logloss: 0.28348\n",
      "[186]\ttrain's binary_logloss: 0.282782\n",
      "[187]\ttrain's binary_logloss: 0.282188\n",
      "[188]\ttrain's binary_logloss: 0.281734\n",
      "[189]\ttrain's binary_logloss: 0.28121\n",
      "[190]\ttrain's binary_logloss: 0.280441\n",
      "[191]\ttrain's binary_logloss: 0.279909\n",
      "[192]\ttrain's binary_logloss: 0.27899\n",
      "[193]\ttrain's binary_logloss: 0.278616\n",
      "[194]\ttrain's binary_logloss: 0.278\n",
      "[195]\ttrain's binary_logloss: 0.277302\n",
      "[196]\ttrain's binary_logloss: 0.276416\n",
      "[197]\ttrain's binary_logloss: 0.275802\n",
      "[198]\ttrain's binary_logloss: 0.275207\n",
      "[199]\ttrain's binary_logloss: 0.274815\n",
      "[200]\ttrain's binary_logloss: 0.274167\n",
      "[201]\ttrain's binary_logloss: 0.273716\n",
      "[202]\ttrain's binary_logloss: 0.272815\n",
      "[203]\ttrain's binary_logloss: 0.272177\n",
      "[204]\ttrain's binary_logloss: 0.271436\n",
      "[205]\ttrain's binary_logloss: 0.270776\n",
      "[206]\ttrain's binary_logloss: 0.270229\n",
      "[207]\ttrain's binary_logloss: 0.269779\n",
      "[208]\ttrain's binary_logloss: 0.269004\n",
      "[209]\ttrain's binary_logloss: 0.267872\n",
      "[210]\ttrain's binary_logloss: 0.267196\n",
      "[211]\ttrain's binary_logloss: 0.266571\n",
      "[212]\ttrain's binary_logloss: 0.26598\n",
      "[213]\ttrain's binary_logloss: 0.265654\n",
      "[214]\ttrain's binary_logloss: 0.264831\n",
      "[215]\ttrain's binary_logloss: 0.263983\n",
      "[216]\ttrain's binary_logloss: 0.262875\n",
      "[217]\ttrain's binary_logloss: 0.26229\n",
      "[218]\ttrain's binary_logloss: 0.26172\n",
      "[219]\ttrain's binary_logloss: 0.260831\n",
      "[220]\ttrain's binary_logloss: 0.260221\n",
      "[221]\ttrain's binary_logloss: 0.259489\n",
      "[222]\ttrain's binary_logloss: 0.258778\n",
      "[223]\ttrain's binary_logloss: 0.25811\n",
      "[224]\ttrain's binary_logloss: 0.257694\n",
      "[225]\ttrain's binary_logloss: 0.257083\n",
      "[226]\ttrain's binary_logloss: 0.256652\n",
      "[227]\ttrain's binary_logloss: 0.255637\n",
      "[228]\ttrain's binary_logloss: 0.255275\n",
      "[229]\ttrain's binary_logloss: 0.25436\n",
      "[230]\ttrain's binary_logloss: 0.253792\n",
      "[231]\ttrain's binary_logloss: 0.253338\n",
      "[232]\ttrain's binary_logloss: 0.252984\n",
      "[233]\ttrain's binary_logloss: 0.252331\n",
      "[234]\ttrain's binary_logloss: 0.251858\n",
      "[235]\ttrain's binary_logloss: 0.251312\n",
      "[236]\ttrain's binary_logloss: 0.250489\n",
      "[237]\ttrain's binary_logloss: 0.250099\n",
      "[238]\ttrain's binary_logloss: 0.249802\n",
      "[239]\ttrain's binary_logloss: 0.249211\n",
      "[240]\ttrain's binary_logloss: 0.24873\n",
      "[241]\ttrain's binary_logloss: 0.248368\n",
      "[242]\ttrain's binary_logloss: 0.247962\n",
      "[243]\ttrain's binary_logloss: 0.247223\n",
      "[244]\ttrain's binary_logloss: 0.246523\n",
      "[245]\ttrain's binary_logloss: 0.245704\n",
      "[246]\ttrain's binary_logloss: 0.245339\n",
      "[247]\ttrain's binary_logloss: 0.244785\n",
      "[248]\ttrain's binary_logloss: 0.244489\n",
      "[249]\ttrain's binary_logloss: 0.244123\n",
      "[250]\ttrain's binary_logloss: 0.243491\n",
      "[251]\ttrain's binary_logloss: 0.242877\n",
      "[252]\ttrain's binary_logloss: 0.24253\n",
      "[253]\ttrain's binary_logloss: 0.242084\n",
      "[254]\ttrain's binary_logloss: 0.241631\n",
      "[255]\ttrain's binary_logloss: 0.241128\n",
      "[256]\ttrain's binary_logloss: 0.240535\n",
      "[257]\ttrain's binary_logloss: 0.240056\n",
      "[258]\ttrain's binary_logloss: 0.23977\n",
      "[259]\ttrain's binary_logloss: 0.239386\n",
      "[260]\ttrain's binary_logloss: 0.238696\n",
      "[261]\ttrain's binary_logloss: 0.238307\n",
      "[262]\ttrain's binary_logloss: 0.237724\n",
      "[263]\ttrain's binary_logloss: 0.23714\n",
      "[264]\ttrain's binary_logloss: 0.236582\n",
      "[265]\ttrain's binary_logloss: 0.236232\n",
      "[266]\ttrain's binary_logloss: 0.235868\n",
      "[267]\ttrain's binary_logloss: 0.235129\n",
      "[268]\ttrain's binary_logloss: 0.234585\n",
      "[269]\ttrain's binary_logloss: 0.23423\n",
      "[270]\ttrain's binary_logloss: 0.233736\n",
      "[271]\ttrain's binary_logloss: 0.233189\n",
      "[272]\ttrain's binary_logloss: 0.232941\n",
      "[273]\ttrain's binary_logloss: 0.23242\n",
      "[274]\ttrain's binary_logloss: 0.231679\n",
      "[275]\ttrain's binary_logloss: 0.231218\n",
      "[276]\ttrain's binary_logloss: 0.23099\n",
      "[277]\ttrain's binary_logloss: 0.230563\n",
      "[278]\ttrain's binary_logloss: 0.229942\n",
      "[279]\ttrain's binary_logloss: 0.229532\n",
      "[280]\ttrain's binary_logloss: 0.22913\n",
      "[281]\ttrain's binary_logloss: 0.228747\n",
      "[282]\ttrain's binary_logloss: 0.227907\n",
      "[283]\ttrain's binary_logloss: 0.227236\n",
      "[284]\ttrain's binary_logloss: 0.226918\n",
      "[285]\ttrain's binary_logloss: 0.226609\n",
      "[286]\ttrain's binary_logloss: 0.226241\n",
      "[287]\ttrain's binary_logloss: 0.2259\n",
      "[288]\ttrain's binary_logloss: 0.225565\n",
      "[289]\ttrain's binary_logloss: 0.225198\n",
      "[290]\ttrain's binary_logloss: 0.224945\n",
      "[291]\ttrain's binary_logloss: 0.224465\n",
      "[292]\ttrain's binary_logloss: 0.224152\n",
      "[293]\ttrain's binary_logloss: 0.223747\n",
      "[294]\ttrain's binary_logloss: 0.223332\n",
      "[295]\ttrain's binary_logloss: 0.223046\n",
      "[296]\ttrain's binary_logloss: 0.222285\n",
      "[297]\ttrain's binary_logloss: 0.221907\n",
      "[298]\ttrain's binary_logloss: 0.221567\n",
      "[299]\ttrain's binary_logloss: 0.221273\n",
      "[300]\ttrain's binary_logloss: 0.220611\n",
      "[301]\ttrain's binary_logloss: 0.220213\n",
      "[302]\ttrain's binary_logloss: 0.21992\n",
      "[303]\ttrain's binary_logloss: 0.219641\n",
      "[304]\ttrain's binary_logloss: 0.219161\n",
      "[305]\ttrain's binary_logloss: 0.218723\n",
      "[306]\ttrain's binary_logloss: 0.218309\n",
      "[307]\ttrain's binary_logloss: 0.21755\n",
      "[308]\ttrain's binary_logloss: 0.217223\n",
      "[309]\ttrain's binary_logloss: 0.216722\n",
      "[310]\ttrain's binary_logloss: 0.216242\n",
      "[311]\ttrain's binary_logloss: 0.216004\n",
      "[312]\ttrain's binary_logloss: 0.215234\n",
      "[313]\ttrain's binary_logloss: 0.214731\n",
      "[314]\ttrain's binary_logloss: 0.214299\n",
      "[315]\ttrain's binary_logloss: 0.213988\n",
      "[316]\ttrain's binary_logloss: 0.213743\n",
      "[317]\ttrain's binary_logloss: 0.21342\n",
      "[318]\ttrain's binary_logloss: 0.212993\n",
      "[319]\ttrain's binary_logloss: 0.212576\n",
      "[320]\ttrain's binary_logloss: 0.21198\n",
      "[321]\ttrain's binary_logloss: 0.211424\n",
      "[322]\ttrain's binary_logloss: 0.21098\n",
      "[323]\ttrain's binary_logloss: 0.210717\n",
      "[324]\ttrain's binary_logloss: 0.210308\n",
      "[325]\ttrain's binary_logloss: 0.209841\n",
      "[326]\ttrain's binary_logloss: 0.208946\n",
      "[327]\ttrain's binary_logloss: 0.208284\n",
      "[328]\ttrain's binary_logloss: 0.207906\n",
      "[329]\ttrain's binary_logloss: 0.207541\n",
      "[330]\ttrain's binary_logloss: 0.207287\n",
      "[331]\ttrain's binary_logloss: 0.206782\n",
      "[332]\ttrain's binary_logloss: 0.206542\n",
      "[333]\ttrain's binary_logloss: 0.205731\n",
      "[334]\ttrain's binary_logloss: 0.20523\n",
      "[335]\ttrain's binary_logloss: 0.204782\n",
      "[336]\ttrain's binary_logloss: 0.204562\n",
      "[337]\ttrain's binary_logloss: 0.204267\n",
      "[338]\ttrain's binary_logloss: 0.204085\n",
      "[339]\ttrain's binary_logloss: 0.203701\n",
      "[340]\ttrain's binary_logloss: 0.203224\n",
      "[341]\ttrain's binary_logloss: 0.202829\n",
      "[342]\ttrain's binary_logloss: 0.202252\n",
      "[343]\ttrain's binary_logloss: 0.201751\n",
      "[344]\ttrain's binary_logloss: 0.201267\n",
      "[345]\ttrain's binary_logloss: 0.200805\n",
      "[346]\ttrain's binary_logloss: 0.200549\n",
      "[347]\ttrain's binary_logloss: 0.200051\n",
      "[348]\ttrain's binary_logloss: 0.199563\n",
      "[349]\ttrain's binary_logloss: 0.199131\n",
      "[350]\ttrain's binary_logloss: 0.198731\n",
      "[351]\ttrain's binary_logloss: 0.1983\n",
      "[352]\ttrain's binary_logloss: 0.197941\n",
      "[353]\ttrain's binary_logloss: 0.197673\n",
      "[354]\ttrain's binary_logloss: 0.197497\n",
      "[355]\ttrain's binary_logloss: 0.197346\n",
      "[356]\ttrain's binary_logloss: 0.196909\n",
      "[357]\ttrain's binary_logloss: 0.196737\n",
      "[358]\ttrain's binary_logloss: 0.196233\n",
      "[359]\ttrain's binary_logloss: 0.195819\n",
      "[360]\ttrain's binary_logloss: 0.195374\n",
      "[361]\ttrain's binary_logloss: 0.194856\n",
      "[362]\ttrain's binary_logloss: 0.194501\n",
      "[363]\ttrain's binary_logloss: 0.194192\n",
      "[364]\ttrain's binary_logloss: 0.193896\n",
      "[365]\ttrain's binary_logloss: 0.193524\n",
      "[366]\ttrain's binary_logloss: 0.193074\n",
      "[367]\ttrain's binary_logloss: 0.192726\n",
      "[368]\ttrain's binary_logloss: 0.192346\n",
      "[369]\ttrain's binary_logloss: 0.19207\n",
      "[370]\ttrain's binary_logloss: 0.191551\n",
      "[371]\ttrain's binary_logloss: 0.19121\n",
      "[372]\ttrain's binary_logloss: 0.190668\n",
      "[373]\ttrain's binary_logloss: 0.190357\n",
      "[374]\ttrain's binary_logloss: 0.189708\n",
      "[375]\ttrain's binary_logloss: 0.189166\n",
      "[376]\ttrain's binary_logloss: 0.188481\n",
      "[377]\ttrain's binary_logloss: 0.187923\n",
      "[378]\ttrain's binary_logloss: 0.187387\n",
      "[379]\ttrain's binary_logloss: 0.186829\n",
      "[380]\ttrain's binary_logloss: 0.186359\n",
      "[381]\ttrain's binary_logloss: 0.186049\n",
      "[382]\ttrain's binary_logloss: 0.185431\n",
      "[383]\ttrain's binary_logloss: 0.184966\n",
      "[384]\ttrain's binary_logloss: 0.184586\n",
      "[385]\ttrain's binary_logloss: 0.183982\n",
      "[386]\ttrain's binary_logloss: 0.183568\n",
      "[387]\ttrain's binary_logloss: 0.183413\n",
      "[388]\ttrain's binary_logloss: 0.182946\n",
      "[389]\ttrain's binary_logloss: 0.182525\n",
      "[390]\ttrain's binary_logloss: 0.181952\n",
      "[391]\ttrain's binary_logloss: 0.181528\n",
      "[392]\ttrain's binary_logloss: 0.18083\n",
      "[393]\ttrain's binary_logloss: 0.180543\n",
      "[394]\ttrain's binary_logloss: 0.180241\n",
      "[395]\ttrain's binary_logloss: 0.179704\n",
      "[396]\ttrain's binary_logloss: 0.179356\n",
      "[397]\ttrain's binary_logloss: 0.179073\n",
      "[398]\ttrain's binary_logloss: 0.178589\n",
      "[399]\ttrain's binary_logloss: 0.178339\n",
      "[400]\ttrain's binary_logloss: 0.17809\n",
      "[401]\ttrain's binary_logloss: 0.177719\n",
      "[402]\ttrain's binary_logloss: 0.177188\n",
      "[403]\ttrain's binary_logloss: 0.176908\n",
      "[404]\ttrain's binary_logloss: 0.176348\n",
      "[405]\ttrain's binary_logloss: 0.176101\n",
      "[406]\ttrain's binary_logloss: 0.175761\n",
      "[407]\ttrain's binary_logloss: 0.175526\n",
      "[408]\ttrain's binary_logloss: 0.175253\n",
      "[409]\ttrain's binary_logloss: 0.174833\n",
      "[410]\ttrain's binary_logloss: 0.174486\n",
      "[411]\ttrain's binary_logloss: 0.174289\n",
      "[412]\ttrain's binary_logloss: 0.173642\n",
      "[413]\ttrain's binary_logloss: 0.173361\n",
      "[414]\ttrain's binary_logloss: 0.172989\n",
      "[415]\ttrain's binary_logloss: 0.172507\n",
      "[416]\ttrain's binary_logloss: 0.17226\n",
      "[417]\ttrain's binary_logloss: 0.171865\n",
      "[418]\ttrain's binary_logloss: 0.171421\n",
      "[419]\ttrain's binary_logloss: 0.171136\n",
      "[420]\ttrain's binary_logloss: 0.170918\n",
      "[421]\ttrain's binary_logloss: 0.170276\n",
      "[422]\ttrain's binary_logloss: 0.169918\n",
      "[423]\ttrain's binary_logloss: 0.169643\n",
      "[424]\ttrain's binary_logloss: 0.169293\n",
      "[425]\ttrain's binary_logloss: 0.169112\n",
      "[426]\ttrain's binary_logloss: 0.16862\n",
      "[427]\ttrain's binary_logloss: 0.168273\n",
      "[428]\ttrain's binary_logloss: 0.167871\n",
      "[429]\ttrain's binary_logloss: 0.167623\n",
      "[430]\ttrain's binary_logloss: 0.167426\n",
      "[431]\ttrain's binary_logloss: 0.166944\n",
      "[432]\ttrain's binary_logloss: 0.166616\n",
      "[433]\ttrain's binary_logloss: 0.166257\n",
      "[434]\ttrain's binary_logloss: 0.166075\n",
      "[435]\ttrain's binary_logloss: 0.165558\n",
      "[436]\ttrain's binary_logloss: 0.165281\n",
      "[437]\ttrain's binary_logloss: 0.165056\n",
      "[438]\ttrain's binary_logloss: 0.164855\n",
      "[439]\ttrain's binary_logloss: 0.164418\n",
      "[440]\ttrain's binary_logloss: 0.163917\n",
      "[441]\ttrain's binary_logloss: 0.163484\n",
      "[442]\ttrain's binary_logloss: 0.163367\n",
      "[443]\ttrain's binary_logloss: 0.163146\n",
      "[444]\ttrain's binary_logloss: 0.162918\n",
      "[445]\ttrain's binary_logloss: 0.1626\n",
      "[446]\ttrain's binary_logloss: 0.162193\n",
      "[447]\ttrain's binary_logloss: 0.16195\n",
      "[448]\ttrain's binary_logloss: 0.161755\n",
      "[449]\ttrain's binary_logloss: 0.16139\n",
      "[450]\ttrain's binary_logloss: 0.16113\n",
      "[451]\ttrain's binary_logloss: 0.160798\n",
      "[452]\ttrain's binary_logloss: 0.160367\n",
      "[453]\ttrain's binary_logloss: 0.160173\n",
      "[454]\ttrain's binary_logloss: 0.160004\n",
      "[455]\ttrain's binary_logloss: 0.159851\n",
      "[456]\ttrain's binary_logloss: 0.15963\n",
      "[457]\ttrain's binary_logloss: 0.159342\n",
      "[458]\ttrain's binary_logloss: 0.158956\n",
      "[459]\ttrain's binary_logloss: 0.158747\n",
      "[460]\ttrain's binary_logloss: 0.158549\n",
      "[461]\ttrain's binary_logloss: 0.158198\n",
      "[462]\ttrain's binary_logloss: 0.157527\n",
      "[463]\ttrain's binary_logloss: 0.157263\n",
      "[464]\ttrain's binary_logloss: 0.157004\n",
      "[465]\ttrain's binary_logloss: 0.156493\n",
      "[466]\ttrain's binary_logloss: 0.156155\n",
      "[467]\ttrain's binary_logloss: 0.156\n",
      "[468]\ttrain's binary_logloss: 0.155591\n",
      "[469]\ttrain's binary_logloss: 0.154938\n",
      "[470]\ttrain's binary_logloss: 0.154755\n",
      "[471]\ttrain's binary_logloss: 0.154591\n",
      "[472]\ttrain's binary_logloss: 0.154373\n",
      "[473]\ttrain's binary_logloss: 0.154156\n",
      "[474]\ttrain's binary_logloss: 0.153797\n",
      "[475]\ttrain's binary_logloss: 0.153479\n",
      "[476]\ttrain's binary_logloss: 0.153004\n",
      "[477]\ttrain's binary_logloss: 0.152814\n",
      "[478]\ttrain's binary_logloss: 0.152484\n",
      "[479]\ttrain's binary_logloss: 0.152381\n",
      "[480]\ttrain's binary_logloss: 0.15209\n",
      "[481]\ttrain's binary_logloss: 0.151521\n",
      "[482]\ttrain's binary_logloss: 0.151195\n",
      "[483]\ttrain's binary_logloss: 0.150919\n",
      "[484]\ttrain's binary_logloss: 0.150498\n",
      "[485]\ttrain's binary_logloss: 0.150235\n",
      "[486]\ttrain's binary_logloss: 0.15008\n",
      "[487]\ttrain's binary_logloss: 0.149875\n",
      "[488]\ttrain's binary_logloss: 0.1497\n",
      "[489]\ttrain's binary_logloss: 0.149427\n",
      "[490]\ttrain's binary_logloss: 0.148995\n",
      "[491]\ttrain's binary_logloss: 0.148707\n",
      "[492]\ttrain's binary_logloss: 0.148535\n",
      "[493]\ttrain's binary_logloss: 0.148291\n",
      "[494]\ttrain's binary_logloss: 0.148023\n",
      "[495]\ttrain's binary_logloss: 0.1476\n",
      "[496]\ttrain's binary_logloss: 0.147413\n",
      "[497]\ttrain's binary_logloss: 0.147097\n",
      "[498]\ttrain's binary_logloss: 0.146752\n",
      "[499]\ttrain's binary_logloss: 0.146375\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "[0]\ttest-logloss:0.59573\n",
      "[1]\ttest-logloss:0.58371\n",
      "[2]\ttest-logloss:0.57642\n",
      "[3]\ttest-logloss:0.58736\n",
      "[4]\ttest-logloss:0.58414\n",
      "[5]\ttest-logloss:0.58967\n",
      "[6]\ttest-logloss:0.59291\n",
      "[7]\ttest-logloss:0.59738\n",
      "[8]\ttest-logloss:0.59849\n",
      "[9]\ttest-logloss:0.59946\n",
      "[10]\ttest-logloss:0.60594\n",
      "[11]\ttest-logloss:0.60589\n",
      "[12]\ttest-logloss:0.60974\n",
      "[13]\ttest-logloss:0.60995\n",
      "[14]\ttest-logloss:0.61244\n",
      "[15]\ttest-logloss:0.61994\n",
      "[16]\ttest-logloss:0.62884\n",
      "[17]\ttest-logloss:0.63393\n",
      "[18]\ttest-logloss:0.63189\n",
      "[19]\ttest-logloss:0.62428\n",
      "[20]\ttest-logloss:0.63861\n",
      "[21]\ttest-logloss:0.63952\n",
      "[22]\ttest-logloss:0.63235\n",
      "X_trainの形状： (646, 24)  y_trainの形状： (646,)  X_testの形状： (278, 24)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.662906\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.638297\n",
      "[3]\ttrain's binary_logloss: 0.617479\n",
      "[4]\ttrain's binary_logloss: 0.600501\n",
      "[5]\ttrain's binary_logloss: 0.585878\n",
      "[6]\ttrain's binary_logloss: 0.573603\n",
      "[7]\ttrain's binary_logloss: 0.562965\n",
      "[8]\ttrain's binary_logloss: 0.553485\n",
      "[9]\ttrain's binary_logloss: 0.545568\n",
      "[10]\ttrain's binary_logloss: 0.538341\n",
      "[11]\ttrain's binary_logloss: 0.53218\n",
      "[12]\ttrain's binary_logloss: 0.526888\n",
      "[13]\ttrain's binary_logloss: 0.521507\n",
      "[14]\ttrain's binary_logloss: 0.516283\n",
      "[15]\ttrain's binary_logloss: 0.511686\n",
      "[16]\ttrain's binary_logloss: 0.507458\n",
      "[17]\ttrain's binary_logloss: 0.502668\n",
      "[18]\ttrain's binary_logloss: 0.498687\n",
      "[19]\ttrain's binary_logloss: 0.494656\n",
      "[20]\ttrain's binary_logloss: 0.491561\n",
      "[21]\ttrain's binary_logloss: 0.488351\n",
      "[22]\ttrain's binary_logloss: 0.485573\n",
      "[23]\ttrain's binary_logloss: 0.482171\n",
      "[24]\ttrain's binary_logloss: 0.479149\n",
      "[25]\ttrain's binary_logloss: 0.476664\n",
      "[26]\ttrain's binary_logloss: 0.473929\n",
      "[27]\ttrain's binary_logloss: 0.471448\n",
      "[28]\ttrain's binary_logloss: 0.469294\n",
      "[29]\ttrain's binary_logloss: 0.466646\n",
      "[30]\ttrain's binary_logloss: 0.463765\n",
      "[31]\ttrain's binary_logloss: 0.461489\n",
      "[32]\ttrain's binary_logloss: 0.45924\n",
      "[33]\ttrain's binary_logloss: 0.456848\n",
      "[34]\ttrain's binary_logloss: 0.454888\n",
      "[35]\ttrain's binary_logloss: 0.452506\n",
      "[36]\ttrain's binary_logloss: 0.450764\n",
      "[37]\ttrain's binary_logloss: 0.448826\n",
      "[38]\ttrain's binary_logloss: 0.446645\n",
      "[39]\ttrain's binary_logloss: 0.444878\n",
      "[40]\ttrain's binary_logloss: 0.44312\n",
      "[41]\ttrain's binary_logloss: 0.441225\n",
      "[42]\ttrain's binary_logloss: 0.43862\n",
      "[43]\ttrain's binary_logloss: 0.43714\n",
      "[44]\ttrain's binary_logloss: 0.435454\n",
      "[45]\ttrain's binary_logloss: 0.433442\n",
      "[46]\ttrain's binary_logloss: 0.431905\n",
      "[47]\ttrain's binary_logloss: 0.430126\n",
      "[48]\ttrain's binary_logloss: 0.428234\n",
      "[49]\ttrain's binary_logloss: 0.42696\n",
      "[50]\ttrain's binary_logloss: 0.424765\n",
      "[51]\ttrain's binary_logloss: 0.423088\n",
      "[52]\ttrain's binary_logloss: 0.421902\n",
      "[53]\ttrain's binary_logloss: 0.420318\n",
      "[54]\ttrain's binary_logloss: 0.418909\n",
      "[55]\ttrain's binary_logloss: 0.417007\n",
      "[56]\ttrain's binary_logloss: 0.415208\n",
      "[57]\ttrain's binary_logloss: 0.413514\n",
      "[58]\ttrain's binary_logloss: 0.412293\n",
      "[59]\ttrain's binary_logloss: 0.411102\n",
      "[60]\ttrain's binary_logloss: 0.40967\n",
      "[61]\ttrain's binary_logloss: 0.407243\n",
      "[62]\ttrain's binary_logloss: 0.40599\n",
      "[63]\ttrain's binary_logloss: 0.404919\n",
      "[64]\ttrain's binary_logloss: 0.403409\n",
      "[65]\ttrain's binary_logloss: 0.402214\n",
      "[66]\ttrain's binary_logloss: 0.400646\n",
      "[67]\ttrain's binary_logloss: 0.398702\n",
      "[68]\ttrain's binary_logloss: 0.397395\n",
      "[69]\ttrain's binary_logloss: 0.395586\n",
      "[70]\ttrain's binary_logloss: 0.393765\n",
      "[71]\ttrain's binary_logloss: 0.392805\n",
      "[72]\ttrain's binary_logloss: 0.391712\n",
      "[73]\ttrain's binary_logloss: 0.390657\n",
      "[74]\ttrain's binary_logloss: 0.388989\n",
      "[75]\ttrain's binary_logloss: 0.38764\n",
      "[76]\ttrain's binary_logloss: 0.386751\n",
      "[77]\ttrain's binary_logloss: 0.384699\n",
      "[78]\ttrain's binary_logloss: 0.382528\n",
      "[79]\ttrain's binary_logloss: 0.381192\n",
      "[80]\ttrain's binary_logloss: 0.380259\n",
      "[81]\ttrain's binary_logloss: 0.378934\n",
      "[82]\ttrain's binary_logloss: 0.377976\n",
      "[83]\ttrain's binary_logloss: 0.376874\n",
      "[84]\ttrain's binary_logloss: 0.375969\n",
      "[85]\ttrain's binary_logloss: 0.374852\n",
      "[86]\ttrain's binary_logloss: 0.373135\n",
      "[87]\ttrain's binary_logloss: 0.371574\n",
      "[88]\ttrain's binary_logloss: 0.370593\n",
      "[89]\ttrain's binary_logloss: 0.369757\n",
      "[90]\ttrain's binary_logloss: 0.368328\n",
      "[91]\ttrain's binary_logloss: 0.367325\n",
      "[92]\ttrain's binary_logloss: 0.36639\n",
      "[93]\ttrain's binary_logloss: 0.365162\n",
      "[94]\ttrain's binary_logloss: 0.364408\n",
      "[95]\ttrain's binary_logloss: 0.362858\n",
      "[96]\ttrain's binary_logloss: 0.360926\n",
      "[97]\ttrain's binary_logloss: 0.35941\n",
      "[98]\ttrain's binary_logloss: 0.358207\n",
      "[99]\ttrain's binary_logloss: 0.357537\n",
      "[100]\ttrain's binary_logloss: 0.356465\n",
      "[101]\ttrain's binary_logloss: 0.355643\n",
      "[102]\ttrain's binary_logloss: 0.354476\n",
      "[103]\ttrain's binary_logloss: 0.353127\n",
      "[104]\ttrain's binary_logloss: 0.352091\n",
      "[105]\ttrain's binary_logloss: 0.350762\n",
      "[106]\ttrain's binary_logloss: 0.349704\n",
      "[107]\ttrain's binary_logloss: 0.348859\n",
      "[108]\ttrain's binary_logloss: 0.347836\n",
      "[109]\ttrain's binary_logloss: 0.346703\n",
      "[110]\ttrain's binary_logloss: 0.345726\n",
      "[111]\ttrain's binary_logloss: 0.344929\n",
      "[112]\ttrain's binary_logloss: 0.344232\n",
      "[113]\ttrain's binary_logloss: 0.343464\n",
      "[114]\ttrain's binary_logloss: 0.342828\n",
      "[115]\ttrain's binary_logloss: 0.341282\n",
      "[116]\ttrain's binary_logloss: 0.339423\n",
      "[117]\ttrain's binary_logloss: 0.338747\n",
      "[118]\ttrain's binary_logloss: 0.337414\n",
      "[119]\ttrain's binary_logloss: 0.336814\n",
      "[120]\ttrain's binary_logloss: 0.335958\n",
      "[121]\ttrain's binary_logloss: 0.335146\n",
      "[122]\ttrain's binary_logloss: 0.333571\n",
      "[123]\ttrain's binary_logloss: 0.332564\n",
      "[124]\ttrain's binary_logloss: 0.331984\n",
      "[125]\ttrain's binary_logloss: 0.331224\n",
      "[126]\ttrain's binary_logloss: 0.33044\n",
      "[127]\ttrain's binary_logloss: 0.32974\n",
      "[128]\ttrain's binary_logloss: 0.328766\n",
      "[129]\ttrain's binary_logloss: 0.327988\n",
      "[130]\ttrain's binary_logloss: 0.327226\n",
      "[131]\ttrain's binary_logloss: 0.326293\n",
      "[132]\ttrain's binary_logloss: 0.325219\n",
      "[133]\ttrain's binary_logloss: 0.323711\n",
      "[134]\ttrain's binary_logloss: 0.323081\n",
      "[135]\ttrain's binary_logloss: 0.321718\n",
      "[136]\ttrain's binary_logloss: 0.321142\n",
      "[137]\ttrain's binary_logloss: 0.320328\n",
      "[138]\ttrain's binary_logloss: 0.319378\n",
      "[139]\ttrain's binary_logloss: 0.318822\n",
      "[140]\ttrain's binary_logloss: 0.317859\n",
      "[141]\ttrain's binary_logloss: 0.31729\n",
      "[142]\ttrain's binary_logloss: 0.316314\n",
      "[143]\ttrain's binary_logloss: 0.315594\n",
      "[144]\ttrain's binary_logloss: 0.314675\n",
      "[145]\ttrain's binary_logloss: 0.313575\n",
      "[146]\ttrain's binary_logloss: 0.312904\n",
      "[147]\ttrain's binary_logloss: 0.31207\n",
      "[148]\ttrain's binary_logloss: 0.311461\n",
      "[149]\ttrain's binary_logloss: 0.310867\n",
      "[150]\ttrain's binary_logloss: 0.309872\n",
      "[151]\ttrain's binary_logloss: 0.309071\n",
      "[152]\ttrain's binary_logloss: 0.308102\n",
      "[153]\ttrain's binary_logloss: 0.307219\n",
      "[154]\ttrain's binary_logloss: 0.306427\n",
      "[155]\ttrain's binary_logloss: 0.305771\n",
      "[156]\ttrain's binary_logloss: 0.304692\n",
      "[157]\ttrain's binary_logloss: 0.303829\n",
      "[158]\ttrain's binary_logloss: 0.302958\n",
      "[159]\ttrain's binary_logloss: 0.302515\n",
      "[160]\ttrain's binary_logloss: 0.301781\n",
      "[161]\ttrain's binary_logloss: 0.301218\n",
      "[162]\ttrain's binary_logloss: 0.30076\n",
      "[163]\ttrain's binary_logloss: 0.299788\n",
      "[164]\ttrain's binary_logloss: 0.299011\n",
      "[165]\ttrain's binary_logloss: 0.298209\n",
      "[166]\ttrain's binary_logloss: 0.297688\n",
      "[167]\ttrain's binary_logloss: 0.296928\n",
      "[168]\ttrain's binary_logloss: 0.296486\n",
      "[169]\ttrain's binary_logloss: 0.295689\n",
      "[170]\ttrain's binary_logloss: 0.295135\n",
      "[171]\ttrain's binary_logloss: 0.293992\n",
      "[172]\ttrain's binary_logloss: 0.293065\n",
      "[173]\ttrain's binary_logloss: 0.292238\n",
      "[174]\ttrain's binary_logloss: 0.291605\n",
      "[175]\ttrain's binary_logloss: 0.290909\n",
      "[176]\ttrain's binary_logloss: 0.290163\n",
      "[177]\ttrain's binary_logloss: 0.289679\n",
      "[178]\ttrain's binary_logloss: 0.288876\n",
      "[179]\ttrain's binary_logloss: 0.287826\n",
      "[180]\ttrain's binary_logloss: 0.286768\n",
      "[181]\ttrain's binary_logloss: 0.2861\n",
      "[182]\ttrain's binary_logloss: 0.285568\n",
      "[183]\ttrain's binary_logloss: 0.285031\n",
      "[184]\ttrain's binary_logloss: 0.284179\n",
      "[185]\ttrain's binary_logloss: 0.28348\n",
      "[186]\ttrain's binary_logloss: 0.282782\n",
      "[187]\ttrain's binary_logloss: 0.282188\n",
      "[188]\ttrain's binary_logloss: 0.281734\n",
      "[189]\ttrain's binary_logloss: 0.28121\n",
      "[190]\ttrain's binary_logloss: 0.280441\n",
      "[191]\ttrain's binary_logloss: 0.279909\n",
      "[192]\ttrain's binary_logloss: 0.27899\n",
      "[193]\ttrain's binary_logloss: 0.278616\n",
      "[194]\ttrain's binary_logloss: 0.278\n",
      "[195]\ttrain's binary_logloss: 0.277302\n",
      "[196]\ttrain's binary_logloss: 0.276416\n",
      "[197]\ttrain's binary_logloss: 0.275802\n",
      "[198]\ttrain's binary_logloss: 0.275207\n",
      "[199]\ttrain's binary_logloss: 0.274815\n",
      "[200]\ttrain's binary_logloss: 0.274167\n",
      "[201]\ttrain's binary_logloss: 0.273716\n",
      "[202]\ttrain's binary_logloss: 0.272815\n",
      "[203]\ttrain's binary_logloss: 0.272177\n",
      "[204]\ttrain's binary_logloss: 0.271436\n",
      "[205]\ttrain's binary_logloss: 0.270776\n",
      "[206]\ttrain's binary_logloss: 0.270229\n",
      "[207]\ttrain's binary_logloss: 0.269779\n",
      "[208]\ttrain's binary_logloss: 0.269004\n",
      "[209]\ttrain's binary_logloss: 0.267872\n",
      "[210]\ttrain's binary_logloss: 0.267196\n",
      "[211]\ttrain's binary_logloss: 0.266571\n",
      "[212]\ttrain's binary_logloss: 0.26598\n",
      "[213]\ttrain's binary_logloss: 0.265654\n",
      "[214]\ttrain's binary_logloss: 0.264831\n",
      "[215]\ttrain's binary_logloss: 0.263983\n",
      "[216]\ttrain's binary_logloss: 0.262875\n",
      "[217]\ttrain's binary_logloss: 0.26229\n",
      "[218]\ttrain's binary_logloss: 0.26172\n",
      "[219]\ttrain's binary_logloss: 0.260831\n",
      "[220]\ttrain's binary_logloss: 0.260221\n",
      "[221]\ttrain's binary_logloss: 0.259489\n",
      "[222]\ttrain's binary_logloss: 0.258778\n",
      "[223]\ttrain's binary_logloss: 0.25811\n",
      "[224]\ttrain's binary_logloss: 0.257694\n",
      "[225]\ttrain's binary_logloss: 0.257083\n",
      "[226]\ttrain's binary_logloss: 0.256652\n",
      "[227]\ttrain's binary_logloss: 0.255637\n",
      "[228]\ttrain's binary_logloss: 0.255275\n",
      "[229]\ttrain's binary_logloss: 0.25436\n",
      "[230]\ttrain's binary_logloss: 0.253792\n",
      "[231]\ttrain's binary_logloss: 0.253338\n",
      "[232]\ttrain's binary_logloss: 0.252984\n",
      "[233]\ttrain's binary_logloss: 0.252331\n",
      "[234]\ttrain's binary_logloss: 0.251858\n",
      "[235]\ttrain's binary_logloss: 0.251312\n",
      "[236]\ttrain's binary_logloss: 0.250489\n",
      "[237]\ttrain's binary_logloss: 0.250099\n",
      "[238]\ttrain's binary_logloss: 0.249802\n",
      "[239]\ttrain's binary_logloss: 0.249211\n",
      "[240]\ttrain's binary_logloss: 0.24873\n",
      "[241]\ttrain's binary_logloss: 0.248368\n",
      "[242]\ttrain's binary_logloss: 0.247962\n",
      "[243]\ttrain's binary_logloss: 0.247223\n",
      "[244]\ttrain's binary_logloss: 0.246523\n",
      "[245]\ttrain's binary_logloss: 0.245704\n",
      "[246]\ttrain's binary_logloss: 0.245339\n",
      "[247]\ttrain's binary_logloss: 0.244785\n",
      "[248]\ttrain's binary_logloss: 0.244489\n",
      "[249]\ttrain's binary_logloss: 0.244123\n",
      "[250]\ttrain's binary_logloss: 0.243491\n",
      "[251]\ttrain's binary_logloss: 0.242877\n",
      "[252]\ttrain's binary_logloss: 0.24253\n",
      "[253]\ttrain's binary_logloss: 0.242084\n",
      "[254]\ttrain's binary_logloss: 0.241631\n",
      "[255]\ttrain's binary_logloss: 0.241128\n",
      "[256]\ttrain's binary_logloss: 0.240535\n",
      "[257]\ttrain's binary_logloss: 0.240056\n",
      "[258]\ttrain's binary_logloss: 0.23977\n",
      "[259]\ttrain's binary_logloss: 0.239386\n",
      "[260]\ttrain's binary_logloss: 0.238696\n",
      "[261]\ttrain's binary_logloss: 0.238307\n",
      "[262]\ttrain's binary_logloss: 0.237724\n",
      "[263]\ttrain's binary_logloss: 0.23714\n",
      "[264]\ttrain's binary_logloss: 0.236582\n",
      "[265]\ttrain's binary_logloss: 0.236232\n",
      "[266]\ttrain's binary_logloss: 0.235868\n",
      "[267]\ttrain's binary_logloss: 0.235129\n",
      "[268]\ttrain's binary_logloss: 0.234585\n",
      "[269]\ttrain's binary_logloss: 0.23423\n",
      "[270]\ttrain's binary_logloss: 0.233736\n",
      "[271]\ttrain's binary_logloss: 0.233189\n",
      "[272]\ttrain's binary_logloss: 0.232941\n",
      "[273]\ttrain's binary_logloss: 0.23242\n",
      "[274]\ttrain's binary_logloss: 0.231679\n",
      "[275]\ttrain's binary_logloss: 0.231218\n",
      "[276]\ttrain's binary_logloss: 0.23099\n",
      "[277]\ttrain's binary_logloss: 0.230563\n",
      "[278]\ttrain's binary_logloss: 0.229942\n",
      "[279]\ttrain's binary_logloss: 0.229532\n",
      "[280]\ttrain's binary_logloss: 0.22913\n",
      "[281]\ttrain's binary_logloss: 0.228747\n",
      "[282]\ttrain's binary_logloss: 0.227907\n",
      "[283]\ttrain's binary_logloss: 0.227236\n",
      "[284]\ttrain's binary_logloss: 0.226918\n",
      "[285]\ttrain's binary_logloss: 0.226609\n",
      "[286]\ttrain's binary_logloss: 0.226241\n",
      "[287]\ttrain's binary_logloss: 0.2259\n",
      "[288]\ttrain's binary_logloss: 0.225565\n",
      "[289]\ttrain's binary_logloss: 0.225198\n",
      "[290]\ttrain's binary_logloss: 0.224945\n",
      "[291]\ttrain's binary_logloss: 0.224465\n",
      "[292]\ttrain's binary_logloss: 0.224152\n",
      "[293]\ttrain's binary_logloss: 0.223747\n",
      "[294]\ttrain's binary_logloss: 0.223332\n",
      "[295]\ttrain's binary_logloss: 0.223046\n",
      "[296]\ttrain's binary_logloss: 0.222285\n",
      "[297]\ttrain's binary_logloss: 0.221907\n",
      "[298]\ttrain's binary_logloss: 0.221567\n",
      "[299]\ttrain's binary_logloss: 0.221273\n",
      "[300]\ttrain's binary_logloss: 0.220611\n",
      "[301]\ttrain's binary_logloss: 0.220213\n",
      "[302]\ttrain's binary_logloss: 0.21992\n",
      "[303]\ttrain's binary_logloss: 0.219641\n",
      "[304]\ttrain's binary_logloss: 0.219161\n",
      "[305]\ttrain's binary_logloss: 0.218723\n",
      "[306]\ttrain's binary_logloss: 0.218309\n",
      "[307]\ttrain's binary_logloss: 0.21755\n",
      "[308]\ttrain's binary_logloss: 0.217223\n",
      "[309]\ttrain's binary_logloss: 0.216722\n",
      "[310]\ttrain's binary_logloss: 0.216242\n",
      "[311]\ttrain's binary_logloss: 0.216004\n",
      "[312]\ttrain's binary_logloss: 0.215234\n",
      "[313]\ttrain's binary_logloss: 0.214731\n",
      "[314]\ttrain's binary_logloss: 0.214299\n",
      "[315]\ttrain's binary_logloss: 0.213988\n",
      "[316]\ttrain's binary_logloss: 0.213743\n",
      "[317]\ttrain's binary_logloss: 0.21342\n",
      "[318]\ttrain's binary_logloss: 0.212993\n",
      "[319]\ttrain's binary_logloss: 0.212576\n",
      "[320]\ttrain's binary_logloss: 0.21198\n",
      "[321]\ttrain's binary_logloss: 0.211424\n",
      "[322]\ttrain's binary_logloss: 0.21098\n",
      "[323]\ttrain's binary_logloss: 0.210717\n",
      "[324]\ttrain's binary_logloss: 0.210308\n",
      "[325]\ttrain's binary_logloss: 0.209841\n",
      "[326]\ttrain's binary_logloss: 0.208946\n",
      "[327]\ttrain's binary_logloss: 0.208284\n",
      "[328]\ttrain's binary_logloss: 0.207906\n",
      "[329]\ttrain's binary_logloss: 0.207541\n",
      "[330]\ttrain's binary_logloss: 0.207287\n",
      "[331]\ttrain's binary_logloss: 0.206782\n",
      "[332]\ttrain's binary_logloss: 0.206542\n",
      "[333]\ttrain's binary_logloss: 0.205731\n",
      "[334]\ttrain's binary_logloss: 0.20523\n",
      "[335]\ttrain's binary_logloss: 0.204782\n",
      "[336]\ttrain's binary_logloss: 0.204562\n",
      "[337]\ttrain's binary_logloss: 0.204267\n",
      "[338]\ttrain's binary_logloss: 0.204085\n",
      "[339]\ttrain's binary_logloss: 0.203701\n",
      "[340]\ttrain's binary_logloss: 0.203224\n",
      "[341]\ttrain's binary_logloss: 0.202829\n",
      "[342]\ttrain's binary_logloss: 0.202252\n",
      "[343]\ttrain's binary_logloss: 0.201751\n",
      "[344]\ttrain's binary_logloss: 0.201267\n",
      "[345]\ttrain's binary_logloss: 0.200805\n",
      "[346]\ttrain's binary_logloss: 0.200549\n",
      "[347]\ttrain's binary_logloss: 0.200051\n",
      "[348]\ttrain's binary_logloss: 0.199563\n",
      "[349]\ttrain's binary_logloss: 0.199131\n",
      "[350]\ttrain's binary_logloss: 0.198731\n",
      "[351]\ttrain's binary_logloss: 0.1983\n",
      "[352]\ttrain's binary_logloss: 0.197941\n",
      "[353]\ttrain's binary_logloss: 0.197673\n",
      "[354]\ttrain's binary_logloss: 0.197497\n",
      "[355]\ttrain's binary_logloss: 0.197346\n",
      "[356]\ttrain's binary_logloss: 0.196909\n",
      "[357]\ttrain's binary_logloss: 0.196737\n",
      "[358]\ttrain's binary_logloss: 0.196233\n",
      "[359]\ttrain's binary_logloss: 0.195819\n",
      "[360]\ttrain's binary_logloss: 0.195374\n",
      "[361]\ttrain's binary_logloss: 0.194856\n",
      "[362]\ttrain's binary_logloss: 0.194501\n",
      "[363]\ttrain's binary_logloss: 0.194192\n",
      "[364]\ttrain's binary_logloss: 0.193896\n",
      "[365]\ttrain's binary_logloss: 0.193524\n",
      "[366]\ttrain's binary_logloss: 0.193074\n",
      "[367]\ttrain's binary_logloss: 0.192726\n",
      "[368]\ttrain's binary_logloss: 0.192346\n",
      "[369]\ttrain's binary_logloss: 0.19207\n",
      "[370]\ttrain's binary_logloss: 0.191551\n",
      "[371]\ttrain's binary_logloss: 0.19121\n",
      "[372]\ttrain's binary_logloss: 0.190668\n",
      "[373]\ttrain's binary_logloss: 0.190357\n",
      "[374]\ttrain's binary_logloss: 0.189708\n",
      "[375]\ttrain's binary_logloss: 0.189166\n",
      "[376]\ttrain's binary_logloss: 0.188481\n",
      "[377]\ttrain's binary_logloss: 0.187923\n",
      "[378]\ttrain's binary_logloss: 0.187387\n",
      "[379]\ttrain's binary_logloss: 0.186829\n",
      "[380]\ttrain's binary_logloss: 0.186359\n",
      "[381]\ttrain's binary_logloss: 0.186049\n",
      "[382]\ttrain's binary_logloss: 0.185431\n",
      "[383]\ttrain's binary_logloss: 0.184966\n",
      "[384]\ttrain's binary_logloss: 0.184586\n",
      "[385]\ttrain's binary_logloss: 0.183982\n",
      "[386]\ttrain's binary_logloss: 0.183568\n",
      "[387]\ttrain's binary_logloss: 0.183413\n",
      "[388]\ttrain's binary_logloss: 0.182946\n",
      "[389]\ttrain's binary_logloss: 0.182525\n",
      "[390]\ttrain's binary_logloss: 0.181952\n",
      "[391]\ttrain's binary_logloss: 0.181528\n",
      "[392]\ttrain's binary_logloss: 0.18083\n",
      "[393]\ttrain's binary_logloss: 0.180543\n",
      "[394]\ttrain's binary_logloss: 0.180241\n",
      "[395]\ttrain's binary_logloss: 0.179704\n",
      "[396]\ttrain's binary_logloss: 0.179356\n",
      "[397]\ttrain's binary_logloss: 0.179073\n",
      "[398]\ttrain's binary_logloss: 0.178589\n",
      "[399]\ttrain's binary_logloss: 0.178339\n",
      "[400]\ttrain's binary_logloss: 0.17809\n",
      "[401]\ttrain's binary_logloss: 0.177719\n",
      "[402]\ttrain's binary_logloss: 0.177188\n",
      "[403]\ttrain's binary_logloss: 0.176908\n",
      "[404]\ttrain's binary_logloss: 0.176348\n",
      "[405]\ttrain's binary_logloss: 0.176101\n",
      "[406]\ttrain's binary_logloss: 0.175761\n",
      "[407]\ttrain's binary_logloss: 0.175526\n",
      "[408]\ttrain's binary_logloss: 0.175253\n",
      "[409]\ttrain's binary_logloss: 0.174833\n",
      "[410]\ttrain's binary_logloss: 0.174486\n",
      "[411]\ttrain's binary_logloss: 0.174289\n",
      "[412]\ttrain's binary_logloss: 0.173642\n",
      "[413]\ttrain's binary_logloss: 0.173361\n",
      "[414]\ttrain's binary_logloss: 0.172989\n",
      "[415]\ttrain's binary_logloss: 0.172507\n",
      "[416]\ttrain's binary_logloss: 0.17226\n",
      "[417]\ttrain's binary_logloss: 0.171865\n",
      "[418]\ttrain's binary_logloss: 0.171421\n",
      "[419]\ttrain's binary_logloss: 0.171136\n",
      "[420]\ttrain's binary_logloss: 0.170918\n",
      "[421]\ttrain's binary_logloss: 0.170276\n",
      "[422]\ttrain's binary_logloss: 0.169918\n",
      "[423]\ttrain's binary_logloss: 0.169643\n",
      "[424]\ttrain's binary_logloss: 0.169293\n",
      "[425]\ttrain's binary_logloss: 0.169112\n",
      "[426]\ttrain's binary_logloss: 0.16862\n",
      "[427]\ttrain's binary_logloss: 0.168273\n",
      "[428]\ttrain's binary_logloss: 0.167871\n",
      "[429]\ttrain's binary_logloss: 0.167623\n",
      "[430]\ttrain's binary_logloss: 0.167426\n",
      "[431]\ttrain's binary_logloss: 0.166944\n",
      "[432]\ttrain's binary_logloss: 0.166616\n",
      "[433]\ttrain's binary_logloss: 0.166257\n",
      "[434]\ttrain's binary_logloss: 0.166075\n",
      "[435]\ttrain's binary_logloss: 0.165558\n",
      "[436]\ttrain's binary_logloss: 0.165281\n",
      "[437]\ttrain's binary_logloss: 0.165056\n",
      "[438]\ttrain's binary_logloss: 0.164855\n",
      "[439]\ttrain's binary_logloss: 0.164418\n",
      "[440]\ttrain's binary_logloss: 0.163917\n",
      "[441]\ttrain's binary_logloss: 0.163484\n",
      "[442]\ttrain's binary_logloss: 0.163367\n",
      "[443]\ttrain's binary_logloss: 0.163146\n",
      "[444]\ttrain's binary_logloss: 0.162918\n",
      "[445]\ttrain's binary_logloss: 0.1626\n",
      "[446]\ttrain's binary_logloss: 0.162193\n",
      "[447]\ttrain's binary_logloss: 0.16195\n",
      "[448]\ttrain's binary_logloss: 0.161755\n",
      "[449]\ttrain's binary_logloss: 0.16139\n",
      "[450]\ttrain's binary_logloss: 0.16113\n",
      "[451]\ttrain's binary_logloss: 0.160798\n",
      "[452]\ttrain's binary_logloss: 0.160367\n",
      "[453]\ttrain's binary_logloss: 0.160173\n",
      "[454]\ttrain's binary_logloss: 0.160004\n",
      "[455]\ttrain's binary_logloss: 0.159851\n",
      "[456]\ttrain's binary_logloss: 0.15963\n",
      "[457]\ttrain's binary_logloss: 0.159342\n",
      "[458]\ttrain's binary_logloss: 0.158956\n",
      "[459]\ttrain's binary_logloss: 0.158747\n",
      "[460]\ttrain's binary_logloss: 0.158549\n",
      "[461]\ttrain's binary_logloss: 0.158198\n",
      "[462]\ttrain's binary_logloss: 0.157527\n",
      "[463]\ttrain's binary_logloss: 0.157263\n",
      "[464]\ttrain's binary_logloss: 0.157004\n",
      "[465]\ttrain's binary_logloss: 0.156493\n",
      "[466]\ttrain's binary_logloss: 0.156155\n",
      "[467]\ttrain's binary_logloss: 0.156\n",
      "[468]\ttrain's binary_logloss: 0.155591\n",
      "[469]\ttrain's binary_logloss: 0.154938\n",
      "[470]\ttrain's binary_logloss: 0.154755\n",
      "[471]\ttrain's binary_logloss: 0.154591\n",
      "[472]\ttrain's binary_logloss: 0.154373\n",
      "[473]\ttrain's binary_logloss: 0.154156\n",
      "[474]\ttrain's binary_logloss: 0.153797\n",
      "[475]\ttrain's binary_logloss: 0.153479\n",
      "[476]\ttrain's binary_logloss: 0.153004\n",
      "[477]\ttrain's binary_logloss: 0.152814\n",
      "[478]\ttrain's binary_logloss: 0.152484\n",
      "[479]\ttrain's binary_logloss: 0.152381\n",
      "[480]\ttrain's binary_logloss: 0.15209\n",
      "[481]\ttrain's binary_logloss: 0.151521\n",
      "[482]\ttrain's binary_logloss: 0.151195\n",
      "[483]\ttrain's binary_logloss: 0.150919\n",
      "[484]\ttrain's binary_logloss: 0.150498\n",
      "[485]\ttrain's binary_logloss: 0.150235\n",
      "[486]\ttrain's binary_logloss: 0.15008\n",
      "[487]\ttrain's binary_logloss: 0.149875\n",
      "[488]\ttrain's binary_logloss: 0.1497\n",
      "[489]\ttrain's binary_logloss: 0.149427\n",
      "[490]\ttrain's binary_logloss: 0.148995\n",
      "[491]\ttrain's binary_logloss: 0.148707\n",
      "[492]\ttrain's binary_logloss: 0.148535\n",
      "[493]\ttrain's binary_logloss: 0.148291\n",
      "[494]\ttrain's binary_logloss: 0.148023\n",
      "[495]\ttrain's binary_logloss: 0.1476\n",
      "[496]\ttrain's binary_logloss: 0.147413\n",
      "[497]\ttrain's binary_logloss: 0.147097\n",
      "[498]\ttrain's binary_logloss: 0.146752\n",
      "[499]\ttrain's binary_logloss: 0.146375\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "[0]\ttest-logloss:0.59573\n",
      "[1]\ttest-logloss:0.58371\n",
      "[2]\ttest-logloss:0.57642\n",
      "[3]\ttest-logloss:0.58736\n",
      "[4]\ttest-logloss:0.58414\n",
      "[5]\ttest-logloss:0.58967\n",
      "[6]\ttest-logloss:0.59291\n",
      "[7]\ttest-logloss:0.59738\n",
      "[8]\ttest-logloss:0.59849\n",
      "[9]\ttest-logloss:0.59946\n",
      "[10]\ttest-logloss:0.60594\n",
      "[11]\ttest-logloss:0.60589\n",
      "[12]\ttest-logloss:0.60974\n",
      "[13]\ttest-logloss:0.60995\n",
      "[14]\ttest-logloss:0.61244\n",
      "[15]\ttest-logloss:0.61994\n",
      "[16]\ttest-logloss:0.62884\n",
      "[17]\ttest-logloss:0.63393\n",
      "[18]\ttest-logloss:0.63189\n",
      "[19]\ttest-logloss:0.62428\n",
      "[20]\ttest-logloss:0.63861\n",
      "[21]\ttest-logloss:0.63952\n",
      "[22]\ttest-logloss:0.63235\n",
      "X_trainの形状： (646, 24)  y_trainの形状： (646,)  X_testの形状： (278, 24)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.662906\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.638297\n",
      "[3]\ttrain's binary_logloss: 0.617479\n",
      "[4]\ttrain's binary_logloss: 0.600501\n",
      "[5]\ttrain's binary_logloss: 0.585878\n",
      "[6]\ttrain's binary_logloss: 0.573603\n",
      "[7]\ttrain's binary_logloss: 0.562965\n",
      "[8]\ttrain's binary_logloss: 0.553485\n",
      "[9]\ttrain's binary_logloss: 0.545568\n",
      "[10]\ttrain's binary_logloss: 0.538341\n",
      "[11]\ttrain's binary_logloss: 0.53218\n",
      "[12]\ttrain's binary_logloss: 0.526888\n",
      "[13]\ttrain's binary_logloss: 0.521507\n",
      "[14]\ttrain's binary_logloss: 0.516283\n",
      "[15]\ttrain's binary_logloss: 0.511686\n",
      "[16]\ttrain's binary_logloss: 0.507458\n",
      "[17]\ttrain's binary_logloss: 0.502668\n",
      "[18]\ttrain's binary_logloss: 0.498687\n",
      "[19]\ttrain's binary_logloss: 0.494656\n",
      "[20]\ttrain's binary_logloss: 0.491561\n",
      "[21]\ttrain's binary_logloss: 0.488351\n",
      "[22]\ttrain's binary_logloss: 0.485573\n",
      "[23]\ttrain's binary_logloss: 0.482171\n",
      "[24]\ttrain's binary_logloss: 0.479149\n",
      "[25]\ttrain's binary_logloss: 0.476664\n",
      "[26]\ttrain's binary_logloss: 0.473929\n",
      "[27]\ttrain's binary_logloss: 0.471448\n",
      "[28]\ttrain's binary_logloss: 0.469294\n",
      "[29]\ttrain's binary_logloss: 0.466646\n",
      "[30]\ttrain's binary_logloss: 0.463765\n",
      "[31]\ttrain's binary_logloss: 0.461489\n",
      "[32]\ttrain's binary_logloss: 0.45924\n",
      "[33]\ttrain's binary_logloss: 0.456848\n",
      "[34]\ttrain's binary_logloss: 0.454888\n",
      "[35]\ttrain's binary_logloss: 0.452506\n",
      "[36]\ttrain's binary_logloss: 0.450764\n",
      "[37]\ttrain's binary_logloss: 0.448826\n",
      "[38]\ttrain's binary_logloss: 0.446645\n",
      "[39]\ttrain's binary_logloss: 0.444878\n",
      "[40]\ttrain's binary_logloss: 0.44312\n",
      "[41]\ttrain's binary_logloss: 0.441225\n",
      "[42]\ttrain's binary_logloss: 0.43862\n",
      "[43]\ttrain's binary_logloss: 0.43714\n",
      "[44]\ttrain's binary_logloss: 0.435454\n",
      "[45]\ttrain's binary_logloss: 0.433442\n",
      "[46]\ttrain's binary_logloss: 0.431905\n",
      "[47]\ttrain's binary_logloss: 0.430126\n",
      "[48]\ttrain's binary_logloss: 0.428234\n",
      "[49]\ttrain's binary_logloss: 0.42696\n",
      "[50]\ttrain's binary_logloss: 0.424765\n",
      "[51]\ttrain's binary_logloss: 0.423088\n",
      "[52]\ttrain's binary_logloss: 0.421902\n",
      "[53]\ttrain's binary_logloss: 0.420318\n",
      "[54]\ttrain's binary_logloss: 0.418909\n",
      "[55]\ttrain's binary_logloss: 0.417007\n",
      "[56]\ttrain's binary_logloss: 0.415208\n",
      "[57]\ttrain's binary_logloss: 0.413514\n",
      "[58]\ttrain's binary_logloss: 0.412293\n",
      "[59]\ttrain's binary_logloss: 0.411102\n",
      "[60]\ttrain's binary_logloss: 0.40967\n",
      "[61]\ttrain's binary_logloss: 0.407243\n",
      "[62]\ttrain's binary_logloss: 0.40599\n",
      "[63]\ttrain's binary_logloss: 0.404919\n",
      "[64]\ttrain's binary_logloss: 0.403409\n",
      "[65]\ttrain's binary_logloss: 0.402214\n",
      "[66]\ttrain's binary_logloss: 0.400646\n",
      "[67]\ttrain's binary_logloss: 0.398702\n",
      "[68]\ttrain's binary_logloss: 0.397395\n",
      "[69]\ttrain's binary_logloss: 0.395586\n",
      "[70]\ttrain's binary_logloss: 0.393765\n",
      "[71]\ttrain's binary_logloss: 0.392805\n",
      "[72]\ttrain's binary_logloss: 0.391712\n",
      "[73]\ttrain's binary_logloss: 0.390657\n",
      "[74]\ttrain's binary_logloss: 0.388989\n",
      "[75]\ttrain's binary_logloss: 0.38764\n",
      "[76]\ttrain's binary_logloss: 0.386751\n",
      "[77]\ttrain's binary_logloss: 0.384699\n",
      "[78]\ttrain's binary_logloss: 0.382528\n",
      "[79]\ttrain's binary_logloss: 0.381192\n",
      "[80]\ttrain's binary_logloss: 0.380259\n",
      "[81]\ttrain's binary_logloss: 0.378934\n",
      "[82]\ttrain's binary_logloss: 0.377976\n",
      "[83]\ttrain's binary_logloss: 0.376874\n",
      "[84]\ttrain's binary_logloss: 0.375969\n",
      "[85]\ttrain's binary_logloss: 0.374852\n",
      "[86]\ttrain's binary_logloss: 0.373135\n",
      "[87]\ttrain's binary_logloss: 0.371574\n",
      "[88]\ttrain's binary_logloss: 0.370593\n",
      "[89]\ttrain's binary_logloss: 0.369757\n",
      "[90]\ttrain's binary_logloss: 0.368328\n",
      "[91]\ttrain's binary_logloss: 0.367325\n",
      "[92]\ttrain's binary_logloss: 0.36639\n",
      "[93]\ttrain's binary_logloss: 0.365162\n",
      "[94]\ttrain's binary_logloss: 0.364408\n",
      "[95]\ttrain's binary_logloss: 0.362858\n",
      "[96]\ttrain's binary_logloss: 0.360926\n",
      "[97]\ttrain's binary_logloss: 0.35941\n",
      "[98]\ttrain's binary_logloss: 0.358207\n",
      "[99]\ttrain's binary_logloss: 0.357537\n",
      "[100]\ttrain's binary_logloss: 0.356465\n",
      "[101]\ttrain's binary_logloss: 0.355643\n",
      "[102]\ttrain's binary_logloss: 0.354476\n",
      "[103]\ttrain's binary_logloss: 0.353127\n",
      "[104]\ttrain's binary_logloss: 0.352091\n",
      "[105]\ttrain's binary_logloss: 0.350762\n",
      "[106]\ttrain's binary_logloss: 0.349704\n",
      "[107]\ttrain's binary_logloss: 0.348859\n",
      "[108]\ttrain's binary_logloss: 0.347836\n",
      "[109]\ttrain's binary_logloss: 0.346703\n",
      "[110]\ttrain's binary_logloss: 0.345726\n",
      "[111]\ttrain's binary_logloss: 0.344929\n",
      "[112]\ttrain's binary_logloss: 0.344232\n",
      "[113]\ttrain's binary_logloss: 0.343464\n",
      "[114]\ttrain's binary_logloss: 0.342828\n",
      "[115]\ttrain's binary_logloss: 0.341282\n",
      "[116]\ttrain's binary_logloss: 0.339423\n",
      "[117]\ttrain's binary_logloss: 0.338747\n",
      "[118]\ttrain's binary_logloss: 0.337414\n",
      "[119]\ttrain's binary_logloss: 0.336814\n",
      "[120]\ttrain's binary_logloss: 0.335958\n",
      "[121]\ttrain's binary_logloss: 0.335146\n",
      "[122]\ttrain's binary_logloss: 0.333571\n",
      "[123]\ttrain's binary_logloss: 0.332564\n",
      "[124]\ttrain's binary_logloss: 0.331984\n",
      "[125]\ttrain's binary_logloss: 0.331224\n",
      "[126]\ttrain's binary_logloss: 0.33044\n",
      "[127]\ttrain's binary_logloss: 0.32974\n",
      "[128]\ttrain's binary_logloss: 0.328766\n",
      "[129]\ttrain's binary_logloss: 0.327988\n",
      "[130]\ttrain's binary_logloss: 0.327226\n",
      "[131]\ttrain's binary_logloss: 0.326293\n",
      "[132]\ttrain's binary_logloss: 0.325219\n",
      "[133]\ttrain's binary_logloss: 0.323711\n",
      "[134]\ttrain's binary_logloss: 0.323081\n",
      "[135]\ttrain's binary_logloss: 0.321718\n",
      "[136]\ttrain's binary_logloss: 0.321142\n",
      "[137]\ttrain's binary_logloss: 0.320328\n",
      "[138]\ttrain's binary_logloss: 0.319378\n",
      "[139]\ttrain's binary_logloss: 0.318822\n",
      "[140]\ttrain's binary_logloss: 0.317859\n",
      "[141]\ttrain's binary_logloss: 0.31729\n",
      "[142]\ttrain's binary_logloss: 0.316314\n",
      "[143]\ttrain's binary_logloss: 0.315594\n",
      "[144]\ttrain's binary_logloss: 0.314675\n",
      "[145]\ttrain's binary_logloss: 0.313575\n",
      "[146]\ttrain's binary_logloss: 0.312904\n",
      "[147]\ttrain's binary_logloss: 0.31207\n",
      "[148]\ttrain's binary_logloss: 0.311461\n",
      "[149]\ttrain's binary_logloss: 0.310867\n",
      "[150]\ttrain's binary_logloss: 0.309872\n",
      "[151]\ttrain's binary_logloss: 0.309071\n",
      "[152]\ttrain's binary_logloss: 0.308102\n",
      "[153]\ttrain's binary_logloss: 0.307219\n",
      "[154]\ttrain's binary_logloss: 0.306427\n",
      "[155]\ttrain's binary_logloss: 0.305771\n",
      "[156]\ttrain's binary_logloss: 0.304692\n",
      "[157]\ttrain's binary_logloss: 0.303829\n",
      "[158]\ttrain's binary_logloss: 0.302958\n",
      "[159]\ttrain's binary_logloss: 0.302515\n",
      "[160]\ttrain's binary_logloss: 0.301781\n",
      "[161]\ttrain's binary_logloss: 0.301218\n",
      "[162]\ttrain's binary_logloss: 0.30076\n",
      "[163]\ttrain's binary_logloss: 0.299788\n",
      "[164]\ttrain's binary_logloss: 0.299011\n",
      "[165]\ttrain's binary_logloss: 0.298209\n",
      "[166]\ttrain's binary_logloss: 0.297688\n",
      "[167]\ttrain's binary_logloss: 0.296928\n",
      "[168]\ttrain's binary_logloss: 0.296486\n",
      "[169]\ttrain's binary_logloss: 0.295689\n",
      "[170]\ttrain's binary_logloss: 0.295135\n",
      "[171]\ttrain's binary_logloss: 0.293992\n",
      "[172]\ttrain's binary_logloss: 0.293065\n",
      "[173]\ttrain's binary_logloss: 0.292238\n",
      "[174]\ttrain's binary_logloss: 0.291605\n",
      "[175]\ttrain's binary_logloss: 0.290909\n",
      "[176]\ttrain's binary_logloss: 0.290163\n",
      "[177]\ttrain's binary_logloss: 0.289679\n",
      "[178]\ttrain's binary_logloss: 0.288876\n",
      "[179]\ttrain's binary_logloss: 0.287826\n",
      "[180]\ttrain's binary_logloss: 0.286768\n",
      "[181]\ttrain's binary_logloss: 0.2861\n",
      "[182]\ttrain's binary_logloss: 0.285568\n",
      "[183]\ttrain's binary_logloss: 0.285031\n",
      "[184]\ttrain's binary_logloss: 0.284179\n",
      "[185]\ttrain's binary_logloss: 0.28348\n",
      "[186]\ttrain's binary_logloss: 0.282782\n",
      "[187]\ttrain's binary_logloss: 0.282188\n",
      "[188]\ttrain's binary_logloss: 0.281734\n",
      "[189]\ttrain's binary_logloss: 0.28121\n",
      "[190]\ttrain's binary_logloss: 0.280441\n",
      "[191]\ttrain's binary_logloss: 0.279909\n",
      "[192]\ttrain's binary_logloss: 0.27899\n",
      "[193]\ttrain's binary_logloss: 0.278616\n",
      "[194]\ttrain's binary_logloss: 0.278\n",
      "[195]\ttrain's binary_logloss: 0.277302\n",
      "[196]\ttrain's binary_logloss: 0.276416\n",
      "[197]\ttrain's binary_logloss: 0.275802\n",
      "[198]\ttrain's binary_logloss: 0.275207\n",
      "[199]\ttrain's binary_logloss: 0.274815\n",
      "[200]\ttrain's binary_logloss: 0.274167\n",
      "[201]\ttrain's binary_logloss: 0.273716\n",
      "[202]\ttrain's binary_logloss: 0.272815\n",
      "[203]\ttrain's binary_logloss: 0.272177\n",
      "[204]\ttrain's binary_logloss: 0.271436\n",
      "[205]\ttrain's binary_logloss: 0.270776\n",
      "[206]\ttrain's binary_logloss: 0.270229\n",
      "[207]\ttrain's binary_logloss: 0.269779\n",
      "[208]\ttrain's binary_logloss: 0.269004\n",
      "[209]\ttrain's binary_logloss: 0.267872\n",
      "[210]\ttrain's binary_logloss: 0.267196\n",
      "[211]\ttrain's binary_logloss: 0.266571\n",
      "[212]\ttrain's binary_logloss: 0.26598\n",
      "[213]\ttrain's binary_logloss: 0.265654\n",
      "[214]\ttrain's binary_logloss: 0.264831\n",
      "[215]\ttrain's binary_logloss: 0.263983\n",
      "[216]\ttrain's binary_logloss: 0.262875\n",
      "[217]\ttrain's binary_logloss: 0.26229\n",
      "[218]\ttrain's binary_logloss: 0.26172\n",
      "[219]\ttrain's binary_logloss: 0.260831\n",
      "[220]\ttrain's binary_logloss: 0.260221\n",
      "[221]\ttrain's binary_logloss: 0.259489\n",
      "[222]\ttrain's binary_logloss: 0.258778\n",
      "[223]\ttrain's binary_logloss: 0.25811\n",
      "[224]\ttrain's binary_logloss: 0.257694\n",
      "[225]\ttrain's binary_logloss: 0.257083\n",
      "[226]\ttrain's binary_logloss: 0.256652\n",
      "[227]\ttrain's binary_logloss: 0.255637\n",
      "[228]\ttrain's binary_logloss: 0.255275\n",
      "[229]\ttrain's binary_logloss: 0.25436\n",
      "[230]\ttrain's binary_logloss: 0.253792\n",
      "[231]\ttrain's binary_logloss: 0.253338\n",
      "[232]\ttrain's binary_logloss: 0.252984\n",
      "[233]\ttrain's binary_logloss: 0.252331\n",
      "[234]\ttrain's binary_logloss: 0.251858\n",
      "[235]\ttrain's binary_logloss: 0.251312\n",
      "[236]\ttrain's binary_logloss: 0.250489\n",
      "[237]\ttrain's binary_logloss: 0.250099\n",
      "[238]\ttrain's binary_logloss: 0.249802\n",
      "[239]\ttrain's binary_logloss: 0.249211\n",
      "[240]\ttrain's binary_logloss: 0.24873\n",
      "[241]\ttrain's binary_logloss: 0.248368\n",
      "[242]\ttrain's binary_logloss: 0.247962\n",
      "[243]\ttrain's binary_logloss: 0.247223\n",
      "[244]\ttrain's binary_logloss: 0.246523\n",
      "[245]\ttrain's binary_logloss: 0.245704\n",
      "[246]\ttrain's binary_logloss: 0.245339\n",
      "[247]\ttrain's binary_logloss: 0.244785\n",
      "[248]\ttrain's binary_logloss: 0.244489\n",
      "[249]\ttrain's binary_logloss: 0.244123\n",
      "[250]\ttrain's binary_logloss: 0.243491\n",
      "[251]\ttrain's binary_logloss: 0.242877\n",
      "[252]\ttrain's binary_logloss: 0.24253\n",
      "[253]\ttrain's binary_logloss: 0.242084\n",
      "[254]\ttrain's binary_logloss: 0.241631\n",
      "[255]\ttrain's binary_logloss: 0.241128\n",
      "[256]\ttrain's binary_logloss: 0.240535\n",
      "[257]\ttrain's binary_logloss: 0.240056\n",
      "[258]\ttrain's binary_logloss: 0.23977\n",
      "[259]\ttrain's binary_logloss: 0.239386\n",
      "[260]\ttrain's binary_logloss: 0.238696\n",
      "[261]\ttrain's binary_logloss: 0.238307\n",
      "[262]\ttrain's binary_logloss: 0.237724\n",
      "[263]\ttrain's binary_logloss: 0.23714\n",
      "[264]\ttrain's binary_logloss: 0.236582\n",
      "[265]\ttrain's binary_logloss: 0.236232\n",
      "[266]\ttrain's binary_logloss: 0.235868\n",
      "[267]\ttrain's binary_logloss: 0.235129\n",
      "[268]\ttrain's binary_logloss: 0.234585\n",
      "[269]\ttrain's binary_logloss: 0.23423\n",
      "[270]\ttrain's binary_logloss: 0.233736\n",
      "[271]\ttrain's binary_logloss: 0.233189\n",
      "[272]\ttrain's binary_logloss: 0.232941\n",
      "[273]\ttrain's binary_logloss: 0.23242\n",
      "[274]\ttrain's binary_logloss: 0.231679\n",
      "[275]\ttrain's binary_logloss: 0.231218\n",
      "[276]\ttrain's binary_logloss: 0.23099\n",
      "[277]\ttrain's binary_logloss: 0.230563\n",
      "[278]\ttrain's binary_logloss: 0.229942\n",
      "[279]\ttrain's binary_logloss: 0.229532\n",
      "[280]\ttrain's binary_logloss: 0.22913\n",
      "[281]\ttrain's binary_logloss: 0.228747\n",
      "[282]\ttrain's binary_logloss: 0.227907\n",
      "[283]\ttrain's binary_logloss: 0.227236\n",
      "[284]\ttrain's binary_logloss: 0.226918\n",
      "[285]\ttrain's binary_logloss: 0.226609\n",
      "[286]\ttrain's binary_logloss: 0.226241\n",
      "[287]\ttrain's binary_logloss: 0.2259\n",
      "[288]\ttrain's binary_logloss: 0.225565\n",
      "[289]\ttrain's binary_logloss: 0.225198\n",
      "[290]\ttrain's binary_logloss: 0.224945\n",
      "[291]\ttrain's binary_logloss: 0.224465\n",
      "[292]\ttrain's binary_logloss: 0.224152\n",
      "[293]\ttrain's binary_logloss: 0.223747\n",
      "[294]\ttrain's binary_logloss: 0.223332\n",
      "[295]\ttrain's binary_logloss: 0.223046\n",
      "[296]\ttrain's binary_logloss: 0.222285\n",
      "[297]\ttrain's binary_logloss: 0.221907\n",
      "[298]\ttrain's binary_logloss: 0.221567\n",
      "[299]\ttrain's binary_logloss: 0.221273\n",
      "[300]\ttrain's binary_logloss: 0.220611\n",
      "[301]\ttrain's binary_logloss: 0.220213\n",
      "[302]\ttrain's binary_logloss: 0.21992\n",
      "[303]\ttrain's binary_logloss: 0.219641\n",
      "[304]\ttrain's binary_logloss: 0.219161\n",
      "[305]\ttrain's binary_logloss: 0.218723\n",
      "[306]\ttrain's binary_logloss: 0.218309\n",
      "[307]\ttrain's binary_logloss: 0.21755\n",
      "[308]\ttrain's binary_logloss: 0.217223\n",
      "[309]\ttrain's binary_logloss: 0.216722\n",
      "[310]\ttrain's binary_logloss: 0.216242\n",
      "[311]\ttrain's binary_logloss: 0.216004\n",
      "[312]\ttrain's binary_logloss: 0.215234\n",
      "[313]\ttrain's binary_logloss: 0.214731\n",
      "[314]\ttrain's binary_logloss: 0.214299\n",
      "[315]\ttrain's binary_logloss: 0.213988\n",
      "[316]\ttrain's binary_logloss: 0.213743\n",
      "[317]\ttrain's binary_logloss: 0.21342\n",
      "[318]\ttrain's binary_logloss: 0.212993\n",
      "[319]\ttrain's binary_logloss: 0.212576\n",
      "[320]\ttrain's binary_logloss: 0.21198\n",
      "[321]\ttrain's binary_logloss: 0.211424\n",
      "[322]\ttrain's binary_logloss: 0.21098\n",
      "[323]\ttrain's binary_logloss: 0.210717\n",
      "[324]\ttrain's binary_logloss: 0.210308\n",
      "[325]\ttrain's binary_logloss: 0.209841\n",
      "[326]\ttrain's binary_logloss: 0.208946\n",
      "[327]\ttrain's binary_logloss: 0.208284\n",
      "[328]\ttrain's binary_logloss: 0.207906\n",
      "[329]\ttrain's binary_logloss: 0.207541\n",
      "[330]\ttrain's binary_logloss: 0.207287\n",
      "[331]\ttrain's binary_logloss: 0.206782\n",
      "[332]\ttrain's binary_logloss: 0.206542\n",
      "[333]\ttrain's binary_logloss: 0.205731\n",
      "[334]\ttrain's binary_logloss: 0.20523\n",
      "[335]\ttrain's binary_logloss: 0.204782\n",
      "[336]\ttrain's binary_logloss: 0.204562\n",
      "[337]\ttrain's binary_logloss: 0.204267\n",
      "[338]\ttrain's binary_logloss: 0.204085\n",
      "[339]\ttrain's binary_logloss: 0.203701\n",
      "[340]\ttrain's binary_logloss: 0.203224\n",
      "[341]\ttrain's binary_logloss: 0.202829\n",
      "[342]\ttrain's binary_logloss: 0.202252\n",
      "[343]\ttrain's binary_logloss: 0.201751\n",
      "[344]\ttrain's binary_logloss: 0.201267\n",
      "[345]\ttrain's binary_logloss: 0.200805\n",
      "[346]\ttrain's binary_logloss: 0.200549\n",
      "[347]\ttrain's binary_logloss: 0.200051\n",
      "[348]\ttrain's binary_logloss: 0.199563\n",
      "[349]\ttrain's binary_logloss: 0.199131\n",
      "[350]\ttrain's binary_logloss: 0.198731\n",
      "[351]\ttrain's binary_logloss: 0.1983\n",
      "[352]\ttrain's binary_logloss: 0.197941\n",
      "[353]\ttrain's binary_logloss: 0.197673\n",
      "[354]\ttrain's binary_logloss: 0.197497\n",
      "[355]\ttrain's binary_logloss: 0.197346\n",
      "[356]\ttrain's binary_logloss: 0.196909\n",
      "[357]\ttrain's binary_logloss: 0.196737\n",
      "[358]\ttrain's binary_logloss: 0.196233\n",
      "[359]\ttrain's binary_logloss: 0.195819\n",
      "[360]\ttrain's binary_logloss: 0.195374\n",
      "[361]\ttrain's binary_logloss: 0.194856\n",
      "[362]\ttrain's binary_logloss: 0.194501\n",
      "[363]\ttrain's binary_logloss: 0.194192\n",
      "[364]\ttrain's binary_logloss: 0.193896\n",
      "[365]\ttrain's binary_logloss: 0.193524\n",
      "[366]\ttrain's binary_logloss: 0.193074\n",
      "[367]\ttrain's binary_logloss: 0.192726\n",
      "[368]\ttrain's binary_logloss: 0.192346\n",
      "[369]\ttrain's binary_logloss: 0.19207\n",
      "[370]\ttrain's binary_logloss: 0.191551\n",
      "[371]\ttrain's binary_logloss: 0.19121\n",
      "[372]\ttrain's binary_logloss: 0.190668\n",
      "[373]\ttrain's binary_logloss: 0.190357\n",
      "[374]\ttrain's binary_logloss: 0.189708\n",
      "[375]\ttrain's binary_logloss: 0.189166\n",
      "[376]\ttrain's binary_logloss: 0.188481\n",
      "[377]\ttrain's binary_logloss: 0.187923\n",
      "[378]\ttrain's binary_logloss: 0.187387\n",
      "[379]\ttrain's binary_logloss: 0.186829\n",
      "[380]\ttrain's binary_logloss: 0.186359\n",
      "[381]\ttrain's binary_logloss: 0.186049\n",
      "[382]\ttrain's binary_logloss: 0.185431\n",
      "[383]\ttrain's binary_logloss: 0.184966\n",
      "[384]\ttrain's binary_logloss: 0.184586\n",
      "[385]\ttrain's binary_logloss: 0.183982\n",
      "[386]\ttrain's binary_logloss: 0.183568\n",
      "[387]\ttrain's binary_logloss: 0.183413\n",
      "[388]\ttrain's binary_logloss: 0.182946\n",
      "[389]\ttrain's binary_logloss: 0.182525\n",
      "[390]\ttrain's binary_logloss: 0.181952\n",
      "[391]\ttrain's binary_logloss: 0.181528\n",
      "[392]\ttrain's binary_logloss: 0.18083\n",
      "[393]\ttrain's binary_logloss: 0.180543\n",
      "[394]\ttrain's binary_logloss: 0.180241\n",
      "[395]\ttrain's binary_logloss: 0.179704\n",
      "[396]\ttrain's binary_logloss: 0.179356\n",
      "[397]\ttrain's binary_logloss: 0.179073\n",
      "[398]\ttrain's binary_logloss: 0.178589\n",
      "[399]\ttrain's binary_logloss: 0.178339\n",
      "[400]\ttrain's binary_logloss: 0.17809\n",
      "[401]\ttrain's binary_logloss: 0.177719\n",
      "[402]\ttrain's binary_logloss: 0.177188\n",
      "[403]\ttrain's binary_logloss: 0.176908\n",
      "[404]\ttrain's binary_logloss: 0.176348\n",
      "[405]\ttrain's binary_logloss: 0.176101\n",
      "[406]\ttrain's binary_logloss: 0.175761\n",
      "[407]\ttrain's binary_logloss: 0.175526\n",
      "[408]\ttrain's binary_logloss: 0.175253\n",
      "[409]\ttrain's binary_logloss: 0.174833\n",
      "[410]\ttrain's binary_logloss: 0.174486\n",
      "[411]\ttrain's binary_logloss: 0.174289\n",
      "[412]\ttrain's binary_logloss: 0.173642\n",
      "[413]\ttrain's binary_logloss: 0.173361\n",
      "[414]\ttrain's binary_logloss: 0.172989\n",
      "[415]\ttrain's binary_logloss: 0.172507\n",
      "[416]\ttrain's binary_logloss: 0.17226\n",
      "[417]\ttrain's binary_logloss: 0.171865\n",
      "[418]\ttrain's binary_logloss: 0.171421\n",
      "[419]\ttrain's binary_logloss: 0.171136\n",
      "[420]\ttrain's binary_logloss: 0.170918\n",
      "[421]\ttrain's binary_logloss: 0.170276\n",
      "[422]\ttrain's binary_logloss: 0.169918\n",
      "[423]\ttrain's binary_logloss: 0.169643\n",
      "[424]\ttrain's binary_logloss: 0.169293\n",
      "[425]\ttrain's binary_logloss: 0.169112\n",
      "[426]\ttrain's binary_logloss: 0.16862\n",
      "[427]\ttrain's binary_logloss: 0.168273\n",
      "[428]\ttrain's binary_logloss: 0.167871\n",
      "[429]\ttrain's binary_logloss: 0.167623\n",
      "[430]\ttrain's binary_logloss: 0.167426\n",
      "[431]\ttrain's binary_logloss: 0.166944\n",
      "[432]\ttrain's binary_logloss: 0.166616\n",
      "[433]\ttrain's binary_logloss: 0.166257\n",
      "[434]\ttrain's binary_logloss: 0.166075\n",
      "[435]\ttrain's binary_logloss: 0.165558\n",
      "[436]\ttrain's binary_logloss: 0.165281\n",
      "[437]\ttrain's binary_logloss: 0.165056\n",
      "[438]\ttrain's binary_logloss: 0.164855\n",
      "[439]\ttrain's binary_logloss: 0.164418\n",
      "[440]\ttrain's binary_logloss: 0.163917\n",
      "[441]\ttrain's binary_logloss: 0.163484\n",
      "[442]\ttrain's binary_logloss: 0.163367\n",
      "[443]\ttrain's binary_logloss: 0.163146\n",
      "[444]\ttrain's binary_logloss: 0.162918\n",
      "[445]\ttrain's binary_logloss: 0.1626\n",
      "[446]\ttrain's binary_logloss: 0.162193\n",
      "[447]\ttrain's binary_logloss: 0.16195\n",
      "[448]\ttrain's binary_logloss: 0.161755\n",
      "[449]\ttrain's binary_logloss: 0.16139\n",
      "[450]\ttrain's binary_logloss: 0.16113\n",
      "[451]\ttrain's binary_logloss: 0.160798\n",
      "[452]\ttrain's binary_logloss: 0.160367\n",
      "[453]\ttrain's binary_logloss: 0.160173\n",
      "[454]\ttrain's binary_logloss: 0.160004\n",
      "[455]\ttrain's binary_logloss: 0.159851\n",
      "[456]\ttrain's binary_logloss: 0.15963\n",
      "[457]\ttrain's binary_logloss: 0.159342\n",
      "[458]\ttrain's binary_logloss: 0.158956\n",
      "[459]\ttrain's binary_logloss: 0.158747\n",
      "[460]\ttrain's binary_logloss: 0.158549\n",
      "[461]\ttrain's binary_logloss: 0.158198\n",
      "[462]\ttrain's binary_logloss: 0.157527\n",
      "[463]\ttrain's binary_logloss: 0.157263\n",
      "[464]\ttrain's binary_logloss: 0.157004\n",
      "[465]\ttrain's binary_logloss: 0.156493\n",
      "[466]\ttrain's binary_logloss: 0.156155\n",
      "[467]\ttrain's binary_logloss: 0.156\n",
      "[468]\ttrain's binary_logloss: 0.155591\n",
      "[469]\ttrain's binary_logloss: 0.154938\n",
      "[470]\ttrain's binary_logloss: 0.154755\n",
      "[471]\ttrain's binary_logloss: 0.154591\n",
      "[472]\ttrain's binary_logloss: 0.154373\n",
      "[473]\ttrain's binary_logloss: 0.154156\n",
      "[474]\ttrain's binary_logloss: 0.153797\n",
      "[475]\ttrain's binary_logloss: 0.153479\n",
      "[476]\ttrain's binary_logloss: 0.153004\n",
      "[477]\ttrain's binary_logloss: 0.152814\n",
      "[478]\ttrain's binary_logloss: 0.152484\n",
      "[479]\ttrain's binary_logloss: 0.152381\n",
      "[480]\ttrain's binary_logloss: 0.15209\n",
      "[481]\ttrain's binary_logloss: 0.151521\n",
      "[482]\ttrain's binary_logloss: 0.151195\n",
      "[483]\ttrain's binary_logloss: 0.150919\n",
      "[484]\ttrain's binary_logloss: 0.150498\n",
      "[485]\ttrain's binary_logloss: 0.150235\n",
      "[486]\ttrain's binary_logloss: 0.15008\n",
      "[487]\ttrain's binary_logloss: 0.149875\n",
      "[488]\ttrain's binary_logloss: 0.1497\n",
      "[489]\ttrain's binary_logloss: 0.149427\n",
      "[490]\ttrain's binary_logloss: 0.148995\n",
      "[491]\ttrain's binary_logloss: 0.148707\n",
      "[492]\ttrain's binary_logloss: 0.148535\n",
      "[493]\ttrain's binary_logloss: 0.148291\n",
      "[494]\ttrain's binary_logloss: 0.148023\n",
      "[495]\ttrain's binary_logloss: 0.1476\n",
      "[496]\ttrain's binary_logloss: 0.147413\n",
      "[497]\ttrain's binary_logloss: 0.147097\n",
      "[498]\ttrain's binary_logloss: 0.146752\n",
      "[499]\ttrain's binary_logloss: 0.146375\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "[0]\ttest-logloss:0.59573\n",
      "[1]\ttest-logloss:0.58371\n",
      "[2]\ttest-logloss:0.57642\n",
      "[3]\ttest-logloss:0.58736\n",
      "[4]\ttest-logloss:0.58414\n",
      "[5]\ttest-logloss:0.58967\n",
      "[6]\ttest-logloss:0.59291\n",
      "[7]\ttest-logloss:0.59738\n",
      "[8]\ttest-logloss:0.59849\n",
      "[9]\ttest-logloss:0.59946\n",
      "[10]\ttest-logloss:0.60594\n",
      "[11]\ttest-logloss:0.60589\n",
      "[12]\ttest-logloss:0.60974\n",
      "[13]\ttest-logloss:0.60995\n",
      "[14]\ttest-logloss:0.61244\n",
      "[15]\ttest-logloss:0.61994\n",
      "[16]\ttest-logloss:0.62884\n",
      "[17]\ttest-logloss:0.63393\n",
      "[18]\ttest-logloss:0.63189\n",
      "[19]\ttest-logloss:0.62428\n",
      "[20]\ttest-logloss:0.63861\n",
      "[21]\ttest-logloss:0.63952\n",
      "X_trainの形状： (646, 24)  y_trainの形状： (646,)  X_testの形状： (278, 24)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.662906\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.638297\n",
      "[3]\ttrain's binary_logloss: 0.617479\n",
      "[4]\ttrain's binary_logloss: 0.600501\n",
      "[5]\ttrain's binary_logloss: 0.585878\n",
      "[6]\ttrain's binary_logloss: 0.573603\n",
      "[7]\ttrain's binary_logloss: 0.562965\n",
      "[8]\ttrain's binary_logloss: 0.553485\n",
      "[9]\ttrain's binary_logloss: 0.545568\n",
      "[10]\ttrain's binary_logloss: 0.538341\n",
      "[11]\ttrain's binary_logloss: 0.53218\n",
      "[12]\ttrain's binary_logloss: 0.526888\n",
      "[13]\ttrain's binary_logloss: 0.521507\n",
      "[14]\ttrain's binary_logloss: 0.516283\n",
      "[15]\ttrain's binary_logloss: 0.511686\n",
      "[16]\ttrain's binary_logloss: 0.507458\n",
      "[17]\ttrain's binary_logloss: 0.502668\n",
      "[18]\ttrain's binary_logloss: 0.498687\n",
      "[19]\ttrain's binary_logloss: 0.494656\n",
      "[20]\ttrain's binary_logloss: 0.491561\n",
      "[21]\ttrain's binary_logloss: 0.488351\n",
      "[22]\ttrain's binary_logloss: 0.485573\n",
      "[23]\ttrain's binary_logloss: 0.482171\n",
      "[24]\ttrain's binary_logloss: 0.479149\n",
      "[25]\ttrain's binary_logloss: 0.476664\n",
      "[26]\ttrain's binary_logloss: 0.473929\n",
      "[27]\ttrain's binary_logloss: 0.471448\n",
      "[28]\ttrain's binary_logloss: 0.469294\n",
      "[29]\ttrain's binary_logloss: 0.466646\n",
      "[30]\ttrain's binary_logloss: 0.463765\n",
      "[31]\ttrain's binary_logloss: 0.461489\n",
      "[32]\ttrain's binary_logloss: 0.45924\n",
      "[33]\ttrain's binary_logloss: 0.456848\n",
      "[34]\ttrain's binary_logloss: 0.454888\n",
      "[35]\ttrain's binary_logloss: 0.452506\n",
      "[36]\ttrain's binary_logloss: 0.450764\n",
      "[37]\ttrain's binary_logloss: 0.448826\n",
      "[38]\ttrain's binary_logloss: 0.446645\n",
      "[39]\ttrain's binary_logloss: 0.444878\n",
      "[40]\ttrain's binary_logloss: 0.44312\n",
      "[41]\ttrain's binary_logloss: 0.441225\n",
      "[42]\ttrain's binary_logloss: 0.43862\n",
      "[43]\ttrain's binary_logloss: 0.43714\n",
      "[44]\ttrain's binary_logloss: 0.435454\n",
      "[45]\ttrain's binary_logloss: 0.433442\n",
      "[46]\ttrain's binary_logloss: 0.431905\n",
      "[47]\ttrain's binary_logloss: 0.430126\n",
      "[48]\ttrain's binary_logloss: 0.428234\n",
      "[49]\ttrain's binary_logloss: 0.42696\n",
      "[50]\ttrain's binary_logloss: 0.424765\n",
      "[51]\ttrain's binary_logloss: 0.423088\n",
      "[52]\ttrain's binary_logloss: 0.421902\n",
      "[53]\ttrain's binary_logloss: 0.420318\n",
      "[54]\ttrain's binary_logloss: 0.418909\n",
      "[55]\ttrain's binary_logloss: 0.417007\n",
      "[56]\ttrain's binary_logloss: 0.415208\n",
      "[57]\ttrain's binary_logloss: 0.413514\n",
      "[58]\ttrain's binary_logloss: 0.412293\n",
      "[59]\ttrain's binary_logloss: 0.411102\n",
      "[60]\ttrain's binary_logloss: 0.40967\n",
      "[61]\ttrain's binary_logloss: 0.407243\n",
      "[62]\ttrain's binary_logloss: 0.40599\n",
      "[63]\ttrain's binary_logloss: 0.404919\n",
      "[64]\ttrain's binary_logloss: 0.403409\n",
      "[65]\ttrain's binary_logloss: 0.402214\n",
      "[66]\ttrain's binary_logloss: 0.400646\n",
      "[67]\ttrain's binary_logloss: 0.398702\n",
      "[68]\ttrain's binary_logloss: 0.397395\n",
      "[69]\ttrain's binary_logloss: 0.395586\n",
      "[70]\ttrain's binary_logloss: 0.393765\n",
      "[71]\ttrain's binary_logloss: 0.392805\n",
      "[72]\ttrain's binary_logloss: 0.391712\n",
      "[73]\ttrain's binary_logloss: 0.390657\n",
      "[74]\ttrain's binary_logloss: 0.388989\n",
      "[75]\ttrain's binary_logloss: 0.38764\n",
      "[76]\ttrain's binary_logloss: 0.386751\n",
      "[77]\ttrain's binary_logloss: 0.384699\n",
      "[78]\ttrain's binary_logloss: 0.382528\n",
      "[79]\ttrain's binary_logloss: 0.381192\n",
      "[80]\ttrain's binary_logloss: 0.380259\n",
      "[81]\ttrain's binary_logloss: 0.378934\n",
      "[82]\ttrain's binary_logloss: 0.377976\n",
      "[83]\ttrain's binary_logloss: 0.376874\n",
      "[84]\ttrain's binary_logloss: 0.375969\n",
      "[85]\ttrain's binary_logloss: 0.374852\n",
      "[86]\ttrain's binary_logloss: 0.373135\n",
      "[87]\ttrain's binary_logloss: 0.371574\n",
      "[88]\ttrain's binary_logloss: 0.370593\n",
      "[89]\ttrain's binary_logloss: 0.369757\n",
      "[90]\ttrain's binary_logloss: 0.368328\n",
      "[91]\ttrain's binary_logloss: 0.367325\n",
      "[92]\ttrain's binary_logloss: 0.36639\n",
      "[93]\ttrain's binary_logloss: 0.365162\n",
      "[94]\ttrain's binary_logloss: 0.364408\n",
      "[95]\ttrain's binary_logloss: 0.362858\n",
      "[96]\ttrain's binary_logloss: 0.360926\n",
      "[97]\ttrain's binary_logloss: 0.35941\n",
      "[98]\ttrain's binary_logloss: 0.358207\n",
      "[99]\ttrain's binary_logloss: 0.357537\n",
      "[100]\ttrain's binary_logloss: 0.356465\n",
      "[101]\ttrain's binary_logloss: 0.355643\n",
      "[102]\ttrain's binary_logloss: 0.354476\n",
      "[103]\ttrain's binary_logloss: 0.353127\n",
      "[104]\ttrain's binary_logloss: 0.352091\n",
      "[105]\ttrain's binary_logloss: 0.350762\n",
      "[106]\ttrain's binary_logloss: 0.349704\n",
      "[107]\ttrain's binary_logloss: 0.348859\n",
      "[108]\ttrain's binary_logloss: 0.347836\n",
      "[109]\ttrain's binary_logloss: 0.346703\n",
      "[110]\ttrain's binary_logloss: 0.345726\n",
      "[111]\ttrain's binary_logloss: 0.344929\n",
      "[112]\ttrain's binary_logloss: 0.344232\n",
      "[113]\ttrain's binary_logloss: 0.343464\n",
      "[114]\ttrain's binary_logloss: 0.342828\n",
      "[115]\ttrain's binary_logloss: 0.341282\n",
      "[116]\ttrain's binary_logloss: 0.339423\n",
      "[117]\ttrain's binary_logloss: 0.338747\n",
      "[118]\ttrain's binary_logloss: 0.337414\n",
      "[119]\ttrain's binary_logloss: 0.336814\n",
      "[120]\ttrain's binary_logloss: 0.335958\n",
      "[121]\ttrain's binary_logloss: 0.335146\n",
      "[122]\ttrain's binary_logloss: 0.333571\n",
      "[123]\ttrain's binary_logloss: 0.332564\n",
      "[124]\ttrain's binary_logloss: 0.331984\n",
      "[125]\ttrain's binary_logloss: 0.331224\n",
      "[126]\ttrain's binary_logloss: 0.33044\n",
      "[127]\ttrain's binary_logloss: 0.32974\n",
      "[128]\ttrain's binary_logloss: 0.328766\n",
      "[129]\ttrain's binary_logloss: 0.327988\n",
      "[130]\ttrain's binary_logloss: 0.327226\n",
      "[131]\ttrain's binary_logloss: 0.326293\n",
      "[132]\ttrain's binary_logloss: 0.325219\n",
      "[133]\ttrain's binary_logloss: 0.323711\n",
      "[134]\ttrain's binary_logloss: 0.323081\n",
      "[135]\ttrain's binary_logloss: 0.321718\n",
      "[136]\ttrain's binary_logloss: 0.321142\n",
      "[137]\ttrain's binary_logloss: 0.320328\n",
      "[138]\ttrain's binary_logloss: 0.319378\n",
      "[139]\ttrain's binary_logloss: 0.318822\n",
      "[140]\ttrain's binary_logloss: 0.317859\n",
      "[141]\ttrain's binary_logloss: 0.31729\n",
      "[142]\ttrain's binary_logloss: 0.316314\n",
      "[143]\ttrain's binary_logloss: 0.315594\n",
      "[144]\ttrain's binary_logloss: 0.314675\n",
      "[145]\ttrain's binary_logloss: 0.313575\n",
      "[146]\ttrain's binary_logloss: 0.312904\n",
      "[147]\ttrain's binary_logloss: 0.31207\n",
      "[148]\ttrain's binary_logloss: 0.311461\n",
      "[149]\ttrain's binary_logloss: 0.310867\n",
      "[150]\ttrain's binary_logloss: 0.309872\n",
      "[151]\ttrain's binary_logloss: 0.309071\n",
      "[152]\ttrain's binary_logloss: 0.308102\n",
      "[153]\ttrain's binary_logloss: 0.307219\n",
      "[154]\ttrain's binary_logloss: 0.306427\n",
      "[155]\ttrain's binary_logloss: 0.305771\n",
      "[156]\ttrain's binary_logloss: 0.304692\n",
      "[157]\ttrain's binary_logloss: 0.303829\n",
      "[158]\ttrain's binary_logloss: 0.302958\n",
      "[159]\ttrain's binary_logloss: 0.302515\n",
      "[160]\ttrain's binary_logloss: 0.301781\n",
      "[161]\ttrain's binary_logloss: 0.301218\n",
      "[162]\ttrain's binary_logloss: 0.30076\n",
      "[163]\ttrain's binary_logloss: 0.299788\n",
      "[164]\ttrain's binary_logloss: 0.299011\n",
      "[165]\ttrain's binary_logloss: 0.298209\n",
      "[166]\ttrain's binary_logloss: 0.297688\n",
      "[167]\ttrain's binary_logloss: 0.296928\n",
      "[168]\ttrain's binary_logloss: 0.296486\n",
      "[169]\ttrain's binary_logloss: 0.295689\n",
      "[170]\ttrain's binary_logloss: 0.295135\n",
      "[171]\ttrain's binary_logloss: 0.293992\n",
      "[172]\ttrain's binary_logloss: 0.293065\n",
      "[173]\ttrain's binary_logloss: 0.292238\n",
      "[174]\ttrain's binary_logloss: 0.291605\n",
      "[175]\ttrain's binary_logloss: 0.290909\n",
      "[176]\ttrain's binary_logloss: 0.290163\n",
      "[177]\ttrain's binary_logloss: 0.289679\n",
      "[178]\ttrain's binary_logloss: 0.288876\n",
      "[179]\ttrain's binary_logloss: 0.287826\n",
      "[180]\ttrain's binary_logloss: 0.286768\n",
      "[181]\ttrain's binary_logloss: 0.2861\n",
      "[182]\ttrain's binary_logloss: 0.285568\n",
      "[183]\ttrain's binary_logloss: 0.285031\n",
      "[184]\ttrain's binary_logloss: 0.284179\n",
      "[185]\ttrain's binary_logloss: 0.28348\n",
      "[186]\ttrain's binary_logloss: 0.282782\n",
      "[187]\ttrain's binary_logloss: 0.282188\n",
      "[188]\ttrain's binary_logloss: 0.281734\n",
      "[189]\ttrain's binary_logloss: 0.28121\n",
      "[190]\ttrain's binary_logloss: 0.280441\n",
      "[191]\ttrain's binary_logloss: 0.279909\n",
      "[192]\ttrain's binary_logloss: 0.27899\n",
      "[193]\ttrain's binary_logloss: 0.278616\n",
      "[194]\ttrain's binary_logloss: 0.278\n",
      "[195]\ttrain's binary_logloss: 0.277302\n",
      "[196]\ttrain's binary_logloss: 0.276416\n",
      "[197]\ttrain's binary_logloss: 0.275802\n",
      "[198]\ttrain's binary_logloss: 0.275207\n",
      "[199]\ttrain's binary_logloss: 0.274815\n",
      "[200]\ttrain's binary_logloss: 0.274167\n",
      "[201]\ttrain's binary_logloss: 0.273716\n",
      "[202]\ttrain's binary_logloss: 0.272815\n",
      "[203]\ttrain's binary_logloss: 0.272177\n",
      "[204]\ttrain's binary_logloss: 0.271436\n",
      "[205]\ttrain's binary_logloss: 0.270776\n",
      "[206]\ttrain's binary_logloss: 0.270229\n",
      "[207]\ttrain's binary_logloss: 0.269779\n",
      "[208]\ttrain's binary_logloss: 0.269004\n",
      "[209]\ttrain's binary_logloss: 0.267872\n",
      "[210]\ttrain's binary_logloss: 0.267196\n",
      "[211]\ttrain's binary_logloss: 0.266571\n",
      "[212]\ttrain's binary_logloss: 0.26598\n",
      "[213]\ttrain's binary_logloss: 0.265654\n",
      "[214]\ttrain's binary_logloss: 0.264831\n",
      "[215]\ttrain's binary_logloss: 0.263983\n",
      "[216]\ttrain's binary_logloss: 0.262875\n",
      "[217]\ttrain's binary_logloss: 0.26229\n",
      "[218]\ttrain's binary_logloss: 0.26172\n",
      "[219]\ttrain's binary_logloss: 0.260831\n",
      "[220]\ttrain's binary_logloss: 0.260221\n",
      "[221]\ttrain's binary_logloss: 0.259489\n",
      "[222]\ttrain's binary_logloss: 0.258778\n",
      "[223]\ttrain's binary_logloss: 0.25811\n",
      "[224]\ttrain's binary_logloss: 0.257694\n",
      "[225]\ttrain's binary_logloss: 0.257083\n",
      "[226]\ttrain's binary_logloss: 0.256652\n",
      "[227]\ttrain's binary_logloss: 0.255637\n",
      "[228]\ttrain's binary_logloss: 0.255275\n",
      "[229]\ttrain's binary_logloss: 0.25436\n",
      "[230]\ttrain's binary_logloss: 0.253792\n",
      "[231]\ttrain's binary_logloss: 0.253338\n",
      "[232]\ttrain's binary_logloss: 0.252984\n",
      "[233]\ttrain's binary_logloss: 0.252331\n",
      "[234]\ttrain's binary_logloss: 0.251858\n",
      "[235]\ttrain's binary_logloss: 0.251312\n",
      "[236]\ttrain's binary_logloss: 0.250489\n",
      "[237]\ttrain's binary_logloss: 0.250099\n",
      "[238]\ttrain's binary_logloss: 0.249802\n",
      "[239]\ttrain's binary_logloss: 0.249211\n",
      "[240]\ttrain's binary_logloss: 0.24873\n",
      "[241]\ttrain's binary_logloss: 0.248368\n",
      "[242]\ttrain's binary_logloss: 0.247962\n",
      "[243]\ttrain's binary_logloss: 0.247223\n",
      "[244]\ttrain's binary_logloss: 0.246523\n",
      "[245]\ttrain's binary_logloss: 0.245704\n",
      "[246]\ttrain's binary_logloss: 0.245339\n",
      "[247]\ttrain's binary_logloss: 0.244785\n",
      "[248]\ttrain's binary_logloss: 0.244489\n",
      "[249]\ttrain's binary_logloss: 0.244123\n",
      "[250]\ttrain's binary_logloss: 0.243491\n",
      "[251]\ttrain's binary_logloss: 0.242877\n",
      "[252]\ttrain's binary_logloss: 0.24253\n",
      "[253]\ttrain's binary_logloss: 0.242084\n",
      "[254]\ttrain's binary_logloss: 0.241631\n",
      "[255]\ttrain's binary_logloss: 0.241128\n",
      "[256]\ttrain's binary_logloss: 0.240535\n",
      "[257]\ttrain's binary_logloss: 0.240056\n",
      "[258]\ttrain's binary_logloss: 0.23977\n",
      "[259]\ttrain's binary_logloss: 0.239386\n",
      "[260]\ttrain's binary_logloss: 0.238696\n",
      "[261]\ttrain's binary_logloss: 0.238307\n",
      "[262]\ttrain's binary_logloss: 0.237724\n",
      "[263]\ttrain's binary_logloss: 0.23714\n",
      "[264]\ttrain's binary_logloss: 0.236582\n",
      "[265]\ttrain's binary_logloss: 0.236232\n",
      "[266]\ttrain's binary_logloss: 0.235868\n",
      "[267]\ttrain's binary_logloss: 0.235129\n",
      "[268]\ttrain's binary_logloss: 0.234585\n",
      "[269]\ttrain's binary_logloss: 0.23423\n",
      "[270]\ttrain's binary_logloss: 0.233736\n",
      "[271]\ttrain's binary_logloss: 0.233189\n",
      "[272]\ttrain's binary_logloss: 0.232941\n",
      "[273]\ttrain's binary_logloss: 0.23242\n",
      "[274]\ttrain's binary_logloss: 0.231679\n",
      "[275]\ttrain's binary_logloss: 0.231218\n",
      "[276]\ttrain's binary_logloss: 0.23099\n",
      "[277]\ttrain's binary_logloss: 0.230563\n",
      "[278]\ttrain's binary_logloss: 0.229942\n",
      "[279]\ttrain's binary_logloss: 0.229532\n",
      "[280]\ttrain's binary_logloss: 0.22913\n",
      "[281]\ttrain's binary_logloss: 0.228747\n",
      "[282]\ttrain's binary_logloss: 0.227907\n",
      "[283]\ttrain's binary_logloss: 0.227236\n",
      "[284]\ttrain's binary_logloss: 0.226918\n",
      "[285]\ttrain's binary_logloss: 0.226609\n",
      "[286]\ttrain's binary_logloss: 0.226241\n",
      "[287]\ttrain's binary_logloss: 0.2259\n",
      "[288]\ttrain's binary_logloss: 0.225565\n",
      "[289]\ttrain's binary_logloss: 0.225198\n",
      "[290]\ttrain's binary_logloss: 0.224945\n",
      "[291]\ttrain's binary_logloss: 0.224465\n",
      "[292]\ttrain's binary_logloss: 0.224152\n",
      "[293]\ttrain's binary_logloss: 0.223747\n",
      "[294]\ttrain's binary_logloss: 0.223332\n",
      "[295]\ttrain's binary_logloss: 0.223046\n",
      "[296]\ttrain's binary_logloss: 0.222285\n",
      "[297]\ttrain's binary_logloss: 0.221907\n",
      "[298]\ttrain's binary_logloss: 0.221567\n",
      "[299]\ttrain's binary_logloss: 0.221273\n",
      "[300]\ttrain's binary_logloss: 0.220611\n",
      "[301]\ttrain's binary_logloss: 0.220213\n",
      "[302]\ttrain's binary_logloss: 0.21992\n",
      "[303]\ttrain's binary_logloss: 0.219641\n",
      "[304]\ttrain's binary_logloss: 0.219161\n",
      "[305]\ttrain's binary_logloss: 0.218723\n",
      "[306]\ttrain's binary_logloss: 0.218309\n",
      "[307]\ttrain's binary_logloss: 0.21755\n",
      "[308]\ttrain's binary_logloss: 0.217223\n",
      "[309]\ttrain's binary_logloss: 0.216722\n",
      "[310]\ttrain's binary_logloss: 0.216242\n",
      "[311]\ttrain's binary_logloss: 0.216004\n",
      "[312]\ttrain's binary_logloss: 0.215234\n",
      "[313]\ttrain's binary_logloss: 0.214731\n",
      "[314]\ttrain's binary_logloss: 0.214299\n",
      "[315]\ttrain's binary_logloss: 0.213988\n",
      "[316]\ttrain's binary_logloss: 0.213743\n",
      "[317]\ttrain's binary_logloss: 0.21342\n",
      "[318]\ttrain's binary_logloss: 0.212993\n",
      "[319]\ttrain's binary_logloss: 0.212576\n",
      "[320]\ttrain's binary_logloss: 0.21198\n",
      "[321]\ttrain's binary_logloss: 0.211424\n",
      "[322]\ttrain's binary_logloss: 0.21098\n",
      "[323]\ttrain's binary_logloss: 0.210717\n",
      "[324]\ttrain's binary_logloss: 0.210308\n",
      "[325]\ttrain's binary_logloss: 0.209841\n",
      "[326]\ttrain's binary_logloss: 0.208946\n",
      "[327]\ttrain's binary_logloss: 0.208284\n",
      "[328]\ttrain's binary_logloss: 0.207906\n",
      "[329]\ttrain's binary_logloss: 0.207541\n",
      "[330]\ttrain's binary_logloss: 0.207287\n",
      "[331]\ttrain's binary_logloss: 0.206782\n",
      "[332]\ttrain's binary_logloss: 0.206542\n",
      "[333]\ttrain's binary_logloss: 0.205731\n",
      "[334]\ttrain's binary_logloss: 0.20523\n",
      "[335]\ttrain's binary_logloss: 0.204782\n",
      "[336]\ttrain's binary_logloss: 0.204562\n",
      "[337]\ttrain's binary_logloss: 0.204267\n",
      "[338]\ttrain's binary_logloss: 0.204085\n",
      "[339]\ttrain's binary_logloss: 0.203701\n",
      "[340]\ttrain's binary_logloss: 0.203224\n",
      "[341]\ttrain's binary_logloss: 0.202829\n",
      "[342]\ttrain's binary_logloss: 0.202252\n",
      "[343]\ttrain's binary_logloss: 0.201751\n",
      "[344]\ttrain's binary_logloss: 0.201267\n",
      "[345]\ttrain's binary_logloss: 0.200805\n",
      "[346]\ttrain's binary_logloss: 0.200549\n",
      "[347]\ttrain's binary_logloss: 0.200051\n",
      "[348]\ttrain's binary_logloss: 0.199563\n",
      "[349]\ttrain's binary_logloss: 0.199131\n",
      "[350]\ttrain's binary_logloss: 0.198731\n",
      "[351]\ttrain's binary_logloss: 0.1983\n",
      "[352]\ttrain's binary_logloss: 0.197941\n",
      "[353]\ttrain's binary_logloss: 0.197673\n",
      "[354]\ttrain's binary_logloss: 0.197497\n",
      "[355]\ttrain's binary_logloss: 0.197346\n",
      "[356]\ttrain's binary_logloss: 0.196909\n",
      "[357]\ttrain's binary_logloss: 0.196737\n",
      "[358]\ttrain's binary_logloss: 0.196233\n",
      "[359]\ttrain's binary_logloss: 0.195819\n",
      "[360]\ttrain's binary_logloss: 0.195374\n",
      "[361]\ttrain's binary_logloss: 0.194856\n",
      "[362]\ttrain's binary_logloss: 0.194501\n",
      "[363]\ttrain's binary_logloss: 0.194192\n",
      "[364]\ttrain's binary_logloss: 0.193896\n",
      "[365]\ttrain's binary_logloss: 0.193524\n",
      "[366]\ttrain's binary_logloss: 0.193074\n",
      "[367]\ttrain's binary_logloss: 0.192726\n",
      "[368]\ttrain's binary_logloss: 0.192346\n",
      "[369]\ttrain's binary_logloss: 0.19207\n",
      "[370]\ttrain's binary_logloss: 0.191551\n",
      "[371]\ttrain's binary_logloss: 0.19121\n",
      "[372]\ttrain's binary_logloss: 0.190668\n",
      "[373]\ttrain's binary_logloss: 0.190357\n",
      "[374]\ttrain's binary_logloss: 0.189708\n",
      "[375]\ttrain's binary_logloss: 0.189166\n",
      "[376]\ttrain's binary_logloss: 0.188481\n",
      "[377]\ttrain's binary_logloss: 0.187923\n",
      "[378]\ttrain's binary_logloss: 0.187387\n",
      "[379]\ttrain's binary_logloss: 0.186829\n",
      "[380]\ttrain's binary_logloss: 0.186359\n",
      "[381]\ttrain's binary_logloss: 0.186049\n",
      "[382]\ttrain's binary_logloss: 0.185431\n",
      "[383]\ttrain's binary_logloss: 0.184966\n",
      "[384]\ttrain's binary_logloss: 0.184586\n",
      "[385]\ttrain's binary_logloss: 0.183982\n",
      "[386]\ttrain's binary_logloss: 0.183568\n",
      "[387]\ttrain's binary_logloss: 0.183413\n",
      "[388]\ttrain's binary_logloss: 0.182946\n",
      "[389]\ttrain's binary_logloss: 0.182525\n",
      "[390]\ttrain's binary_logloss: 0.181952\n",
      "[391]\ttrain's binary_logloss: 0.181528\n",
      "[392]\ttrain's binary_logloss: 0.18083\n",
      "[393]\ttrain's binary_logloss: 0.180543\n",
      "[394]\ttrain's binary_logloss: 0.180241\n",
      "[395]\ttrain's binary_logloss: 0.179704\n",
      "[396]\ttrain's binary_logloss: 0.179356\n",
      "[397]\ttrain's binary_logloss: 0.179073\n",
      "[398]\ttrain's binary_logloss: 0.178589\n",
      "[399]\ttrain's binary_logloss: 0.178339\n",
      "[400]\ttrain's binary_logloss: 0.17809\n",
      "[401]\ttrain's binary_logloss: 0.177719\n",
      "[402]\ttrain's binary_logloss: 0.177188\n",
      "[403]\ttrain's binary_logloss: 0.176908\n",
      "[404]\ttrain's binary_logloss: 0.176348\n",
      "[405]\ttrain's binary_logloss: 0.176101\n",
      "[406]\ttrain's binary_logloss: 0.175761\n",
      "[407]\ttrain's binary_logloss: 0.175526\n",
      "[408]\ttrain's binary_logloss: 0.175253\n",
      "[409]\ttrain's binary_logloss: 0.174833\n",
      "[410]\ttrain's binary_logloss: 0.174486\n",
      "[411]\ttrain's binary_logloss: 0.174289\n",
      "[412]\ttrain's binary_logloss: 0.173642\n",
      "[413]\ttrain's binary_logloss: 0.173361\n",
      "[414]\ttrain's binary_logloss: 0.172989\n",
      "[415]\ttrain's binary_logloss: 0.172507\n",
      "[416]\ttrain's binary_logloss: 0.17226\n",
      "[417]\ttrain's binary_logloss: 0.171865\n",
      "[418]\ttrain's binary_logloss: 0.171421\n",
      "[419]\ttrain's binary_logloss: 0.171136\n",
      "[420]\ttrain's binary_logloss: 0.170918\n",
      "[421]\ttrain's binary_logloss: 0.170276\n",
      "[422]\ttrain's binary_logloss: 0.169918\n",
      "[423]\ttrain's binary_logloss: 0.169643\n",
      "[424]\ttrain's binary_logloss: 0.169293\n",
      "[425]\ttrain's binary_logloss: 0.169112\n",
      "[426]\ttrain's binary_logloss: 0.16862\n",
      "[427]\ttrain's binary_logloss: 0.168273\n",
      "[428]\ttrain's binary_logloss: 0.167871\n",
      "[429]\ttrain's binary_logloss: 0.167623\n",
      "[430]\ttrain's binary_logloss: 0.167426\n",
      "[431]\ttrain's binary_logloss: 0.166944\n",
      "[432]\ttrain's binary_logloss: 0.166616\n",
      "[433]\ttrain's binary_logloss: 0.166257\n",
      "[434]\ttrain's binary_logloss: 0.166075\n",
      "[435]\ttrain's binary_logloss: 0.165558\n",
      "[436]\ttrain's binary_logloss: 0.165281\n",
      "[437]\ttrain's binary_logloss: 0.165056\n",
      "[438]\ttrain's binary_logloss: 0.164855\n",
      "[439]\ttrain's binary_logloss: 0.164418\n",
      "[440]\ttrain's binary_logloss: 0.163917\n",
      "[441]\ttrain's binary_logloss: 0.163484\n",
      "[442]\ttrain's binary_logloss: 0.163367\n",
      "[443]\ttrain's binary_logloss: 0.163146\n",
      "[444]\ttrain's binary_logloss: 0.162918\n",
      "[445]\ttrain's binary_logloss: 0.1626\n",
      "[446]\ttrain's binary_logloss: 0.162193\n",
      "[447]\ttrain's binary_logloss: 0.16195\n",
      "[448]\ttrain's binary_logloss: 0.161755\n",
      "[449]\ttrain's binary_logloss: 0.16139\n",
      "[450]\ttrain's binary_logloss: 0.16113\n",
      "[451]\ttrain's binary_logloss: 0.160798\n",
      "[452]\ttrain's binary_logloss: 0.160367\n",
      "[453]\ttrain's binary_logloss: 0.160173\n",
      "[454]\ttrain's binary_logloss: 0.160004\n",
      "[455]\ttrain's binary_logloss: 0.159851\n",
      "[456]\ttrain's binary_logloss: 0.15963\n",
      "[457]\ttrain's binary_logloss: 0.159342\n",
      "[458]\ttrain's binary_logloss: 0.158956\n",
      "[459]\ttrain's binary_logloss: 0.158747\n",
      "[460]\ttrain's binary_logloss: 0.158549\n",
      "[461]\ttrain's binary_logloss: 0.158198\n",
      "[462]\ttrain's binary_logloss: 0.157527\n",
      "[463]\ttrain's binary_logloss: 0.157263\n",
      "[464]\ttrain's binary_logloss: 0.157004\n",
      "[465]\ttrain's binary_logloss: 0.156493\n",
      "[466]\ttrain's binary_logloss: 0.156155\n",
      "[467]\ttrain's binary_logloss: 0.156\n",
      "[468]\ttrain's binary_logloss: 0.155591\n",
      "[469]\ttrain's binary_logloss: 0.154938\n",
      "[470]\ttrain's binary_logloss: 0.154755\n",
      "[471]\ttrain's binary_logloss: 0.154591\n",
      "[472]\ttrain's binary_logloss: 0.154373\n",
      "[473]\ttrain's binary_logloss: 0.154156\n",
      "[474]\ttrain's binary_logloss: 0.153797\n",
      "[475]\ttrain's binary_logloss: 0.153479\n",
      "[476]\ttrain's binary_logloss: 0.153004\n",
      "[477]\ttrain's binary_logloss: 0.152814\n",
      "[478]\ttrain's binary_logloss: 0.152484\n",
      "[479]\ttrain's binary_logloss: 0.152381\n",
      "[480]\ttrain's binary_logloss: 0.15209\n",
      "[481]\ttrain's binary_logloss: 0.151521\n",
      "[482]\ttrain's binary_logloss: 0.151195\n",
      "[483]\ttrain's binary_logloss: 0.150919\n",
      "[484]\ttrain's binary_logloss: 0.150498\n",
      "[485]\ttrain's binary_logloss: 0.150235\n",
      "[486]\ttrain's binary_logloss: 0.15008\n",
      "[487]\ttrain's binary_logloss: 0.149875\n",
      "[488]\ttrain's binary_logloss: 0.1497\n",
      "[489]\ttrain's binary_logloss: 0.149427\n",
      "[490]\ttrain's binary_logloss: 0.148995\n",
      "[491]\ttrain's binary_logloss: 0.148707\n",
      "[492]\ttrain's binary_logloss: 0.148535\n",
      "[493]\ttrain's binary_logloss: 0.148291\n",
      "[494]\ttrain's binary_logloss: 0.148023\n",
      "[495]\ttrain's binary_logloss: 0.1476\n",
      "[496]\ttrain's binary_logloss: 0.147413\n",
      "[497]\ttrain's binary_logloss: 0.147097\n",
      "[498]\ttrain's binary_logloss: 0.146752\n",
      "[499]\ttrain's binary_logloss: 0.146375\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "[0]\ttest-logloss:0.59573\n",
      "[1]\ttest-logloss:0.58371\n",
      "[2]\ttest-logloss:0.57642\n",
      "[3]\ttest-logloss:0.58736\n",
      "[4]\ttest-logloss:0.58414\n",
      "[5]\ttest-logloss:0.58967\n",
      "[6]\ttest-logloss:0.59291\n",
      "[7]\ttest-logloss:0.59738\n",
      "[8]\ttest-logloss:0.59849\n",
      "[9]\ttest-logloss:0.59946\n",
      "[10]\ttest-logloss:0.60594\n",
      "[11]\ttest-logloss:0.60589\n",
      "[12]\ttest-logloss:0.60974\n",
      "[13]\ttest-logloss:0.60995\n",
      "[14]\ttest-logloss:0.61244\n",
      "[15]\ttest-logloss:0.61994\n",
      "[16]\ttest-logloss:0.62884\n",
      "[17]\ttest-logloss:0.63393\n",
      "[18]\ttest-logloss:0.63189\n",
      "[19]\ttest-logloss:0.62428\n",
      "[20]\ttest-logloss:0.63861\n",
      "[21]\ttest-logloss:0.63952\n",
      "[22]\ttest-logloss:0.63235\n",
      "X_trainの形状： (646, 24)  y_trainの形状： (646,)  X_testの形状： (278, 24)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.662906\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.638297\n",
      "[3]\ttrain's binary_logloss: 0.617479\n",
      "[4]\ttrain's binary_logloss: 0.600501\n",
      "[5]\ttrain's binary_logloss: 0.585878\n",
      "[6]\ttrain's binary_logloss: 0.573603\n",
      "[7]\ttrain's binary_logloss: 0.562965\n",
      "[8]\ttrain's binary_logloss: 0.553485\n",
      "[9]\ttrain's binary_logloss: 0.545568\n",
      "[10]\ttrain's binary_logloss: 0.538341\n",
      "[11]\ttrain's binary_logloss: 0.53218\n",
      "[12]\ttrain's binary_logloss: 0.526888\n",
      "[13]\ttrain's binary_logloss: 0.521507\n",
      "[14]\ttrain's binary_logloss: 0.516283\n",
      "[15]\ttrain's binary_logloss: 0.511686\n",
      "[16]\ttrain's binary_logloss: 0.507458\n",
      "[17]\ttrain's binary_logloss: 0.502668\n",
      "[18]\ttrain's binary_logloss: 0.498687\n",
      "[19]\ttrain's binary_logloss: 0.494656\n",
      "[20]\ttrain's binary_logloss: 0.491561\n",
      "[21]\ttrain's binary_logloss: 0.488351\n",
      "[22]\ttrain's binary_logloss: 0.485573\n",
      "[23]\ttrain's binary_logloss: 0.482171\n",
      "[24]\ttrain's binary_logloss: 0.479149\n",
      "[25]\ttrain's binary_logloss: 0.476664\n",
      "[26]\ttrain's binary_logloss: 0.473929\n",
      "[27]\ttrain's binary_logloss: 0.471448\n",
      "[28]\ttrain's binary_logloss: 0.469294\n",
      "[29]\ttrain's binary_logloss: 0.466646\n",
      "[30]\ttrain's binary_logloss: 0.463765\n",
      "[31]\ttrain's binary_logloss: 0.461489\n",
      "[32]\ttrain's binary_logloss: 0.45924\n",
      "[33]\ttrain's binary_logloss: 0.456848\n",
      "[34]\ttrain's binary_logloss: 0.454888\n",
      "[35]\ttrain's binary_logloss: 0.452506\n",
      "[36]\ttrain's binary_logloss: 0.450764\n",
      "[37]\ttrain's binary_logloss: 0.448826\n",
      "[38]\ttrain's binary_logloss: 0.446645\n",
      "[39]\ttrain's binary_logloss: 0.444878\n",
      "[40]\ttrain's binary_logloss: 0.44312\n",
      "[41]\ttrain's binary_logloss: 0.441225\n",
      "[42]\ttrain's binary_logloss: 0.43862\n",
      "[43]\ttrain's binary_logloss: 0.43714\n",
      "[44]\ttrain's binary_logloss: 0.435454\n",
      "[45]\ttrain's binary_logloss: 0.433442\n",
      "[46]\ttrain's binary_logloss: 0.431905\n",
      "[47]\ttrain's binary_logloss: 0.430126\n",
      "[48]\ttrain's binary_logloss: 0.428234\n",
      "[49]\ttrain's binary_logloss: 0.42696\n",
      "[50]\ttrain's binary_logloss: 0.424765\n",
      "[51]\ttrain's binary_logloss: 0.423088\n",
      "[52]\ttrain's binary_logloss: 0.421902\n",
      "[53]\ttrain's binary_logloss: 0.420318\n",
      "[54]\ttrain's binary_logloss: 0.418909\n",
      "[55]\ttrain's binary_logloss: 0.417007\n",
      "[56]\ttrain's binary_logloss: 0.415208\n",
      "[57]\ttrain's binary_logloss: 0.413514\n",
      "[58]\ttrain's binary_logloss: 0.412293\n",
      "[59]\ttrain's binary_logloss: 0.411102\n",
      "[60]\ttrain's binary_logloss: 0.40967\n",
      "[61]\ttrain's binary_logloss: 0.407243\n",
      "[62]\ttrain's binary_logloss: 0.40599\n",
      "[63]\ttrain's binary_logloss: 0.404919\n",
      "[64]\ttrain's binary_logloss: 0.403409\n",
      "[65]\ttrain's binary_logloss: 0.402214\n",
      "[66]\ttrain's binary_logloss: 0.400646\n",
      "[67]\ttrain's binary_logloss: 0.398702\n",
      "[68]\ttrain's binary_logloss: 0.397395\n",
      "[69]\ttrain's binary_logloss: 0.395586\n",
      "[70]\ttrain's binary_logloss: 0.393765\n",
      "[71]\ttrain's binary_logloss: 0.392805\n",
      "[72]\ttrain's binary_logloss: 0.391712\n",
      "[73]\ttrain's binary_logloss: 0.390657\n",
      "[74]\ttrain's binary_logloss: 0.388989\n",
      "[75]\ttrain's binary_logloss: 0.38764\n",
      "[76]\ttrain's binary_logloss: 0.386751\n",
      "[77]\ttrain's binary_logloss: 0.384699\n",
      "[78]\ttrain's binary_logloss: 0.382528\n",
      "[79]\ttrain's binary_logloss: 0.381192\n",
      "[80]\ttrain's binary_logloss: 0.380259\n",
      "[81]\ttrain's binary_logloss: 0.378934\n",
      "[82]\ttrain's binary_logloss: 0.377976\n",
      "[83]\ttrain's binary_logloss: 0.376874\n",
      "[84]\ttrain's binary_logloss: 0.375969\n",
      "[85]\ttrain's binary_logloss: 0.374852\n",
      "[86]\ttrain's binary_logloss: 0.373135\n",
      "[87]\ttrain's binary_logloss: 0.371574\n",
      "[88]\ttrain's binary_logloss: 0.370593\n",
      "[89]\ttrain's binary_logloss: 0.369757\n",
      "[90]\ttrain's binary_logloss: 0.368328\n",
      "[91]\ttrain's binary_logloss: 0.367325\n",
      "[92]\ttrain's binary_logloss: 0.36639\n",
      "[93]\ttrain's binary_logloss: 0.365162\n",
      "[94]\ttrain's binary_logloss: 0.364408\n",
      "[95]\ttrain's binary_logloss: 0.362858\n",
      "[96]\ttrain's binary_logloss: 0.360926\n",
      "[97]\ttrain's binary_logloss: 0.35941\n",
      "[98]\ttrain's binary_logloss: 0.358207\n",
      "[99]\ttrain's binary_logloss: 0.357537\n",
      "[100]\ttrain's binary_logloss: 0.356465\n",
      "[101]\ttrain's binary_logloss: 0.355643\n",
      "[102]\ttrain's binary_logloss: 0.354476\n",
      "[103]\ttrain's binary_logloss: 0.353127\n",
      "[104]\ttrain's binary_logloss: 0.352091\n",
      "[105]\ttrain's binary_logloss: 0.350762\n",
      "[106]\ttrain's binary_logloss: 0.349704\n",
      "[107]\ttrain's binary_logloss: 0.348859\n",
      "[108]\ttrain's binary_logloss: 0.347836\n",
      "[109]\ttrain's binary_logloss: 0.346703\n",
      "[110]\ttrain's binary_logloss: 0.345726\n",
      "[111]\ttrain's binary_logloss: 0.344929\n",
      "[112]\ttrain's binary_logloss: 0.344232\n",
      "[113]\ttrain's binary_logloss: 0.343464\n",
      "[114]\ttrain's binary_logloss: 0.342828\n",
      "[115]\ttrain's binary_logloss: 0.341282\n",
      "[116]\ttrain's binary_logloss: 0.339423\n",
      "[117]\ttrain's binary_logloss: 0.338747\n",
      "[118]\ttrain's binary_logloss: 0.337414\n",
      "[119]\ttrain's binary_logloss: 0.336814\n",
      "[120]\ttrain's binary_logloss: 0.335958\n",
      "[121]\ttrain's binary_logloss: 0.335146\n",
      "[122]\ttrain's binary_logloss: 0.333571\n",
      "[123]\ttrain's binary_logloss: 0.332564\n",
      "[124]\ttrain's binary_logloss: 0.331984\n",
      "[125]\ttrain's binary_logloss: 0.331224\n",
      "[126]\ttrain's binary_logloss: 0.33044\n",
      "[127]\ttrain's binary_logloss: 0.32974\n",
      "[128]\ttrain's binary_logloss: 0.328766\n",
      "[129]\ttrain's binary_logloss: 0.327988\n",
      "[130]\ttrain's binary_logloss: 0.327226\n",
      "[131]\ttrain's binary_logloss: 0.326293\n",
      "[132]\ttrain's binary_logloss: 0.325219\n",
      "[133]\ttrain's binary_logloss: 0.323711\n",
      "[134]\ttrain's binary_logloss: 0.323081\n",
      "[135]\ttrain's binary_logloss: 0.321718\n",
      "[136]\ttrain's binary_logloss: 0.321142\n",
      "[137]\ttrain's binary_logloss: 0.320328\n",
      "[138]\ttrain's binary_logloss: 0.319378\n",
      "[139]\ttrain's binary_logloss: 0.318822\n",
      "[140]\ttrain's binary_logloss: 0.317859\n",
      "[141]\ttrain's binary_logloss: 0.31729\n",
      "[142]\ttrain's binary_logloss: 0.316314\n",
      "[143]\ttrain's binary_logloss: 0.315594\n",
      "[144]\ttrain's binary_logloss: 0.314675\n",
      "[145]\ttrain's binary_logloss: 0.313575\n",
      "[146]\ttrain's binary_logloss: 0.312904\n",
      "[147]\ttrain's binary_logloss: 0.31207\n",
      "[148]\ttrain's binary_logloss: 0.311461\n",
      "[149]\ttrain's binary_logloss: 0.310867\n",
      "[150]\ttrain's binary_logloss: 0.309872\n",
      "[151]\ttrain's binary_logloss: 0.309071\n",
      "[152]\ttrain's binary_logloss: 0.308102\n",
      "[153]\ttrain's binary_logloss: 0.307219\n",
      "[154]\ttrain's binary_logloss: 0.306427\n",
      "[155]\ttrain's binary_logloss: 0.305771\n",
      "[156]\ttrain's binary_logloss: 0.304692\n",
      "[157]\ttrain's binary_logloss: 0.303829\n",
      "[158]\ttrain's binary_logloss: 0.302958\n",
      "[159]\ttrain's binary_logloss: 0.302515\n",
      "[160]\ttrain's binary_logloss: 0.301781\n",
      "[161]\ttrain's binary_logloss: 0.301218\n",
      "[162]\ttrain's binary_logloss: 0.30076\n",
      "[163]\ttrain's binary_logloss: 0.299788\n",
      "[164]\ttrain's binary_logloss: 0.299011\n",
      "[165]\ttrain's binary_logloss: 0.298209\n",
      "[166]\ttrain's binary_logloss: 0.297688\n",
      "[167]\ttrain's binary_logloss: 0.296928\n",
      "[168]\ttrain's binary_logloss: 0.296486\n",
      "[169]\ttrain's binary_logloss: 0.295689\n",
      "[170]\ttrain's binary_logloss: 0.295135\n",
      "[171]\ttrain's binary_logloss: 0.293992\n",
      "[172]\ttrain's binary_logloss: 0.293065\n",
      "[173]\ttrain's binary_logloss: 0.292238\n",
      "[174]\ttrain's binary_logloss: 0.291605\n",
      "[175]\ttrain's binary_logloss: 0.290909\n",
      "[176]\ttrain's binary_logloss: 0.290163\n",
      "[177]\ttrain's binary_logloss: 0.289679\n",
      "[178]\ttrain's binary_logloss: 0.288876\n",
      "[179]\ttrain's binary_logloss: 0.287826\n",
      "[180]\ttrain's binary_logloss: 0.286768\n",
      "[181]\ttrain's binary_logloss: 0.2861\n",
      "[182]\ttrain's binary_logloss: 0.285568\n",
      "[183]\ttrain's binary_logloss: 0.285031\n",
      "[184]\ttrain's binary_logloss: 0.284179\n",
      "[185]\ttrain's binary_logloss: 0.28348\n",
      "[186]\ttrain's binary_logloss: 0.282782\n",
      "[187]\ttrain's binary_logloss: 0.282188\n",
      "[188]\ttrain's binary_logloss: 0.281734\n",
      "[189]\ttrain's binary_logloss: 0.28121\n",
      "[190]\ttrain's binary_logloss: 0.280441\n",
      "[191]\ttrain's binary_logloss: 0.279909\n",
      "[192]\ttrain's binary_logloss: 0.27899\n",
      "[193]\ttrain's binary_logloss: 0.278616\n",
      "[194]\ttrain's binary_logloss: 0.278\n",
      "[195]\ttrain's binary_logloss: 0.277302\n",
      "[196]\ttrain's binary_logloss: 0.276416\n",
      "[197]\ttrain's binary_logloss: 0.275802\n",
      "[198]\ttrain's binary_logloss: 0.275207\n",
      "[199]\ttrain's binary_logloss: 0.274815\n",
      "[200]\ttrain's binary_logloss: 0.274167\n",
      "[201]\ttrain's binary_logloss: 0.273716\n",
      "[202]\ttrain's binary_logloss: 0.272815\n",
      "[203]\ttrain's binary_logloss: 0.272177\n",
      "[204]\ttrain's binary_logloss: 0.271436\n",
      "[205]\ttrain's binary_logloss: 0.270776\n",
      "[206]\ttrain's binary_logloss: 0.270229\n",
      "[207]\ttrain's binary_logloss: 0.269779\n",
      "[208]\ttrain's binary_logloss: 0.269004\n",
      "[209]\ttrain's binary_logloss: 0.267872\n",
      "[210]\ttrain's binary_logloss: 0.267196\n",
      "[211]\ttrain's binary_logloss: 0.266571\n",
      "[212]\ttrain's binary_logloss: 0.26598\n",
      "[213]\ttrain's binary_logloss: 0.265654\n",
      "[214]\ttrain's binary_logloss: 0.264831\n",
      "[215]\ttrain's binary_logloss: 0.263983\n",
      "[216]\ttrain's binary_logloss: 0.262875\n",
      "[217]\ttrain's binary_logloss: 0.26229\n",
      "[218]\ttrain's binary_logloss: 0.26172\n",
      "[219]\ttrain's binary_logloss: 0.260831\n",
      "[220]\ttrain's binary_logloss: 0.260221\n",
      "[221]\ttrain's binary_logloss: 0.259489\n",
      "[222]\ttrain's binary_logloss: 0.258778\n",
      "[223]\ttrain's binary_logloss: 0.25811\n",
      "[224]\ttrain's binary_logloss: 0.257694\n",
      "[225]\ttrain's binary_logloss: 0.257083\n",
      "[226]\ttrain's binary_logloss: 0.256652\n",
      "[227]\ttrain's binary_logloss: 0.255637\n",
      "[228]\ttrain's binary_logloss: 0.255275\n",
      "[229]\ttrain's binary_logloss: 0.25436\n",
      "[230]\ttrain's binary_logloss: 0.253792\n",
      "[231]\ttrain's binary_logloss: 0.253338\n",
      "[232]\ttrain's binary_logloss: 0.252984\n",
      "[233]\ttrain's binary_logloss: 0.252331\n",
      "[234]\ttrain's binary_logloss: 0.251858\n",
      "[235]\ttrain's binary_logloss: 0.251312\n",
      "[236]\ttrain's binary_logloss: 0.250489\n",
      "[237]\ttrain's binary_logloss: 0.250099\n",
      "[238]\ttrain's binary_logloss: 0.249802\n",
      "[239]\ttrain's binary_logloss: 0.249211\n",
      "[240]\ttrain's binary_logloss: 0.24873\n",
      "[241]\ttrain's binary_logloss: 0.248368\n",
      "[242]\ttrain's binary_logloss: 0.247962\n",
      "[243]\ttrain's binary_logloss: 0.247223\n",
      "[244]\ttrain's binary_logloss: 0.246523\n",
      "[245]\ttrain's binary_logloss: 0.245704\n",
      "[246]\ttrain's binary_logloss: 0.245339\n",
      "[247]\ttrain's binary_logloss: 0.244785\n",
      "[248]\ttrain's binary_logloss: 0.244489\n",
      "[249]\ttrain's binary_logloss: 0.244123\n",
      "[250]\ttrain's binary_logloss: 0.243491\n",
      "[251]\ttrain's binary_logloss: 0.242877\n",
      "[252]\ttrain's binary_logloss: 0.24253\n",
      "[253]\ttrain's binary_logloss: 0.242084\n",
      "[254]\ttrain's binary_logloss: 0.241631\n",
      "[255]\ttrain's binary_logloss: 0.241128\n",
      "[256]\ttrain's binary_logloss: 0.240535\n",
      "[257]\ttrain's binary_logloss: 0.240056\n",
      "[258]\ttrain's binary_logloss: 0.23977\n",
      "[259]\ttrain's binary_logloss: 0.239386\n",
      "[260]\ttrain's binary_logloss: 0.238696\n",
      "[261]\ttrain's binary_logloss: 0.238307\n",
      "[262]\ttrain's binary_logloss: 0.237724\n",
      "[263]\ttrain's binary_logloss: 0.23714\n",
      "[264]\ttrain's binary_logloss: 0.236582\n",
      "[265]\ttrain's binary_logloss: 0.236232\n",
      "[266]\ttrain's binary_logloss: 0.235868\n",
      "[267]\ttrain's binary_logloss: 0.235129\n",
      "[268]\ttrain's binary_logloss: 0.234585\n",
      "[269]\ttrain's binary_logloss: 0.23423\n",
      "[270]\ttrain's binary_logloss: 0.233736\n",
      "[271]\ttrain's binary_logloss: 0.233189\n",
      "[272]\ttrain's binary_logloss: 0.232941\n",
      "[273]\ttrain's binary_logloss: 0.23242\n",
      "[274]\ttrain's binary_logloss: 0.231679\n",
      "[275]\ttrain's binary_logloss: 0.231218\n",
      "[276]\ttrain's binary_logloss: 0.23099\n",
      "[277]\ttrain's binary_logloss: 0.230563\n",
      "[278]\ttrain's binary_logloss: 0.229942\n",
      "[279]\ttrain's binary_logloss: 0.229532\n",
      "[280]\ttrain's binary_logloss: 0.22913\n",
      "[281]\ttrain's binary_logloss: 0.228747\n",
      "[282]\ttrain's binary_logloss: 0.227907\n",
      "[283]\ttrain's binary_logloss: 0.227236\n",
      "[284]\ttrain's binary_logloss: 0.226918\n",
      "[285]\ttrain's binary_logloss: 0.226609\n",
      "[286]\ttrain's binary_logloss: 0.226241\n",
      "[287]\ttrain's binary_logloss: 0.2259\n",
      "[288]\ttrain's binary_logloss: 0.225565\n",
      "[289]\ttrain's binary_logloss: 0.225198\n",
      "[290]\ttrain's binary_logloss: 0.224945\n",
      "[291]\ttrain's binary_logloss: 0.224465\n",
      "[292]\ttrain's binary_logloss: 0.224152\n",
      "[293]\ttrain's binary_logloss: 0.223747\n",
      "[294]\ttrain's binary_logloss: 0.223332\n",
      "[295]\ttrain's binary_logloss: 0.223046\n",
      "[296]\ttrain's binary_logloss: 0.222285\n",
      "[297]\ttrain's binary_logloss: 0.221907\n",
      "[298]\ttrain's binary_logloss: 0.221567\n",
      "[299]\ttrain's binary_logloss: 0.221273\n",
      "[300]\ttrain's binary_logloss: 0.220611\n",
      "[301]\ttrain's binary_logloss: 0.220213\n",
      "[302]\ttrain's binary_logloss: 0.21992\n",
      "[303]\ttrain's binary_logloss: 0.219641\n",
      "[304]\ttrain's binary_logloss: 0.219161\n",
      "[305]\ttrain's binary_logloss: 0.218723\n",
      "[306]\ttrain's binary_logloss: 0.218309\n",
      "[307]\ttrain's binary_logloss: 0.21755\n",
      "[308]\ttrain's binary_logloss: 0.217223\n",
      "[309]\ttrain's binary_logloss: 0.216722\n",
      "[310]\ttrain's binary_logloss: 0.216242\n",
      "[311]\ttrain's binary_logloss: 0.216004\n",
      "[312]\ttrain's binary_logloss: 0.215234\n",
      "[313]\ttrain's binary_logloss: 0.214731\n",
      "[314]\ttrain's binary_logloss: 0.214299\n",
      "[315]\ttrain's binary_logloss: 0.213988\n",
      "[316]\ttrain's binary_logloss: 0.213743\n",
      "[317]\ttrain's binary_logloss: 0.21342\n",
      "[318]\ttrain's binary_logloss: 0.212993\n",
      "[319]\ttrain's binary_logloss: 0.212576\n",
      "[320]\ttrain's binary_logloss: 0.21198\n",
      "[321]\ttrain's binary_logloss: 0.211424\n",
      "[322]\ttrain's binary_logloss: 0.21098\n",
      "[323]\ttrain's binary_logloss: 0.210717\n",
      "[324]\ttrain's binary_logloss: 0.210308\n",
      "[325]\ttrain's binary_logloss: 0.209841\n",
      "[326]\ttrain's binary_logloss: 0.208946\n",
      "[327]\ttrain's binary_logloss: 0.208284\n",
      "[328]\ttrain's binary_logloss: 0.207906\n",
      "[329]\ttrain's binary_logloss: 0.207541\n",
      "[330]\ttrain's binary_logloss: 0.207287\n",
      "[331]\ttrain's binary_logloss: 0.206782\n",
      "[332]\ttrain's binary_logloss: 0.206542\n",
      "[333]\ttrain's binary_logloss: 0.205731\n",
      "[334]\ttrain's binary_logloss: 0.20523\n",
      "[335]\ttrain's binary_logloss: 0.204782\n",
      "[336]\ttrain's binary_logloss: 0.204562\n",
      "[337]\ttrain's binary_logloss: 0.204267\n",
      "[338]\ttrain's binary_logloss: 0.204085\n",
      "[339]\ttrain's binary_logloss: 0.203701\n",
      "[340]\ttrain's binary_logloss: 0.203224\n",
      "[341]\ttrain's binary_logloss: 0.202829\n",
      "[342]\ttrain's binary_logloss: 0.202252\n",
      "[343]\ttrain's binary_logloss: 0.201751\n",
      "[344]\ttrain's binary_logloss: 0.201267\n",
      "[345]\ttrain's binary_logloss: 0.200805\n",
      "[346]\ttrain's binary_logloss: 0.200549\n",
      "[347]\ttrain's binary_logloss: 0.200051\n",
      "[348]\ttrain's binary_logloss: 0.199563\n",
      "[349]\ttrain's binary_logloss: 0.199131\n",
      "[350]\ttrain's binary_logloss: 0.198731\n",
      "[351]\ttrain's binary_logloss: 0.1983\n",
      "[352]\ttrain's binary_logloss: 0.197941\n",
      "[353]\ttrain's binary_logloss: 0.197673\n",
      "[354]\ttrain's binary_logloss: 0.197497\n",
      "[355]\ttrain's binary_logloss: 0.197346\n",
      "[356]\ttrain's binary_logloss: 0.196909\n",
      "[357]\ttrain's binary_logloss: 0.196737\n",
      "[358]\ttrain's binary_logloss: 0.196233\n",
      "[359]\ttrain's binary_logloss: 0.195819\n",
      "[360]\ttrain's binary_logloss: 0.195374\n",
      "[361]\ttrain's binary_logloss: 0.194856\n",
      "[362]\ttrain's binary_logloss: 0.194501\n",
      "[363]\ttrain's binary_logloss: 0.194192\n",
      "[364]\ttrain's binary_logloss: 0.193896\n",
      "[365]\ttrain's binary_logloss: 0.193524\n",
      "[366]\ttrain's binary_logloss: 0.193074\n",
      "[367]\ttrain's binary_logloss: 0.192726\n",
      "[368]\ttrain's binary_logloss: 0.192346\n",
      "[369]\ttrain's binary_logloss: 0.19207\n",
      "[370]\ttrain's binary_logloss: 0.191551\n",
      "[371]\ttrain's binary_logloss: 0.19121\n",
      "[372]\ttrain's binary_logloss: 0.190668\n",
      "[373]\ttrain's binary_logloss: 0.190357\n",
      "[374]\ttrain's binary_logloss: 0.189708\n",
      "[375]\ttrain's binary_logloss: 0.189166\n",
      "[376]\ttrain's binary_logloss: 0.188481\n",
      "[377]\ttrain's binary_logloss: 0.187923\n",
      "[378]\ttrain's binary_logloss: 0.187387\n",
      "[379]\ttrain's binary_logloss: 0.186829\n",
      "[380]\ttrain's binary_logloss: 0.186359\n",
      "[381]\ttrain's binary_logloss: 0.186049\n",
      "[382]\ttrain's binary_logloss: 0.185431\n",
      "[383]\ttrain's binary_logloss: 0.184966\n",
      "[384]\ttrain's binary_logloss: 0.184586\n",
      "[385]\ttrain's binary_logloss: 0.183982\n",
      "[386]\ttrain's binary_logloss: 0.183568\n",
      "[387]\ttrain's binary_logloss: 0.183413\n",
      "[388]\ttrain's binary_logloss: 0.182946\n",
      "[389]\ttrain's binary_logloss: 0.182525\n",
      "[390]\ttrain's binary_logloss: 0.181952\n",
      "[391]\ttrain's binary_logloss: 0.181528\n",
      "[392]\ttrain's binary_logloss: 0.18083\n",
      "[393]\ttrain's binary_logloss: 0.180543\n",
      "[394]\ttrain's binary_logloss: 0.180241\n",
      "[395]\ttrain's binary_logloss: 0.179704\n",
      "[396]\ttrain's binary_logloss: 0.179356\n",
      "[397]\ttrain's binary_logloss: 0.179073\n",
      "[398]\ttrain's binary_logloss: 0.178589\n",
      "[399]\ttrain's binary_logloss: 0.178339\n",
      "[400]\ttrain's binary_logloss: 0.17809\n",
      "[401]\ttrain's binary_logloss: 0.177719\n",
      "[402]\ttrain's binary_logloss: 0.177188\n",
      "[403]\ttrain's binary_logloss: 0.176908\n",
      "[404]\ttrain's binary_logloss: 0.176348\n",
      "[405]\ttrain's binary_logloss: 0.176101\n",
      "[406]\ttrain's binary_logloss: 0.175761\n",
      "[407]\ttrain's binary_logloss: 0.175526\n",
      "[408]\ttrain's binary_logloss: 0.175253\n",
      "[409]\ttrain's binary_logloss: 0.174833\n",
      "[410]\ttrain's binary_logloss: 0.174486\n",
      "[411]\ttrain's binary_logloss: 0.174289\n",
      "[412]\ttrain's binary_logloss: 0.173642\n",
      "[413]\ttrain's binary_logloss: 0.173361\n",
      "[414]\ttrain's binary_logloss: 0.172989\n",
      "[415]\ttrain's binary_logloss: 0.172507\n",
      "[416]\ttrain's binary_logloss: 0.17226\n",
      "[417]\ttrain's binary_logloss: 0.171865\n",
      "[418]\ttrain's binary_logloss: 0.171421\n",
      "[419]\ttrain's binary_logloss: 0.171136\n",
      "[420]\ttrain's binary_logloss: 0.170918\n",
      "[421]\ttrain's binary_logloss: 0.170276\n",
      "[422]\ttrain's binary_logloss: 0.169918\n",
      "[423]\ttrain's binary_logloss: 0.169643\n",
      "[424]\ttrain's binary_logloss: 0.169293\n",
      "[425]\ttrain's binary_logloss: 0.169112\n",
      "[426]\ttrain's binary_logloss: 0.16862\n",
      "[427]\ttrain's binary_logloss: 0.168273\n",
      "[428]\ttrain's binary_logloss: 0.167871\n",
      "[429]\ttrain's binary_logloss: 0.167623\n",
      "[430]\ttrain's binary_logloss: 0.167426\n",
      "[431]\ttrain's binary_logloss: 0.166944\n",
      "[432]\ttrain's binary_logloss: 0.166616\n",
      "[433]\ttrain's binary_logloss: 0.166257\n",
      "[434]\ttrain's binary_logloss: 0.166075\n",
      "[435]\ttrain's binary_logloss: 0.165558\n",
      "[436]\ttrain's binary_logloss: 0.165281\n",
      "[437]\ttrain's binary_logloss: 0.165056\n",
      "[438]\ttrain's binary_logloss: 0.164855\n",
      "[439]\ttrain's binary_logloss: 0.164418\n",
      "[440]\ttrain's binary_logloss: 0.163917\n",
      "[441]\ttrain's binary_logloss: 0.163484\n",
      "[442]\ttrain's binary_logloss: 0.163367\n",
      "[443]\ttrain's binary_logloss: 0.163146\n",
      "[444]\ttrain's binary_logloss: 0.162918\n",
      "[445]\ttrain's binary_logloss: 0.1626\n",
      "[446]\ttrain's binary_logloss: 0.162193\n",
      "[447]\ttrain's binary_logloss: 0.16195\n",
      "[448]\ttrain's binary_logloss: 0.161755\n",
      "[449]\ttrain's binary_logloss: 0.16139\n",
      "[450]\ttrain's binary_logloss: 0.16113\n",
      "[451]\ttrain's binary_logloss: 0.160798\n",
      "[452]\ttrain's binary_logloss: 0.160367\n",
      "[453]\ttrain's binary_logloss: 0.160173\n",
      "[454]\ttrain's binary_logloss: 0.160004\n",
      "[455]\ttrain's binary_logloss: 0.159851\n",
      "[456]\ttrain's binary_logloss: 0.15963\n",
      "[457]\ttrain's binary_logloss: 0.159342\n",
      "[458]\ttrain's binary_logloss: 0.158956\n",
      "[459]\ttrain's binary_logloss: 0.158747\n",
      "[460]\ttrain's binary_logloss: 0.158549\n",
      "[461]\ttrain's binary_logloss: 0.158198\n",
      "[462]\ttrain's binary_logloss: 0.157527\n",
      "[463]\ttrain's binary_logloss: 0.157263\n",
      "[464]\ttrain's binary_logloss: 0.157004\n",
      "[465]\ttrain's binary_logloss: 0.156493\n",
      "[466]\ttrain's binary_logloss: 0.156155\n",
      "[467]\ttrain's binary_logloss: 0.156\n",
      "[468]\ttrain's binary_logloss: 0.155591\n",
      "[469]\ttrain's binary_logloss: 0.154938\n",
      "[470]\ttrain's binary_logloss: 0.154755\n",
      "[471]\ttrain's binary_logloss: 0.154591\n",
      "[472]\ttrain's binary_logloss: 0.154373\n",
      "[473]\ttrain's binary_logloss: 0.154156\n",
      "[474]\ttrain's binary_logloss: 0.153797\n",
      "[475]\ttrain's binary_logloss: 0.153479\n",
      "[476]\ttrain's binary_logloss: 0.153004\n",
      "[477]\ttrain's binary_logloss: 0.152814\n",
      "[478]\ttrain's binary_logloss: 0.152484\n",
      "[479]\ttrain's binary_logloss: 0.152381\n",
      "[480]\ttrain's binary_logloss: 0.15209\n",
      "[481]\ttrain's binary_logloss: 0.151521\n",
      "[482]\ttrain's binary_logloss: 0.151195\n",
      "[483]\ttrain's binary_logloss: 0.150919\n",
      "[484]\ttrain's binary_logloss: 0.150498\n",
      "[485]\ttrain's binary_logloss: 0.150235\n",
      "[486]\ttrain's binary_logloss: 0.15008\n",
      "[487]\ttrain's binary_logloss: 0.149875\n",
      "[488]\ttrain's binary_logloss: 0.1497\n",
      "[489]\ttrain's binary_logloss: 0.149427\n",
      "[490]\ttrain's binary_logloss: 0.148995\n",
      "[491]\ttrain's binary_logloss: 0.148707\n",
      "[492]\ttrain's binary_logloss: 0.148535\n",
      "[493]\ttrain's binary_logloss: 0.148291\n",
      "[494]\ttrain's binary_logloss: 0.148023\n",
      "[495]\ttrain's binary_logloss: 0.1476\n",
      "[496]\ttrain's binary_logloss: 0.147413\n",
      "[497]\ttrain's binary_logloss: 0.147097\n",
      "[498]\ttrain's binary_logloss: 0.146752\n",
      "[499]\ttrain's binary_logloss: 0.146375\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "[0]\ttest-logloss:0.59573\n",
      "[1]\ttest-logloss:0.58371\n",
      "[2]\ttest-logloss:0.57642\n",
      "[3]\ttest-logloss:0.58736\n",
      "[4]\ttest-logloss:0.58414\n",
      "[5]\ttest-logloss:0.58967\n",
      "[6]\ttest-logloss:0.59291\n",
      "[7]\ttest-logloss:0.59738\n",
      "[8]\ttest-logloss:0.59849\n",
      "[9]\ttest-logloss:0.59946\n",
      "[10]\ttest-logloss:0.60594\n",
      "[11]\ttest-logloss:0.60589\n",
      "[12]\ttest-logloss:0.60974\n",
      "[13]\ttest-logloss:0.60995\n",
      "[14]\ttest-logloss:0.61244\n",
      "[15]\ttest-logloss:0.61994\n",
      "[16]\ttest-logloss:0.62884\n",
      "[17]\ttest-logloss:0.63393\n",
      "[18]\ttest-logloss:0.63189\n",
      "[19]\ttest-logloss:0.62428\n",
      "[20]\ttest-logloss:0.63861\n",
      "[21]\ttest-logloss:0.63952\n",
      "[22]\ttest-logloss:0.63235\n",
      "X_trainの形状： (646, 24)  y_trainの形状： (646,)  X_testの形状： (278, 24)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.662906\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.638297\n",
      "[3]\ttrain's binary_logloss: 0.617479\n",
      "[4]\ttrain's binary_logloss: 0.600501\n",
      "[5]\ttrain's binary_logloss: 0.585878\n",
      "[6]\ttrain's binary_logloss: 0.573603\n",
      "[7]\ttrain's binary_logloss: 0.562965\n",
      "[8]\ttrain's binary_logloss: 0.553485\n",
      "[9]\ttrain's binary_logloss: 0.545568\n",
      "[10]\ttrain's binary_logloss: 0.538341\n",
      "[11]\ttrain's binary_logloss: 0.53218\n",
      "[12]\ttrain's binary_logloss: 0.526888\n",
      "[13]\ttrain's binary_logloss: 0.521507\n",
      "[14]\ttrain's binary_logloss: 0.516283\n",
      "[15]\ttrain's binary_logloss: 0.511686\n",
      "[16]\ttrain's binary_logloss: 0.507458\n",
      "[17]\ttrain's binary_logloss: 0.502668\n",
      "[18]\ttrain's binary_logloss: 0.498687\n",
      "[19]\ttrain's binary_logloss: 0.494656\n",
      "[20]\ttrain's binary_logloss: 0.491561\n",
      "[21]\ttrain's binary_logloss: 0.488351\n",
      "[22]\ttrain's binary_logloss: 0.485573\n",
      "[23]\ttrain's binary_logloss: 0.482171\n",
      "[24]\ttrain's binary_logloss: 0.479149\n",
      "[25]\ttrain's binary_logloss: 0.476664\n",
      "[26]\ttrain's binary_logloss: 0.473929\n",
      "[27]\ttrain's binary_logloss: 0.471448\n",
      "[28]\ttrain's binary_logloss: 0.469294\n",
      "[29]\ttrain's binary_logloss: 0.466646\n",
      "[30]\ttrain's binary_logloss: 0.463765\n",
      "[31]\ttrain's binary_logloss: 0.461489\n",
      "[32]\ttrain's binary_logloss: 0.45924\n",
      "[33]\ttrain's binary_logloss: 0.456848\n",
      "[34]\ttrain's binary_logloss: 0.454888\n",
      "[35]\ttrain's binary_logloss: 0.452506\n",
      "[36]\ttrain's binary_logloss: 0.450764\n",
      "[37]\ttrain's binary_logloss: 0.448826\n",
      "[38]\ttrain's binary_logloss: 0.446645\n",
      "[39]\ttrain's binary_logloss: 0.444878\n",
      "[40]\ttrain's binary_logloss: 0.44312\n",
      "[41]\ttrain's binary_logloss: 0.441225\n",
      "[42]\ttrain's binary_logloss: 0.43862\n",
      "[43]\ttrain's binary_logloss: 0.43714\n",
      "[44]\ttrain's binary_logloss: 0.435454\n",
      "[45]\ttrain's binary_logloss: 0.433442\n",
      "[46]\ttrain's binary_logloss: 0.431905\n",
      "[47]\ttrain's binary_logloss: 0.430126\n",
      "[48]\ttrain's binary_logloss: 0.428234\n",
      "[49]\ttrain's binary_logloss: 0.42696\n",
      "[50]\ttrain's binary_logloss: 0.424765\n",
      "[51]\ttrain's binary_logloss: 0.423088\n",
      "[52]\ttrain's binary_logloss: 0.421902\n",
      "[53]\ttrain's binary_logloss: 0.420318\n",
      "[54]\ttrain's binary_logloss: 0.418909\n",
      "[55]\ttrain's binary_logloss: 0.417007\n",
      "[56]\ttrain's binary_logloss: 0.415208\n",
      "[57]\ttrain's binary_logloss: 0.413514\n",
      "[58]\ttrain's binary_logloss: 0.412293\n",
      "[59]\ttrain's binary_logloss: 0.411102\n",
      "[60]\ttrain's binary_logloss: 0.40967\n",
      "[61]\ttrain's binary_logloss: 0.407243\n",
      "[62]\ttrain's binary_logloss: 0.40599\n",
      "[63]\ttrain's binary_logloss: 0.404919\n",
      "[64]\ttrain's binary_logloss: 0.403409\n",
      "[65]\ttrain's binary_logloss: 0.402214\n",
      "[66]\ttrain's binary_logloss: 0.400646\n",
      "[67]\ttrain's binary_logloss: 0.398702\n",
      "[68]\ttrain's binary_logloss: 0.397395\n",
      "[69]\ttrain's binary_logloss: 0.395586\n",
      "[70]\ttrain's binary_logloss: 0.393765\n",
      "[71]\ttrain's binary_logloss: 0.392805\n",
      "[72]\ttrain's binary_logloss: 0.391712\n",
      "[73]\ttrain's binary_logloss: 0.390657\n",
      "[74]\ttrain's binary_logloss: 0.388989\n",
      "[75]\ttrain's binary_logloss: 0.38764\n",
      "[76]\ttrain's binary_logloss: 0.386751\n",
      "[77]\ttrain's binary_logloss: 0.384699\n",
      "[78]\ttrain's binary_logloss: 0.382528\n",
      "[79]\ttrain's binary_logloss: 0.381192\n",
      "[80]\ttrain's binary_logloss: 0.380259\n",
      "[81]\ttrain's binary_logloss: 0.378934\n",
      "[82]\ttrain's binary_logloss: 0.377976\n",
      "[83]\ttrain's binary_logloss: 0.376874\n",
      "[84]\ttrain's binary_logloss: 0.375969\n",
      "[85]\ttrain's binary_logloss: 0.374852\n",
      "[86]\ttrain's binary_logloss: 0.373135\n",
      "[87]\ttrain's binary_logloss: 0.371574\n",
      "[88]\ttrain's binary_logloss: 0.370593\n",
      "[89]\ttrain's binary_logloss: 0.369757\n",
      "[90]\ttrain's binary_logloss: 0.368328\n",
      "[91]\ttrain's binary_logloss: 0.367325\n",
      "[92]\ttrain's binary_logloss: 0.36639\n",
      "[93]\ttrain's binary_logloss: 0.365162\n",
      "[94]\ttrain's binary_logloss: 0.364408\n",
      "[95]\ttrain's binary_logloss: 0.362858\n",
      "[96]\ttrain's binary_logloss: 0.360926\n",
      "[97]\ttrain's binary_logloss: 0.35941\n",
      "[98]\ttrain's binary_logloss: 0.358207\n",
      "[99]\ttrain's binary_logloss: 0.357537\n",
      "[100]\ttrain's binary_logloss: 0.356465\n",
      "[101]\ttrain's binary_logloss: 0.355643\n",
      "[102]\ttrain's binary_logloss: 0.354476\n",
      "[103]\ttrain's binary_logloss: 0.353127\n",
      "[104]\ttrain's binary_logloss: 0.352091\n",
      "[105]\ttrain's binary_logloss: 0.350762\n",
      "[106]\ttrain's binary_logloss: 0.349704\n",
      "[107]\ttrain's binary_logloss: 0.348859\n",
      "[108]\ttrain's binary_logloss: 0.347836\n",
      "[109]\ttrain's binary_logloss: 0.346703\n",
      "[110]\ttrain's binary_logloss: 0.345726\n",
      "[111]\ttrain's binary_logloss: 0.344929\n",
      "[112]\ttrain's binary_logloss: 0.344232\n",
      "[113]\ttrain's binary_logloss: 0.343464\n",
      "[114]\ttrain's binary_logloss: 0.342828\n",
      "[115]\ttrain's binary_logloss: 0.341282\n",
      "[116]\ttrain's binary_logloss: 0.339423\n",
      "[117]\ttrain's binary_logloss: 0.338747\n",
      "[118]\ttrain's binary_logloss: 0.337414\n",
      "[119]\ttrain's binary_logloss: 0.336814\n",
      "[120]\ttrain's binary_logloss: 0.335958\n",
      "[121]\ttrain's binary_logloss: 0.335146\n",
      "[122]\ttrain's binary_logloss: 0.333571\n",
      "[123]\ttrain's binary_logloss: 0.332564\n",
      "[124]\ttrain's binary_logloss: 0.331984\n",
      "[125]\ttrain's binary_logloss: 0.331224\n",
      "[126]\ttrain's binary_logloss: 0.33044\n",
      "[127]\ttrain's binary_logloss: 0.32974\n",
      "[128]\ttrain's binary_logloss: 0.328766\n",
      "[129]\ttrain's binary_logloss: 0.327988\n",
      "[130]\ttrain's binary_logloss: 0.327226\n",
      "[131]\ttrain's binary_logloss: 0.326293\n",
      "[132]\ttrain's binary_logloss: 0.325219\n",
      "[133]\ttrain's binary_logloss: 0.323711\n",
      "[134]\ttrain's binary_logloss: 0.323081\n",
      "[135]\ttrain's binary_logloss: 0.321718\n",
      "[136]\ttrain's binary_logloss: 0.321142\n",
      "[137]\ttrain's binary_logloss: 0.320328\n",
      "[138]\ttrain's binary_logloss: 0.319378\n",
      "[139]\ttrain's binary_logloss: 0.318822\n",
      "[140]\ttrain's binary_logloss: 0.317859\n",
      "[141]\ttrain's binary_logloss: 0.31729\n",
      "[142]\ttrain's binary_logloss: 0.316314\n",
      "[143]\ttrain's binary_logloss: 0.315594\n",
      "[144]\ttrain's binary_logloss: 0.314675\n",
      "[145]\ttrain's binary_logloss: 0.313575\n",
      "[146]\ttrain's binary_logloss: 0.312904\n",
      "[147]\ttrain's binary_logloss: 0.31207\n",
      "[148]\ttrain's binary_logloss: 0.311461\n",
      "[149]\ttrain's binary_logloss: 0.310867\n",
      "[150]\ttrain's binary_logloss: 0.309872\n",
      "[151]\ttrain's binary_logloss: 0.309071\n",
      "[152]\ttrain's binary_logloss: 0.308102\n",
      "[153]\ttrain's binary_logloss: 0.307219\n",
      "[154]\ttrain's binary_logloss: 0.306427\n",
      "[155]\ttrain's binary_logloss: 0.305771\n",
      "[156]\ttrain's binary_logloss: 0.304692\n",
      "[157]\ttrain's binary_logloss: 0.303829\n",
      "[158]\ttrain's binary_logloss: 0.302958\n",
      "[159]\ttrain's binary_logloss: 0.302515\n",
      "[160]\ttrain's binary_logloss: 0.301781\n",
      "[161]\ttrain's binary_logloss: 0.301218\n",
      "[162]\ttrain's binary_logloss: 0.30076\n",
      "[163]\ttrain's binary_logloss: 0.299788\n",
      "[164]\ttrain's binary_logloss: 0.299011\n",
      "[165]\ttrain's binary_logloss: 0.298209\n",
      "[166]\ttrain's binary_logloss: 0.297688\n",
      "[167]\ttrain's binary_logloss: 0.296928\n",
      "[168]\ttrain's binary_logloss: 0.296486\n",
      "[169]\ttrain's binary_logloss: 0.295689\n",
      "[170]\ttrain's binary_logloss: 0.295135\n",
      "[171]\ttrain's binary_logloss: 0.293992\n",
      "[172]\ttrain's binary_logloss: 0.293065\n",
      "[173]\ttrain's binary_logloss: 0.292238\n",
      "[174]\ttrain's binary_logloss: 0.291605\n",
      "[175]\ttrain's binary_logloss: 0.290909\n",
      "[176]\ttrain's binary_logloss: 0.290163\n",
      "[177]\ttrain's binary_logloss: 0.289679\n",
      "[178]\ttrain's binary_logloss: 0.288876\n",
      "[179]\ttrain's binary_logloss: 0.287826\n",
      "[180]\ttrain's binary_logloss: 0.286768\n",
      "[181]\ttrain's binary_logloss: 0.2861\n",
      "[182]\ttrain's binary_logloss: 0.285568\n",
      "[183]\ttrain's binary_logloss: 0.285031\n",
      "[184]\ttrain's binary_logloss: 0.284179\n",
      "[185]\ttrain's binary_logloss: 0.28348\n",
      "[186]\ttrain's binary_logloss: 0.282782\n",
      "[187]\ttrain's binary_logloss: 0.282188\n",
      "[188]\ttrain's binary_logloss: 0.281734\n",
      "[189]\ttrain's binary_logloss: 0.28121\n",
      "[190]\ttrain's binary_logloss: 0.280441\n",
      "[191]\ttrain's binary_logloss: 0.279909\n",
      "[192]\ttrain's binary_logloss: 0.27899\n",
      "[193]\ttrain's binary_logloss: 0.278616\n",
      "[194]\ttrain's binary_logloss: 0.278\n",
      "[195]\ttrain's binary_logloss: 0.277302\n",
      "[196]\ttrain's binary_logloss: 0.276416\n",
      "[197]\ttrain's binary_logloss: 0.275802\n",
      "[198]\ttrain's binary_logloss: 0.275207\n",
      "[199]\ttrain's binary_logloss: 0.274815\n",
      "[200]\ttrain's binary_logloss: 0.274167\n",
      "[201]\ttrain's binary_logloss: 0.273716\n",
      "[202]\ttrain's binary_logloss: 0.272815\n",
      "[203]\ttrain's binary_logloss: 0.272177\n",
      "[204]\ttrain's binary_logloss: 0.271436\n",
      "[205]\ttrain's binary_logloss: 0.270776\n",
      "[206]\ttrain's binary_logloss: 0.270229\n",
      "[207]\ttrain's binary_logloss: 0.269779\n",
      "[208]\ttrain's binary_logloss: 0.269004\n",
      "[209]\ttrain's binary_logloss: 0.267872\n",
      "[210]\ttrain's binary_logloss: 0.267196\n",
      "[211]\ttrain's binary_logloss: 0.266571\n",
      "[212]\ttrain's binary_logloss: 0.26598\n",
      "[213]\ttrain's binary_logloss: 0.265654\n",
      "[214]\ttrain's binary_logloss: 0.264831\n",
      "[215]\ttrain's binary_logloss: 0.263983\n",
      "[216]\ttrain's binary_logloss: 0.262875\n",
      "[217]\ttrain's binary_logloss: 0.26229\n",
      "[218]\ttrain's binary_logloss: 0.26172\n",
      "[219]\ttrain's binary_logloss: 0.260831\n",
      "[220]\ttrain's binary_logloss: 0.260221\n",
      "[221]\ttrain's binary_logloss: 0.259489\n",
      "[222]\ttrain's binary_logloss: 0.258778\n",
      "[223]\ttrain's binary_logloss: 0.25811\n",
      "[224]\ttrain's binary_logloss: 0.257694\n",
      "[225]\ttrain's binary_logloss: 0.257083\n",
      "[226]\ttrain's binary_logloss: 0.256652\n",
      "[227]\ttrain's binary_logloss: 0.255637\n",
      "[228]\ttrain's binary_logloss: 0.255275\n",
      "[229]\ttrain's binary_logloss: 0.25436\n",
      "[230]\ttrain's binary_logloss: 0.253792\n",
      "[231]\ttrain's binary_logloss: 0.253338\n",
      "[232]\ttrain's binary_logloss: 0.252984\n",
      "[233]\ttrain's binary_logloss: 0.252331\n",
      "[234]\ttrain's binary_logloss: 0.251858\n",
      "[235]\ttrain's binary_logloss: 0.251312\n",
      "[236]\ttrain's binary_logloss: 0.250489\n",
      "[237]\ttrain's binary_logloss: 0.250099\n",
      "[238]\ttrain's binary_logloss: 0.249802\n",
      "[239]\ttrain's binary_logloss: 0.249211\n",
      "[240]\ttrain's binary_logloss: 0.24873\n",
      "[241]\ttrain's binary_logloss: 0.248368\n",
      "[242]\ttrain's binary_logloss: 0.247962\n",
      "[243]\ttrain's binary_logloss: 0.247223\n",
      "[244]\ttrain's binary_logloss: 0.246523\n",
      "[245]\ttrain's binary_logloss: 0.245704\n",
      "[246]\ttrain's binary_logloss: 0.245339\n",
      "[247]\ttrain's binary_logloss: 0.244785\n",
      "[248]\ttrain's binary_logloss: 0.244489\n",
      "[249]\ttrain's binary_logloss: 0.244123\n",
      "[250]\ttrain's binary_logloss: 0.243491\n",
      "[251]\ttrain's binary_logloss: 0.242877\n",
      "[252]\ttrain's binary_logloss: 0.24253\n",
      "[253]\ttrain's binary_logloss: 0.242084\n",
      "[254]\ttrain's binary_logloss: 0.241631\n",
      "[255]\ttrain's binary_logloss: 0.241128\n",
      "[256]\ttrain's binary_logloss: 0.240535\n",
      "[257]\ttrain's binary_logloss: 0.240056\n",
      "[258]\ttrain's binary_logloss: 0.23977\n",
      "[259]\ttrain's binary_logloss: 0.239386\n",
      "[260]\ttrain's binary_logloss: 0.238696\n",
      "[261]\ttrain's binary_logloss: 0.238307\n",
      "[262]\ttrain's binary_logloss: 0.237724\n",
      "[263]\ttrain's binary_logloss: 0.23714\n",
      "[264]\ttrain's binary_logloss: 0.236582\n",
      "[265]\ttrain's binary_logloss: 0.236232\n",
      "[266]\ttrain's binary_logloss: 0.235868\n",
      "[267]\ttrain's binary_logloss: 0.235129\n",
      "[268]\ttrain's binary_logloss: 0.234585\n",
      "[269]\ttrain's binary_logloss: 0.23423\n",
      "[270]\ttrain's binary_logloss: 0.233736\n",
      "[271]\ttrain's binary_logloss: 0.233189\n",
      "[272]\ttrain's binary_logloss: 0.232941\n",
      "[273]\ttrain's binary_logloss: 0.23242\n",
      "[274]\ttrain's binary_logloss: 0.231679\n",
      "[275]\ttrain's binary_logloss: 0.231218\n",
      "[276]\ttrain's binary_logloss: 0.23099\n",
      "[277]\ttrain's binary_logloss: 0.230563\n",
      "[278]\ttrain's binary_logloss: 0.229942\n",
      "[279]\ttrain's binary_logloss: 0.229532\n",
      "[280]\ttrain's binary_logloss: 0.22913\n",
      "[281]\ttrain's binary_logloss: 0.228747\n",
      "[282]\ttrain's binary_logloss: 0.227907\n",
      "[283]\ttrain's binary_logloss: 0.227236\n",
      "[284]\ttrain's binary_logloss: 0.226918\n",
      "[285]\ttrain's binary_logloss: 0.226609\n",
      "[286]\ttrain's binary_logloss: 0.226241\n",
      "[287]\ttrain's binary_logloss: 0.2259\n",
      "[288]\ttrain's binary_logloss: 0.225565\n",
      "[289]\ttrain's binary_logloss: 0.225198\n",
      "[290]\ttrain's binary_logloss: 0.224945\n",
      "[291]\ttrain's binary_logloss: 0.224465\n",
      "[292]\ttrain's binary_logloss: 0.224152\n",
      "[293]\ttrain's binary_logloss: 0.223747\n",
      "[294]\ttrain's binary_logloss: 0.223332\n",
      "[295]\ttrain's binary_logloss: 0.223046\n",
      "[296]\ttrain's binary_logloss: 0.222285\n",
      "[297]\ttrain's binary_logloss: 0.221907\n",
      "[298]\ttrain's binary_logloss: 0.221567\n",
      "[299]\ttrain's binary_logloss: 0.221273\n",
      "[300]\ttrain's binary_logloss: 0.220611\n",
      "[301]\ttrain's binary_logloss: 0.220213\n",
      "[302]\ttrain's binary_logloss: 0.21992\n",
      "[303]\ttrain's binary_logloss: 0.219641\n",
      "[304]\ttrain's binary_logloss: 0.219161\n",
      "[305]\ttrain's binary_logloss: 0.218723\n",
      "[306]\ttrain's binary_logloss: 0.218309\n",
      "[307]\ttrain's binary_logloss: 0.21755\n",
      "[308]\ttrain's binary_logloss: 0.217223\n",
      "[309]\ttrain's binary_logloss: 0.216722\n",
      "[310]\ttrain's binary_logloss: 0.216242\n",
      "[311]\ttrain's binary_logloss: 0.216004\n",
      "[312]\ttrain's binary_logloss: 0.215234\n",
      "[313]\ttrain's binary_logloss: 0.214731\n",
      "[314]\ttrain's binary_logloss: 0.214299\n",
      "[315]\ttrain's binary_logloss: 0.213988\n",
      "[316]\ttrain's binary_logloss: 0.213743\n",
      "[317]\ttrain's binary_logloss: 0.21342\n",
      "[318]\ttrain's binary_logloss: 0.212993\n",
      "[319]\ttrain's binary_logloss: 0.212576\n",
      "[320]\ttrain's binary_logloss: 0.21198\n",
      "[321]\ttrain's binary_logloss: 0.211424\n",
      "[322]\ttrain's binary_logloss: 0.21098\n",
      "[323]\ttrain's binary_logloss: 0.210717\n",
      "[324]\ttrain's binary_logloss: 0.210308\n",
      "[325]\ttrain's binary_logloss: 0.209841\n",
      "[326]\ttrain's binary_logloss: 0.208946\n",
      "[327]\ttrain's binary_logloss: 0.208284\n",
      "[328]\ttrain's binary_logloss: 0.207906\n",
      "[329]\ttrain's binary_logloss: 0.207541\n",
      "[330]\ttrain's binary_logloss: 0.207287\n",
      "[331]\ttrain's binary_logloss: 0.206782\n",
      "[332]\ttrain's binary_logloss: 0.206542\n",
      "[333]\ttrain's binary_logloss: 0.205731\n",
      "[334]\ttrain's binary_logloss: 0.20523\n",
      "[335]\ttrain's binary_logloss: 0.204782\n",
      "[336]\ttrain's binary_logloss: 0.204562\n",
      "[337]\ttrain's binary_logloss: 0.204267\n",
      "[338]\ttrain's binary_logloss: 0.204085\n",
      "[339]\ttrain's binary_logloss: 0.203701\n",
      "[340]\ttrain's binary_logloss: 0.203224\n",
      "[341]\ttrain's binary_logloss: 0.202829\n",
      "[342]\ttrain's binary_logloss: 0.202252\n",
      "[343]\ttrain's binary_logloss: 0.201751\n",
      "[344]\ttrain's binary_logloss: 0.201267\n",
      "[345]\ttrain's binary_logloss: 0.200805\n",
      "[346]\ttrain's binary_logloss: 0.200549\n",
      "[347]\ttrain's binary_logloss: 0.200051\n",
      "[348]\ttrain's binary_logloss: 0.199563\n",
      "[349]\ttrain's binary_logloss: 0.199131\n",
      "[350]\ttrain's binary_logloss: 0.198731\n",
      "[351]\ttrain's binary_logloss: 0.1983\n",
      "[352]\ttrain's binary_logloss: 0.197941\n",
      "[353]\ttrain's binary_logloss: 0.197673\n",
      "[354]\ttrain's binary_logloss: 0.197497\n",
      "[355]\ttrain's binary_logloss: 0.197346\n",
      "[356]\ttrain's binary_logloss: 0.196909\n",
      "[357]\ttrain's binary_logloss: 0.196737\n",
      "[358]\ttrain's binary_logloss: 0.196233\n",
      "[359]\ttrain's binary_logloss: 0.195819\n",
      "[360]\ttrain's binary_logloss: 0.195374\n",
      "[361]\ttrain's binary_logloss: 0.194856\n",
      "[362]\ttrain's binary_logloss: 0.194501\n",
      "[363]\ttrain's binary_logloss: 0.194192\n",
      "[364]\ttrain's binary_logloss: 0.193896\n",
      "[365]\ttrain's binary_logloss: 0.193524\n",
      "[366]\ttrain's binary_logloss: 0.193074\n",
      "[367]\ttrain's binary_logloss: 0.192726\n",
      "[368]\ttrain's binary_logloss: 0.192346\n",
      "[369]\ttrain's binary_logloss: 0.19207\n",
      "[370]\ttrain's binary_logloss: 0.191551\n",
      "[371]\ttrain's binary_logloss: 0.19121\n",
      "[372]\ttrain's binary_logloss: 0.190668\n",
      "[373]\ttrain's binary_logloss: 0.190357\n",
      "[374]\ttrain's binary_logloss: 0.189708\n",
      "[375]\ttrain's binary_logloss: 0.189166\n",
      "[376]\ttrain's binary_logloss: 0.188481\n",
      "[377]\ttrain's binary_logloss: 0.187923\n",
      "[378]\ttrain's binary_logloss: 0.187387\n",
      "[379]\ttrain's binary_logloss: 0.186829\n",
      "[380]\ttrain's binary_logloss: 0.186359\n",
      "[381]\ttrain's binary_logloss: 0.186049\n",
      "[382]\ttrain's binary_logloss: 0.185431\n",
      "[383]\ttrain's binary_logloss: 0.184966\n",
      "[384]\ttrain's binary_logloss: 0.184586\n",
      "[385]\ttrain's binary_logloss: 0.183982\n",
      "[386]\ttrain's binary_logloss: 0.183568\n",
      "[387]\ttrain's binary_logloss: 0.183413\n",
      "[388]\ttrain's binary_logloss: 0.182946\n",
      "[389]\ttrain's binary_logloss: 0.182525\n",
      "[390]\ttrain's binary_logloss: 0.181952\n",
      "[391]\ttrain's binary_logloss: 0.181528\n",
      "[392]\ttrain's binary_logloss: 0.18083\n",
      "[393]\ttrain's binary_logloss: 0.180543\n",
      "[394]\ttrain's binary_logloss: 0.180241\n",
      "[395]\ttrain's binary_logloss: 0.179704\n",
      "[396]\ttrain's binary_logloss: 0.179356\n",
      "[397]\ttrain's binary_logloss: 0.179073\n",
      "[398]\ttrain's binary_logloss: 0.178589\n",
      "[399]\ttrain's binary_logloss: 0.178339\n",
      "[400]\ttrain's binary_logloss: 0.17809\n",
      "[401]\ttrain's binary_logloss: 0.177719\n",
      "[402]\ttrain's binary_logloss: 0.177188\n",
      "[403]\ttrain's binary_logloss: 0.176908\n",
      "[404]\ttrain's binary_logloss: 0.176348\n",
      "[405]\ttrain's binary_logloss: 0.176101\n",
      "[406]\ttrain's binary_logloss: 0.175761\n",
      "[407]\ttrain's binary_logloss: 0.175526\n",
      "[408]\ttrain's binary_logloss: 0.175253\n",
      "[409]\ttrain's binary_logloss: 0.174833\n",
      "[410]\ttrain's binary_logloss: 0.174486\n",
      "[411]\ttrain's binary_logloss: 0.174289\n",
      "[412]\ttrain's binary_logloss: 0.173642\n",
      "[413]\ttrain's binary_logloss: 0.173361\n",
      "[414]\ttrain's binary_logloss: 0.172989\n",
      "[415]\ttrain's binary_logloss: 0.172507\n",
      "[416]\ttrain's binary_logloss: 0.17226\n",
      "[417]\ttrain's binary_logloss: 0.171865\n",
      "[418]\ttrain's binary_logloss: 0.171421\n",
      "[419]\ttrain's binary_logloss: 0.171136\n",
      "[420]\ttrain's binary_logloss: 0.170918\n",
      "[421]\ttrain's binary_logloss: 0.170276\n",
      "[422]\ttrain's binary_logloss: 0.169918\n",
      "[423]\ttrain's binary_logloss: 0.169643\n",
      "[424]\ttrain's binary_logloss: 0.169293\n",
      "[425]\ttrain's binary_logloss: 0.169112\n",
      "[426]\ttrain's binary_logloss: 0.16862\n",
      "[427]\ttrain's binary_logloss: 0.168273\n",
      "[428]\ttrain's binary_logloss: 0.167871\n",
      "[429]\ttrain's binary_logloss: 0.167623\n",
      "[430]\ttrain's binary_logloss: 0.167426\n",
      "[431]\ttrain's binary_logloss: 0.166944\n",
      "[432]\ttrain's binary_logloss: 0.166616\n",
      "[433]\ttrain's binary_logloss: 0.166257\n",
      "[434]\ttrain's binary_logloss: 0.166075\n",
      "[435]\ttrain's binary_logloss: 0.165558\n",
      "[436]\ttrain's binary_logloss: 0.165281\n",
      "[437]\ttrain's binary_logloss: 0.165056\n",
      "[438]\ttrain's binary_logloss: 0.164855\n",
      "[439]\ttrain's binary_logloss: 0.164418\n",
      "[440]\ttrain's binary_logloss: 0.163917\n",
      "[441]\ttrain's binary_logloss: 0.163484\n",
      "[442]\ttrain's binary_logloss: 0.163367\n",
      "[443]\ttrain's binary_logloss: 0.163146\n",
      "[444]\ttrain's binary_logloss: 0.162918\n",
      "[445]\ttrain's binary_logloss: 0.1626\n",
      "[446]\ttrain's binary_logloss: 0.162193\n",
      "[447]\ttrain's binary_logloss: 0.16195\n",
      "[448]\ttrain's binary_logloss: 0.161755\n",
      "[449]\ttrain's binary_logloss: 0.16139\n",
      "[450]\ttrain's binary_logloss: 0.16113\n",
      "[451]\ttrain's binary_logloss: 0.160798\n",
      "[452]\ttrain's binary_logloss: 0.160367\n",
      "[453]\ttrain's binary_logloss: 0.160173\n",
      "[454]\ttrain's binary_logloss: 0.160004\n",
      "[455]\ttrain's binary_logloss: 0.159851\n",
      "[456]\ttrain's binary_logloss: 0.15963\n",
      "[457]\ttrain's binary_logloss: 0.159342\n",
      "[458]\ttrain's binary_logloss: 0.158956\n",
      "[459]\ttrain's binary_logloss: 0.158747\n",
      "[460]\ttrain's binary_logloss: 0.158549\n",
      "[461]\ttrain's binary_logloss: 0.158198\n",
      "[462]\ttrain's binary_logloss: 0.157527\n",
      "[463]\ttrain's binary_logloss: 0.157263\n",
      "[464]\ttrain's binary_logloss: 0.157004\n",
      "[465]\ttrain's binary_logloss: 0.156493\n",
      "[466]\ttrain's binary_logloss: 0.156155\n",
      "[467]\ttrain's binary_logloss: 0.156\n",
      "[468]\ttrain's binary_logloss: 0.155591\n",
      "[469]\ttrain's binary_logloss: 0.154938\n",
      "[470]\ttrain's binary_logloss: 0.154755\n",
      "[471]\ttrain's binary_logloss: 0.154591\n",
      "[472]\ttrain's binary_logloss: 0.154373\n",
      "[473]\ttrain's binary_logloss: 0.154156\n",
      "[474]\ttrain's binary_logloss: 0.153797\n",
      "[475]\ttrain's binary_logloss: 0.153479\n",
      "[476]\ttrain's binary_logloss: 0.153004\n",
      "[477]\ttrain's binary_logloss: 0.152814\n",
      "[478]\ttrain's binary_logloss: 0.152484\n",
      "[479]\ttrain's binary_logloss: 0.152381\n",
      "[480]\ttrain's binary_logloss: 0.15209\n",
      "[481]\ttrain's binary_logloss: 0.151521\n",
      "[482]\ttrain's binary_logloss: 0.151195\n",
      "[483]\ttrain's binary_logloss: 0.150919\n",
      "[484]\ttrain's binary_logloss: 0.150498\n",
      "[485]\ttrain's binary_logloss: 0.150235\n",
      "[486]\ttrain's binary_logloss: 0.15008\n",
      "[487]\ttrain's binary_logloss: 0.149875\n",
      "[488]\ttrain's binary_logloss: 0.1497\n",
      "[489]\ttrain's binary_logloss: 0.149427\n",
      "[490]\ttrain's binary_logloss: 0.148995\n",
      "[491]\ttrain's binary_logloss: 0.148707\n",
      "[492]\ttrain's binary_logloss: 0.148535\n",
      "[493]\ttrain's binary_logloss: 0.148291\n",
      "[494]\ttrain's binary_logloss: 0.148023\n",
      "[495]\ttrain's binary_logloss: 0.1476\n",
      "[496]\ttrain's binary_logloss: 0.147413\n",
      "[497]\ttrain's binary_logloss: 0.147097\n",
      "[498]\ttrain's binary_logloss: 0.146752\n",
      "[499]\ttrain's binary_logloss: 0.146375\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "[0]\ttest-logloss:0.59573\n",
      "[1]\ttest-logloss:0.58371\n",
      "[2]\ttest-logloss:0.57642\n",
      "[3]\ttest-logloss:0.58736\n",
      "[4]\ttest-logloss:0.58414\n",
      "[5]\ttest-logloss:0.58967\n",
      "[6]\ttest-logloss:0.59291\n",
      "[7]\ttest-logloss:0.59738\n",
      "[8]\ttest-logloss:0.59849\n",
      "[9]\ttest-logloss:0.59946\n",
      "[10]\ttest-logloss:0.60594\n",
      "[11]\ttest-logloss:0.60589\n",
      "[12]\ttest-logloss:0.60974\n",
      "[13]\ttest-logloss:0.60995\n",
      "[14]\ttest-logloss:0.61244\n",
      "[15]\ttest-logloss:0.61994\n",
      "[16]\ttest-logloss:0.62884\n",
      "[17]\ttest-logloss:0.63393\n",
      "[18]\ttest-logloss:0.63189\n",
      "[19]\ttest-logloss:0.62428\n",
      "[20]\ttest-logloss:0.63861\n",
      "[21]\ttest-logloss:0.63952\n",
      "X_trainの形状： (646, 24)  y_trainの形状： (646,)  X_testの形状： (278, 24)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.662906\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.638297\n",
      "[3]\ttrain's binary_logloss: 0.617479\n",
      "[4]\ttrain's binary_logloss: 0.600501\n",
      "[5]\ttrain's binary_logloss: 0.585878\n",
      "[6]\ttrain's binary_logloss: 0.573603\n",
      "[7]\ttrain's binary_logloss: 0.562965\n",
      "[8]\ttrain's binary_logloss: 0.553485\n",
      "[9]\ttrain's binary_logloss: 0.545568\n",
      "[10]\ttrain's binary_logloss: 0.538341\n",
      "[11]\ttrain's binary_logloss: 0.53218\n",
      "[12]\ttrain's binary_logloss: 0.526888\n",
      "[13]\ttrain's binary_logloss: 0.521507\n",
      "[14]\ttrain's binary_logloss: 0.516283\n",
      "[15]\ttrain's binary_logloss: 0.511686\n",
      "[16]\ttrain's binary_logloss: 0.507458\n",
      "[17]\ttrain's binary_logloss: 0.502668\n",
      "[18]\ttrain's binary_logloss: 0.498687\n",
      "[19]\ttrain's binary_logloss: 0.494656\n",
      "[20]\ttrain's binary_logloss: 0.491561\n",
      "[21]\ttrain's binary_logloss: 0.488351\n",
      "[22]\ttrain's binary_logloss: 0.485573\n",
      "[23]\ttrain's binary_logloss: 0.482171\n",
      "[24]\ttrain's binary_logloss: 0.479149\n",
      "[25]\ttrain's binary_logloss: 0.476664\n",
      "[26]\ttrain's binary_logloss: 0.473929\n",
      "[27]\ttrain's binary_logloss: 0.471448\n",
      "[28]\ttrain's binary_logloss: 0.469294\n",
      "[29]\ttrain's binary_logloss: 0.466646\n",
      "[30]\ttrain's binary_logloss: 0.463765\n",
      "[31]\ttrain's binary_logloss: 0.461489\n",
      "[32]\ttrain's binary_logloss: 0.45924\n",
      "[33]\ttrain's binary_logloss: 0.456848\n",
      "[34]\ttrain's binary_logloss: 0.454888\n",
      "[35]\ttrain's binary_logloss: 0.452506\n",
      "[36]\ttrain's binary_logloss: 0.450764\n",
      "[37]\ttrain's binary_logloss: 0.448826\n",
      "[38]\ttrain's binary_logloss: 0.446645\n",
      "[39]\ttrain's binary_logloss: 0.444878\n",
      "[40]\ttrain's binary_logloss: 0.44312\n",
      "[41]\ttrain's binary_logloss: 0.441225\n",
      "[42]\ttrain's binary_logloss: 0.43862\n",
      "[43]\ttrain's binary_logloss: 0.43714\n",
      "[44]\ttrain's binary_logloss: 0.435454\n",
      "[45]\ttrain's binary_logloss: 0.433442\n",
      "[46]\ttrain's binary_logloss: 0.431905\n",
      "[47]\ttrain's binary_logloss: 0.430126\n",
      "[48]\ttrain's binary_logloss: 0.428234\n",
      "[49]\ttrain's binary_logloss: 0.42696\n",
      "[50]\ttrain's binary_logloss: 0.424765\n",
      "[51]\ttrain's binary_logloss: 0.423088\n",
      "[52]\ttrain's binary_logloss: 0.421902\n",
      "[53]\ttrain's binary_logloss: 0.420318\n",
      "[54]\ttrain's binary_logloss: 0.418909\n",
      "[55]\ttrain's binary_logloss: 0.417007\n",
      "[56]\ttrain's binary_logloss: 0.415208\n",
      "[57]\ttrain's binary_logloss: 0.413514\n",
      "[58]\ttrain's binary_logloss: 0.412293\n",
      "[59]\ttrain's binary_logloss: 0.411102\n",
      "[60]\ttrain's binary_logloss: 0.40967\n",
      "[61]\ttrain's binary_logloss: 0.407243\n",
      "[62]\ttrain's binary_logloss: 0.40599\n",
      "[63]\ttrain's binary_logloss: 0.404919\n",
      "[64]\ttrain's binary_logloss: 0.403409\n",
      "[65]\ttrain's binary_logloss: 0.402214\n",
      "[66]\ttrain's binary_logloss: 0.400646\n",
      "[67]\ttrain's binary_logloss: 0.398702\n",
      "[68]\ttrain's binary_logloss: 0.397395\n",
      "[69]\ttrain's binary_logloss: 0.395586\n",
      "[70]\ttrain's binary_logloss: 0.393765\n",
      "[71]\ttrain's binary_logloss: 0.392805\n",
      "[72]\ttrain's binary_logloss: 0.391712\n",
      "[73]\ttrain's binary_logloss: 0.390657\n",
      "[74]\ttrain's binary_logloss: 0.388989\n",
      "[75]\ttrain's binary_logloss: 0.38764\n",
      "[76]\ttrain's binary_logloss: 0.386751\n",
      "[77]\ttrain's binary_logloss: 0.384699\n",
      "[78]\ttrain's binary_logloss: 0.382528\n",
      "[79]\ttrain's binary_logloss: 0.381192\n",
      "[80]\ttrain's binary_logloss: 0.380259\n",
      "[81]\ttrain's binary_logloss: 0.378934\n",
      "[82]\ttrain's binary_logloss: 0.377976\n",
      "[83]\ttrain's binary_logloss: 0.376874\n",
      "[84]\ttrain's binary_logloss: 0.375969\n",
      "[85]\ttrain's binary_logloss: 0.374852\n",
      "[86]\ttrain's binary_logloss: 0.373135\n",
      "[87]\ttrain's binary_logloss: 0.371574\n",
      "[88]\ttrain's binary_logloss: 0.370593\n",
      "[89]\ttrain's binary_logloss: 0.369757\n",
      "[90]\ttrain's binary_logloss: 0.368328\n",
      "[91]\ttrain's binary_logloss: 0.367325\n",
      "[92]\ttrain's binary_logloss: 0.36639\n",
      "[93]\ttrain's binary_logloss: 0.365162\n",
      "[94]\ttrain's binary_logloss: 0.364408\n",
      "[95]\ttrain's binary_logloss: 0.362858\n",
      "[96]\ttrain's binary_logloss: 0.360926\n",
      "[97]\ttrain's binary_logloss: 0.35941\n",
      "[98]\ttrain's binary_logloss: 0.358207\n",
      "[99]\ttrain's binary_logloss: 0.357537\n",
      "[100]\ttrain's binary_logloss: 0.356465\n",
      "[101]\ttrain's binary_logloss: 0.355643\n",
      "[102]\ttrain's binary_logloss: 0.354476\n",
      "[103]\ttrain's binary_logloss: 0.353127\n",
      "[104]\ttrain's binary_logloss: 0.352091\n",
      "[105]\ttrain's binary_logloss: 0.350762\n",
      "[106]\ttrain's binary_logloss: 0.349704\n",
      "[107]\ttrain's binary_logloss: 0.348859\n",
      "[108]\ttrain's binary_logloss: 0.347836\n",
      "[109]\ttrain's binary_logloss: 0.346703\n",
      "[110]\ttrain's binary_logloss: 0.345726\n",
      "[111]\ttrain's binary_logloss: 0.344929\n",
      "[112]\ttrain's binary_logloss: 0.344232\n",
      "[113]\ttrain's binary_logloss: 0.343464\n",
      "[114]\ttrain's binary_logloss: 0.342828\n",
      "[115]\ttrain's binary_logloss: 0.341282\n",
      "[116]\ttrain's binary_logloss: 0.339423\n",
      "[117]\ttrain's binary_logloss: 0.338747\n",
      "[118]\ttrain's binary_logloss: 0.337414\n",
      "[119]\ttrain's binary_logloss: 0.336814\n",
      "[120]\ttrain's binary_logloss: 0.335958\n",
      "[121]\ttrain's binary_logloss: 0.335146\n",
      "[122]\ttrain's binary_logloss: 0.333571\n",
      "[123]\ttrain's binary_logloss: 0.332564\n",
      "[124]\ttrain's binary_logloss: 0.331984\n",
      "[125]\ttrain's binary_logloss: 0.331224\n",
      "[126]\ttrain's binary_logloss: 0.33044\n",
      "[127]\ttrain's binary_logloss: 0.32974\n",
      "[128]\ttrain's binary_logloss: 0.328766\n",
      "[129]\ttrain's binary_logloss: 0.327988\n",
      "[130]\ttrain's binary_logloss: 0.327226\n",
      "[131]\ttrain's binary_logloss: 0.326293\n",
      "[132]\ttrain's binary_logloss: 0.325219\n",
      "[133]\ttrain's binary_logloss: 0.323711\n",
      "[134]\ttrain's binary_logloss: 0.323081\n",
      "[135]\ttrain's binary_logloss: 0.321718\n",
      "[136]\ttrain's binary_logloss: 0.321142\n",
      "[137]\ttrain's binary_logloss: 0.320328\n",
      "[138]\ttrain's binary_logloss: 0.319378\n",
      "[139]\ttrain's binary_logloss: 0.318822\n",
      "[140]\ttrain's binary_logloss: 0.317859\n",
      "[141]\ttrain's binary_logloss: 0.31729\n",
      "[142]\ttrain's binary_logloss: 0.316314\n",
      "[143]\ttrain's binary_logloss: 0.315594\n",
      "[144]\ttrain's binary_logloss: 0.314675\n",
      "[145]\ttrain's binary_logloss: 0.313575\n",
      "[146]\ttrain's binary_logloss: 0.312904\n",
      "[147]\ttrain's binary_logloss: 0.31207\n",
      "[148]\ttrain's binary_logloss: 0.311461\n",
      "[149]\ttrain's binary_logloss: 0.310867\n",
      "[150]\ttrain's binary_logloss: 0.309872\n",
      "[151]\ttrain's binary_logloss: 0.309071\n",
      "[152]\ttrain's binary_logloss: 0.308102\n",
      "[153]\ttrain's binary_logloss: 0.307219\n",
      "[154]\ttrain's binary_logloss: 0.306427\n",
      "[155]\ttrain's binary_logloss: 0.305771\n",
      "[156]\ttrain's binary_logloss: 0.304692\n",
      "[157]\ttrain's binary_logloss: 0.303829\n",
      "[158]\ttrain's binary_logloss: 0.302958\n",
      "[159]\ttrain's binary_logloss: 0.302515\n",
      "[160]\ttrain's binary_logloss: 0.301781\n",
      "[161]\ttrain's binary_logloss: 0.301218\n",
      "[162]\ttrain's binary_logloss: 0.30076\n",
      "[163]\ttrain's binary_logloss: 0.299788\n",
      "[164]\ttrain's binary_logloss: 0.299011\n",
      "[165]\ttrain's binary_logloss: 0.298209\n",
      "[166]\ttrain's binary_logloss: 0.297688\n",
      "[167]\ttrain's binary_logloss: 0.296928\n",
      "[168]\ttrain's binary_logloss: 0.296486\n",
      "[169]\ttrain's binary_logloss: 0.295689\n",
      "[170]\ttrain's binary_logloss: 0.295135\n",
      "[171]\ttrain's binary_logloss: 0.293992\n",
      "[172]\ttrain's binary_logloss: 0.293065\n",
      "[173]\ttrain's binary_logloss: 0.292238\n",
      "[174]\ttrain's binary_logloss: 0.291605\n",
      "[175]\ttrain's binary_logloss: 0.290909\n",
      "[176]\ttrain's binary_logloss: 0.290163\n",
      "[177]\ttrain's binary_logloss: 0.289679\n",
      "[178]\ttrain's binary_logloss: 0.288876\n",
      "[179]\ttrain's binary_logloss: 0.287826\n",
      "[180]\ttrain's binary_logloss: 0.286768\n",
      "[181]\ttrain's binary_logloss: 0.2861\n",
      "[182]\ttrain's binary_logloss: 0.285568\n",
      "[183]\ttrain's binary_logloss: 0.285031\n",
      "[184]\ttrain's binary_logloss: 0.284179\n",
      "[185]\ttrain's binary_logloss: 0.28348\n",
      "[186]\ttrain's binary_logloss: 0.282782\n",
      "[187]\ttrain's binary_logloss: 0.282188\n",
      "[188]\ttrain's binary_logloss: 0.281734\n",
      "[189]\ttrain's binary_logloss: 0.28121\n",
      "[190]\ttrain's binary_logloss: 0.280441\n",
      "[191]\ttrain's binary_logloss: 0.279909\n",
      "[192]\ttrain's binary_logloss: 0.27899\n",
      "[193]\ttrain's binary_logloss: 0.278616\n",
      "[194]\ttrain's binary_logloss: 0.278\n",
      "[195]\ttrain's binary_logloss: 0.277302\n",
      "[196]\ttrain's binary_logloss: 0.276416\n",
      "[197]\ttrain's binary_logloss: 0.275802\n",
      "[198]\ttrain's binary_logloss: 0.275207\n",
      "[199]\ttrain's binary_logloss: 0.274815\n",
      "[200]\ttrain's binary_logloss: 0.274167\n",
      "[201]\ttrain's binary_logloss: 0.273716\n",
      "[202]\ttrain's binary_logloss: 0.272815\n",
      "[203]\ttrain's binary_logloss: 0.272177\n",
      "[204]\ttrain's binary_logloss: 0.271436\n",
      "[205]\ttrain's binary_logloss: 0.270776\n",
      "[206]\ttrain's binary_logloss: 0.270229\n",
      "[207]\ttrain's binary_logloss: 0.269779\n",
      "[208]\ttrain's binary_logloss: 0.269004\n",
      "[209]\ttrain's binary_logloss: 0.267872\n",
      "[210]\ttrain's binary_logloss: 0.267196\n",
      "[211]\ttrain's binary_logloss: 0.266571\n",
      "[212]\ttrain's binary_logloss: 0.26598\n",
      "[213]\ttrain's binary_logloss: 0.265654\n",
      "[214]\ttrain's binary_logloss: 0.264831\n",
      "[215]\ttrain's binary_logloss: 0.263983\n",
      "[216]\ttrain's binary_logloss: 0.262875\n",
      "[217]\ttrain's binary_logloss: 0.26229\n",
      "[218]\ttrain's binary_logloss: 0.26172\n",
      "[219]\ttrain's binary_logloss: 0.260831\n",
      "[220]\ttrain's binary_logloss: 0.260221\n",
      "[221]\ttrain's binary_logloss: 0.259489\n",
      "[222]\ttrain's binary_logloss: 0.258778\n",
      "[223]\ttrain's binary_logloss: 0.25811\n",
      "[224]\ttrain's binary_logloss: 0.257694\n",
      "[225]\ttrain's binary_logloss: 0.257083\n",
      "[226]\ttrain's binary_logloss: 0.256652\n",
      "[227]\ttrain's binary_logloss: 0.255637\n",
      "[228]\ttrain's binary_logloss: 0.255275\n",
      "[229]\ttrain's binary_logloss: 0.25436\n",
      "[230]\ttrain's binary_logloss: 0.253792\n",
      "[231]\ttrain's binary_logloss: 0.253338\n",
      "[232]\ttrain's binary_logloss: 0.252984\n",
      "[233]\ttrain's binary_logloss: 0.252331\n",
      "[234]\ttrain's binary_logloss: 0.251858\n",
      "[235]\ttrain's binary_logloss: 0.251312\n",
      "[236]\ttrain's binary_logloss: 0.250489\n",
      "[237]\ttrain's binary_logloss: 0.250099\n",
      "[238]\ttrain's binary_logloss: 0.249802\n",
      "[239]\ttrain's binary_logloss: 0.249211\n",
      "[240]\ttrain's binary_logloss: 0.24873\n",
      "[241]\ttrain's binary_logloss: 0.248368\n",
      "[242]\ttrain's binary_logloss: 0.247962\n",
      "[243]\ttrain's binary_logloss: 0.247223\n",
      "[244]\ttrain's binary_logloss: 0.246523\n",
      "[245]\ttrain's binary_logloss: 0.245704\n",
      "[246]\ttrain's binary_logloss: 0.245339\n",
      "[247]\ttrain's binary_logloss: 0.244785\n",
      "[248]\ttrain's binary_logloss: 0.244489\n",
      "[249]\ttrain's binary_logloss: 0.244123\n",
      "[250]\ttrain's binary_logloss: 0.243491\n",
      "[251]\ttrain's binary_logloss: 0.242877\n",
      "[252]\ttrain's binary_logloss: 0.24253\n",
      "[253]\ttrain's binary_logloss: 0.242084\n",
      "[254]\ttrain's binary_logloss: 0.241631\n",
      "[255]\ttrain's binary_logloss: 0.241128\n",
      "[256]\ttrain's binary_logloss: 0.240535\n",
      "[257]\ttrain's binary_logloss: 0.240056\n",
      "[258]\ttrain's binary_logloss: 0.23977\n",
      "[259]\ttrain's binary_logloss: 0.239386\n",
      "[260]\ttrain's binary_logloss: 0.238696\n",
      "[261]\ttrain's binary_logloss: 0.238307\n",
      "[262]\ttrain's binary_logloss: 0.237724\n",
      "[263]\ttrain's binary_logloss: 0.23714\n",
      "[264]\ttrain's binary_logloss: 0.236582\n",
      "[265]\ttrain's binary_logloss: 0.236232\n",
      "[266]\ttrain's binary_logloss: 0.235868\n",
      "[267]\ttrain's binary_logloss: 0.235129\n",
      "[268]\ttrain's binary_logloss: 0.234585\n",
      "[269]\ttrain's binary_logloss: 0.23423\n",
      "[270]\ttrain's binary_logloss: 0.233736\n",
      "[271]\ttrain's binary_logloss: 0.233189\n",
      "[272]\ttrain's binary_logloss: 0.232941\n",
      "[273]\ttrain's binary_logloss: 0.23242\n",
      "[274]\ttrain's binary_logloss: 0.231679\n",
      "[275]\ttrain's binary_logloss: 0.231218\n",
      "[276]\ttrain's binary_logloss: 0.23099\n",
      "[277]\ttrain's binary_logloss: 0.230563\n",
      "[278]\ttrain's binary_logloss: 0.229942\n",
      "[279]\ttrain's binary_logloss: 0.229532\n",
      "[280]\ttrain's binary_logloss: 0.22913\n",
      "[281]\ttrain's binary_logloss: 0.228747\n",
      "[282]\ttrain's binary_logloss: 0.227907\n",
      "[283]\ttrain's binary_logloss: 0.227236\n",
      "[284]\ttrain's binary_logloss: 0.226918\n",
      "[285]\ttrain's binary_logloss: 0.226609\n",
      "[286]\ttrain's binary_logloss: 0.226241\n",
      "[287]\ttrain's binary_logloss: 0.2259\n",
      "[288]\ttrain's binary_logloss: 0.225565\n",
      "[289]\ttrain's binary_logloss: 0.225198\n",
      "[290]\ttrain's binary_logloss: 0.224945\n",
      "[291]\ttrain's binary_logloss: 0.224465\n",
      "[292]\ttrain's binary_logloss: 0.224152\n",
      "[293]\ttrain's binary_logloss: 0.223747\n",
      "[294]\ttrain's binary_logloss: 0.223332\n",
      "[295]\ttrain's binary_logloss: 0.223046\n",
      "[296]\ttrain's binary_logloss: 0.222285\n",
      "[297]\ttrain's binary_logloss: 0.221907\n",
      "[298]\ttrain's binary_logloss: 0.221567\n",
      "[299]\ttrain's binary_logloss: 0.221273\n",
      "[300]\ttrain's binary_logloss: 0.220611\n",
      "[301]\ttrain's binary_logloss: 0.220213\n",
      "[302]\ttrain's binary_logloss: 0.21992\n",
      "[303]\ttrain's binary_logloss: 0.219641\n",
      "[304]\ttrain's binary_logloss: 0.219161\n",
      "[305]\ttrain's binary_logloss: 0.218723\n",
      "[306]\ttrain's binary_logloss: 0.218309\n",
      "[307]\ttrain's binary_logloss: 0.21755\n",
      "[308]\ttrain's binary_logloss: 0.217223\n",
      "[309]\ttrain's binary_logloss: 0.216722\n",
      "[310]\ttrain's binary_logloss: 0.216242\n",
      "[311]\ttrain's binary_logloss: 0.216004\n",
      "[312]\ttrain's binary_logloss: 0.215234\n",
      "[313]\ttrain's binary_logloss: 0.214731\n",
      "[314]\ttrain's binary_logloss: 0.214299\n",
      "[315]\ttrain's binary_logloss: 0.213988\n",
      "[316]\ttrain's binary_logloss: 0.213743\n",
      "[317]\ttrain's binary_logloss: 0.21342\n",
      "[318]\ttrain's binary_logloss: 0.212993\n",
      "[319]\ttrain's binary_logloss: 0.212576\n",
      "[320]\ttrain's binary_logloss: 0.21198\n",
      "[321]\ttrain's binary_logloss: 0.211424\n",
      "[322]\ttrain's binary_logloss: 0.21098\n",
      "[323]\ttrain's binary_logloss: 0.210717\n",
      "[324]\ttrain's binary_logloss: 0.210308\n",
      "[325]\ttrain's binary_logloss: 0.209841\n",
      "[326]\ttrain's binary_logloss: 0.208946\n",
      "[327]\ttrain's binary_logloss: 0.208284\n",
      "[328]\ttrain's binary_logloss: 0.207906\n",
      "[329]\ttrain's binary_logloss: 0.207541\n",
      "[330]\ttrain's binary_logloss: 0.207287\n",
      "[331]\ttrain's binary_logloss: 0.206782\n",
      "[332]\ttrain's binary_logloss: 0.206542\n",
      "[333]\ttrain's binary_logloss: 0.205731\n",
      "[334]\ttrain's binary_logloss: 0.20523\n",
      "[335]\ttrain's binary_logloss: 0.204782\n",
      "[336]\ttrain's binary_logloss: 0.204562\n",
      "[337]\ttrain's binary_logloss: 0.204267\n",
      "[338]\ttrain's binary_logloss: 0.204085\n",
      "[339]\ttrain's binary_logloss: 0.203701\n",
      "[340]\ttrain's binary_logloss: 0.203224\n",
      "[341]\ttrain's binary_logloss: 0.202829\n",
      "[342]\ttrain's binary_logloss: 0.202252\n",
      "[343]\ttrain's binary_logloss: 0.201751\n",
      "[344]\ttrain's binary_logloss: 0.201267\n",
      "[345]\ttrain's binary_logloss: 0.200805\n",
      "[346]\ttrain's binary_logloss: 0.200549\n",
      "[347]\ttrain's binary_logloss: 0.200051\n",
      "[348]\ttrain's binary_logloss: 0.199563\n",
      "[349]\ttrain's binary_logloss: 0.199131\n",
      "[350]\ttrain's binary_logloss: 0.198731\n",
      "[351]\ttrain's binary_logloss: 0.1983\n",
      "[352]\ttrain's binary_logloss: 0.197941\n",
      "[353]\ttrain's binary_logloss: 0.197673\n",
      "[354]\ttrain's binary_logloss: 0.197497\n",
      "[355]\ttrain's binary_logloss: 0.197346\n",
      "[356]\ttrain's binary_logloss: 0.196909\n",
      "[357]\ttrain's binary_logloss: 0.196737\n",
      "[358]\ttrain's binary_logloss: 0.196233\n",
      "[359]\ttrain's binary_logloss: 0.195819\n",
      "[360]\ttrain's binary_logloss: 0.195374\n",
      "[361]\ttrain's binary_logloss: 0.194856\n",
      "[362]\ttrain's binary_logloss: 0.194501\n",
      "[363]\ttrain's binary_logloss: 0.194192\n",
      "[364]\ttrain's binary_logloss: 0.193896\n",
      "[365]\ttrain's binary_logloss: 0.193524\n",
      "[366]\ttrain's binary_logloss: 0.193074\n",
      "[367]\ttrain's binary_logloss: 0.192726\n",
      "[368]\ttrain's binary_logloss: 0.192346\n",
      "[369]\ttrain's binary_logloss: 0.19207\n",
      "[370]\ttrain's binary_logloss: 0.191551\n",
      "[371]\ttrain's binary_logloss: 0.19121\n",
      "[372]\ttrain's binary_logloss: 0.190668\n",
      "[373]\ttrain's binary_logloss: 0.190357\n",
      "[374]\ttrain's binary_logloss: 0.189708\n",
      "[375]\ttrain's binary_logloss: 0.189166\n",
      "[376]\ttrain's binary_logloss: 0.188481\n",
      "[377]\ttrain's binary_logloss: 0.187923\n",
      "[378]\ttrain's binary_logloss: 0.187387\n",
      "[379]\ttrain's binary_logloss: 0.186829\n",
      "[380]\ttrain's binary_logloss: 0.186359\n",
      "[381]\ttrain's binary_logloss: 0.186049\n",
      "[382]\ttrain's binary_logloss: 0.185431\n",
      "[383]\ttrain's binary_logloss: 0.184966\n",
      "[384]\ttrain's binary_logloss: 0.184586\n",
      "[385]\ttrain's binary_logloss: 0.183982\n",
      "[386]\ttrain's binary_logloss: 0.183568\n",
      "[387]\ttrain's binary_logloss: 0.183413\n",
      "[388]\ttrain's binary_logloss: 0.182946\n",
      "[389]\ttrain's binary_logloss: 0.182525\n",
      "[390]\ttrain's binary_logloss: 0.181952\n",
      "[391]\ttrain's binary_logloss: 0.181528\n",
      "[392]\ttrain's binary_logloss: 0.18083\n",
      "[393]\ttrain's binary_logloss: 0.180543\n",
      "[394]\ttrain's binary_logloss: 0.180241\n",
      "[395]\ttrain's binary_logloss: 0.179704\n",
      "[396]\ttrain's binary_logloss: 0.179356\n",
      "[397]\ttrain's binary_logloss: 0.179073\n",
      "[398]\ttrain's binary_logloss: 0.178589\n",
      "[399]\ttrain's binary_logloss: 0.178339\n",
      "[400]\ttrain's binary_logloss: 0.17809\n",
      "[401]\ttrain's binary_logloss: 0.177719\n",
      "[402]\ttrain's binary_logloss: 0.177188\n",
      "[403]\ttrain's binary_logloss: 0.176908\n",
      "[404]\ttrain's binary_logloss: 0.176348\n",
      "[405]\ttrain's binary_logloss: 0.176101\n",
      "[406]\ttrain's binary_logloss: 0.175761\n",
      "[407]\ttrain's binary_logloss: 0.175526\n",
      "[408]\ttrain's binary_logloss: 0.175253\n",
      "[409]\ttrain's binary_logloss: 0.174833\n",
      "[410]\ttrain's binary_logloss: 0.174486\n",
      "[411]\ttrain's binary_logloss: 0.174289\n",
      "[412]\ttrain's binary_logloss: 0.173642\n",
      "[413]\ttrain's binary_logloss: 0.173361\n",
      "[414]\ttrain's binary_logloss: 0.172989\n",
      "[415]\ttrain's binary_logloss: 0.172507\n",
      "[416]\ttrain's binary_logloss: 0.17226\n",
      "[417]\ttrain's binary_logloss: 0.171865\n",
      "[418]\ttrain's binary_logloss: 0.171421\n",
      "[419]\ttrain's binary_logloss: 0.171136\n",
      "[420]\ttrain's binary_logloss: 0.170918\n",
      "[421]\ttrain's binary_logloss: 0.170276\n",
      "[422]\ttrain's binary_logloss: 0.169918\n",
      "[423]\ttrain's binary_logloss: 0.169643\n",
      "[424]\ttrain's binary_logloss: 0.169293\n",
      "[425]\ttrain's binary_logloss: 0.169112\n",
      "[426]\ttrain's binary_logloss: 0.16862\n",
      "[427]\ttrain's binary_logloss: 0.168273\n",
      "[428]\ttrain's binary_logloss: 0.167871\n",
      "[429]\ttrain's binary_logloss: 0.167623\n",
      "[430]\ttrain's binary_logloss: 0.167426\n",
      "[431]\ttrain's binary_logloss: 0.166944\n",
      "[432]\ttrain's binary_logloss: 0.166616\n",
      "[433]\ttrain's binary_logloss: 0.166257\n",
      "[434]\ttrain's binary_logloss: 0.166075\n",
      "[435]\ttrain's binary_logloss: 0.165558\n",
      "[436]\ttrain's binary_logloss: 0.165281\n",
      "[437]\ttrain's binary_logloss: 0.165056\n",
      "[438]\ttrain's binary_logloss: 0.164855\n",
      "[439]\ttrain's binary_logloss: 0.164418\n",
      "[440]\ttrain's binary_logloss: 0.163917\n",
      "[441]\ttrain's binary_logloss: 0.163484\n",
      "[442]\ttrain's binary_logloss: 0.163367\n",
      "[443]\ttrain's binary_logloss: 0.163146\n",
      "[444]\ttrain's binary_logloss: 0.162918\n",
      "[445]\ttrain's binary_logloss: 0.1626\n",
      "[446]\ttrain's binary_logloss: 0.162193\n",
      "[447]\ttrain's binary_logloss: 0.16195\n",
      "[448]\ttrain's binary_logloss: 0.161755\n",
      "[449]\ttrain's binary_logloss: 0.16139\n",
      "[450]\ttrain's binary_logloss: 0.16113\n",
      "[451]\ttrain's binary_logloss: 0.160798\n",
      "[452]\ttrain's binary_logloss: 0.160367\n",
      "[453]\ttrain's binary_logloss: 0.160173\n",
      "[454]\ttrain's binary_logloss: 0.160004\n",
      "[455]\ttrain's binary_logloss: 0.159851\n",
      "[456]\ttrain's binary_logloss: 0.15963\n",
      "[457]\ttrain's binary_logloss: 0.159342\n",
      "[458]\ttrain's binary_logloss: 0.158956\n",
      "[459]\ttrain's binary_logloss: 0.158747\n",
      "[460]\ttrain's binary_logloss: 0.158549\n",
      "[461]\ttrain's binary_logloss: 0.158198\n",
      "[462]\ttrain's binary_logloss: 0.157527\n",
      "[463]\ttrain's binary_logloss: 0.157263\n",
      "[464]\ttrain's binary_logloss: 0.157004\n",
      "[465]\ttrain's binary_logloss: 0.156493\n",
      "[466]\ttrain's binary_logloss: 0.156155\n",
      "[467]\ttrain's binary_logloss: 0.156\n",
      "[468]\ttrain's binary_logloss: 0.155591\n",
      "[469]\ttrain's binary_logloss: 0.154938\n",
      "[470]\ttrain's binary_logloss: 0.154755\n",
      "[471]\ttrain's binary_logloss: 0.154591\n",
      "[472]\ttrain's binary_logloss: 0.154373\n",
      "[473]\ttrain's binary_logloss: 0.154156\n",
      "[474]\ttrain's binary_logloss: 0.153797\n",
      "[475]\ttrain's binary_logloss: 0.153479\n",
      "[476]\ttrain's binary_logloss: 0.153004\n",
      "[477]\ttrain's binary_logloss: 0.152814\n",
      "[478]\ttrain's binary_logloss: 0.152484\n",
      "[479]\ttrain's binary_logloss: 0.152381\n",
      "[480]\ttrain's binary_logloss: 0.15209\n",
      "[481]\ttrain's binary_logloss: 0.151521\n",
      "[482]\ttrain's binary_logloss: 0.151195\n",
      "[483]\ttrain's binary_logloss: 0.150919\n",
      "[484]\ttrain's binary_logloss: 0.150498\n",
      "[485]\ttrain's binary_logloss: 0.150235\n",
      "[486]\ttrain's binary_logloss: 0.15008\n",
      "[487]\ttrain's binary_logloss: 0.149875\n",
      "[488]\ttrain's binary_logloss: 0.1497\n",
      "[489]\ttrain's binary_logloss: 0.149427\n",
      "[490]\ttrain's binary_logloss: 0.148995\n",
      "[491]\ttrain's binary_logloss: 0.148707\n",
      "[492]\ttrain's binary_logloss: 0.148535\n",
      "[493]\ttrain's binary_logloss: 0.148291\n",
      "[494]\ttrain's binary_logloss: 0.148023\n",
      "[495]\ttrain's binary_logloss: 0.1476\n",
      "[496]\ttrain's binary_logloss: 0.147413\n",
      "[497]\ttrain's binary_logloss: 0.147097\n",
      "[498]\ttrain's binary_logloss: 0.146752\n",
      "[499]\ttrain's binary_logloss: 0.146375\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "[0]\ttest-logloss:0.59573\n",
      "[1]\ttest-logloss:0.58371\n",
      "[2]\ttest-logloss:0.57642\n",
      "[3]\ttest-logloss:0.58736\n",
      "[4]\ttest-logloss:0.58414\n",
      "[5]\ttest-logloss:0.58967\n",
      "[6]\ttest-logloss:0.59291\n",
      "[7]\ttest-logloss:0.59738\n",
      "[8]\ttest-logloss:0.59849\n",
      "[9]\ttest-logloss:0.59946\n",
      "[10]\ttest-logloss:0.60594\n",
      "[11]\ttest-logloss:0.60589\n",
      "[12]\ttest-logloss:0.60974\n",
      "[13]\ttest-logloss:0.60995\n",
      "[14]\ttest-logloss:0.61244\n",
      "[15]\ttest-logloss:0.61994\n",
      "[16]\ttest-logloss:0.62884\n",
      "[17]\ttest-logloss:0.63393\n",
      "[18]\ttest-logloss:0.63189\n",
      "[19]\ttest-logloss:0.62428\n",
      "[20]\ttest-logloss:0.63861\n",
      "[21]\ttest-logloss:0.63952\n",
      "X_trainの形状： (646, 24)  y_trainの形状： (646,)  X_testの形状： (278, 24)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.662906\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.638297\n",
      "[3]\ttrain's binary_logloss: 0.617479\n",
      "[4]\ttrain's binary_logloss: 0.600501\n",
      "[5]\ttrain's binary_logloss: 0.585878\n",
      "[6]\ttrain's binary_logloss: 0.573603\n",
      "[7]\ttrain's binary_logloss: 0.562965\n",
      "[8]\ttrain's binary_logloss: 0.553485\n",
      "[9]\ttrain's binary_logloss: 0.545568\n",
      "[10]\ttrain's binary_logloss: 0.538341\n",
      "[11]\ttrain's binary_logloss: 0.53218\n",
      "[12]\ttrain's binary_logloss: 0.526888\n",
      "[13]\ttrain's binary_logloss: 0.521507\n",
      "[14]\ttrain's binary_logloss: 0.516283\n",
      "[15]\ttrain's binary_logloss: 0.511686\n",
      "[16]\ttrain's binary_logloss: 0.507458\n",
      "[17]\ttrain's binary_logloss: 0.502668\n",
      "[18]\ttrain's binary_logloss: 0.498687\n",
      "[19]\ttrain's binary_logloss: 0.494656\n",
      "[20]\ttrain's binary_logloss: 0.491561\n",
      "[21]\ttrain's binary_logloss: 0.488351\n",
      "[22]\ttrain's binary_logloss: 0.485573\n",
      "[23]\ttrain's binary_logloss: 0.482171\n",
      "[24]\ttrain's binary_logloss: 0.479149\n",
      "[25]\ttrain's binary_logloss: 0.476664\n",
      "[26]\ttrain's binary_logloss: 0.473929\n",
      "[27]\ttrain's binary_logloss: 0.471448\n",
      "[28]\ttrain's binary_logloss: 0.469294\n",
      "[29]\ttrain's binary_logloss: 0.466646\n",
      "[30]\ttrain's binary_logloss: 0.463765\n",
      "[31]\ttrain's binary_logloss: 0.461489\n",
      "[32]\ttrain's binary_logloss: 0.45924\n",
      "[33]\ttrain's binary_logloss: 0.456848\n",
      "[34]\ttrain's binary_logloss: 0.454888\n",
      "[35]\ttrain's binary_logloss: 0.452506\n",
      "[36]\ttrain's binary_logloss: 0.450764\n",
      "[37]\ttrain's binary_logloss: 0.448826\n",
      "[38]\ttrain's binary_logloss: 0.446645\n",
      "[39]\ttrain's binary_logloss: 0.444878\n",
      "[40]\ttrain's binary_logloss: 0.44312\n",
      "[41]\ttrain's binary_logloss: 0.441225\n",
      "[42]\ttrain's binary_logloss: 0.43862\n",
      "[43]\ttrain's binary_logloss: 0.43714\n",
      "[44]\ttrain's binary_logloss: 0.435454\n",
      "[45]\ttrain's binary_logloss: 0.433442\n",
      "[46]\ttrain's binary_logloss: 0.431905\n",
      "[47]\ttrain's binary_logloss: 0.430126\n",
      "[48]\ttrain's binary_logloss: 0.428234\n",
      "[49]\ttrain's binary_logloss: 0.42696\n",
      "[50]\ttrain's binary_logloss: 0.424765\n",
      "[51]\ttrain's binary_logloss: 0.423088\n",
      "[52]\ttrain's binary_logloss: 0.421902\n",
      "[53]\ttrain's binary_logloss: 0.420318\n",
      "[54]\ttrain's binary_logloss: 0.418909\n",
      "[55]\ttrain's binary_logloss: 0.417007\n",
      "[56]\ttrain's binary_logloss: 0.415208\n",
      "[57]\ttrain's binary_logloss: 0.413514\n",
      "[58]\ttrain's binary_logloss: 0.412293\n",
      "[59]\ttrain's binary_logloss: 0.411102\n",
      "[60]\ttrain's binary_logloss: 0.40967\n",
      "[61]\ttrain's binary_logloss: 0.407243\n",
      "[62]\ttrain's binary_logloss: 0.40599\n",
      "[63]\ttrain's binary_logloss: 0.404919\n",
      "[64]\ttrain's binary_logloss: 0.403409\n",
      "[65]\ttrain's binary_logloss: 0.402214\n",
      "[66]\ttrain's binary_logloss: 0.400646\n",
      "[67]\ttrain's binary_logloss: 0.398702\n",
      "[68]\ttrain's binary_logloss: 0.397395\n",
      "[69]\ttrain's binary_logloss: 0.395586\n",
      "[70]\ttrain's binary_logloss: 0.393765\n",
      "[71]\ttrain's binary_logloss: 0.392805\n",
      "[72]\ttrain's binary_logloss: 0.391712\n",
      "[73]\ttrain's binary_logloss: 0.390657\n",
      "[74]\ttrain's binary_logloss: 0.388989\n",
      "[75]\ttrain's binary_logloss: 0.38764\n",
      "[76]\ttrain's binary_logloss: 0.386751\n",
      "[77]\ttrain's binary_logloss: 0.384699\n",
      "[78]\ttrain's binary_logloss: 0.382528\n",
      "[79]\ttrain's binary_logloss: 0.381192\n",
      "[80]\ttrain's binary_logloss: 0.380259\n",
      "[81]\ttrain's binary_logloss: 0.378934\n",
      "[82]\ttrain's binary_logloss: 0.377976\n",
      "[83]\ttrain's binary_logloss: 0.376874\n",
      "[84]\ttrain's binary_logloss: 0.375969\n",
      "[85]\ttrain's binary_logloss: 0.374852\n",
      "[86]\ttrain's binary_logloss: 0.373135\n",
      "[87]\ttrain's binary_logloss: 0.371574\n",
      "[88]\ttrain's binary_logloss: 0.370593\n",
      "[89]\ttrain's binary_logloss: 0.369757\n",
      "[90]\ttrain's binary_logloss: 0.368328\n",
      "[91]\ttrain's binary_logloss: 0.367325\n",
      "[92]\ttrain's binary_logloss: 0.36639\n",
      "[93]\ttrain's binary_logloss: 0.365162\n",
      "[94]\ttrain's binary_logloss: 0.364408\n",
      "[95]\ttrain's binary_logloss: 0.362858\n",
      "[96]\ttrain's binary_logloss: 0.360926\n",
      "[97]\ttrain's binary_logloss: 0.35941\n",
      "[98]\ttrain's binary_logloss: 0.358207\n",
      "[99]\ttrain's binary_logloss: 0.357537\n",
      "[100]\ttrain's binary_logloss: 0.356465\n",
      "[101]\ttrain's binary_logloss: 0.355643\n",
      "[102]\ttrain's binary_logloss: 0.354476\n",
      "[103]\ttrain's binary_logloss: 0.353127\n",
      "[104]\ttrain's binary_logloss: 0.352091\n",
      "[105]\ttrain's binary_logloss: 0.350762\n",
      "[106]\ttrain's binary_logloss: 0.349704\n",
      "[107]\ttrain's binary_logloss: 0.348859\n",
      "[108]\ttrain's binary_logloss: 0.347836\n",
      "[109]\ttrain's binary_logloss: 0.346703\n",
      "[110]\ttrain's binary_logloss: 0.345726\n",
      "[111]\ttrain's binary_logloss: 0.344929\n",
      "[112]\ttrain's binary_logloss: 0.344232\n",
      "[113]\ttrain's binary_logloss: 0.343464\n",
      "[114]\ttrain's binary_logloss: 0.342828\n",
      "[115]\ttrain's binary_logloss: 0.341282\n",
      "[116]\ttrain's binary_logloss: 0.339423\n",
      "[117]\ttrain's binary_logloss: 0.338747\n",
      "[118]\ttrain's binary_logloss: 0.337414\n",
      "[119]\ttrain's binary_logloss: 0.336814\n",
      "[120]\ttrain's binary_logloss: 0.335958\n",
      "[121]\ttrain's binary_logloss: 0.335146\n",
      "[122]\ttrain's binary_logloss: 0.333571\n",
      "[123]\ttrain's binary_logloss: 0.332564\n",
      "[124]\ttrain's binary_logloss: 0.331984\n",
      "[125]\ttrain's binary_logloss: 0.331224\n",
      "[126]\ttrain's binary_logloss: 0.33044\n",
      "[127]\ttrain's binary_logloss: 0.32974\n",
      "[128]\ttrain's binary_logloss: 0.328766\n",
      "[129]\ttrain's binary_logloss: 0.327988\n",
      "[130]\ttrain's binary_logloss: 0.327226\n",
      "[131]\ttrain's binary_logloss: 0.326293\n",
      "[132]\ttrain's binary_logloss: 0.325219\n",
      "[133]\ttrain's binary_logloss: 0.323711\n",
      "[134]\ttrain's binary_logloss: 0.323081\n",
      "[135]\ttrain's binary_logloss: 0.321718\n",
      "[136]\ttrain's binary_logloss: 0.321142\n",
      "[137]\ttrain's binary_logloss: 0.320328\n",
      "[138]\ttrain's binary_logloss: 0.319378\n",
      "[139]\ttrain's binary_logloss: 0.318822\n",
      "[140]\ttrain's binary_logloss: 0.317859\n",
      "[141]\ttrain's binary_logloss: 0.31729\n",
      "[142]\ttrain's binary_logloss: 0.316314\n",
      "[143]\ttrain's binary_logloss: 0.315594\n",
      "[144]\ttrain's binary_logloss: 0.314675\n",
      "[145]\ttrain's binary_logloss: 0.313575\n",
      "[146]\ttrain's binary_logloss: 0.312904\n",
      "[147]\ttrain's binary_logloss: 0.31207\n",
      "[148]\ttrain's binary_logloss: 0.311461\n",
      "[149]\ttrain's binary_logloss: 0.310867\n",
      "[150]\ttrain's binary_logloss: 0.309872\n",
      "[151]\ttrain's binary_logloss: 0.309071\n",
      "[152]\ttrain's binary_logloss: 0.308102\n",
      "[153]\ttrain's binary_logloss: 0.307219\n",
      "[154]\ttrain's binary_logloss: 0.306427\n",
      "[155]\ttrain's binary_logloss: 0.305771\n",
      "[156]\ttrain's binary_logloss: 0.304692\n",
      "[157]\ttrain's binary_logloss: 0.303829\n",
      "[158]\ttrain's binary_logloss: 0.302958\n",
      "[159]\ttrain's binary_logloss: 0.302515\n",
      "[160]\ttrain's binary_logloss: 0.301781\n",
      "[161]\ttrain's binary_logloss: 0.301218\n",
      "[162]\ttrain's binary_logloss: 0.30076\n",
      "[163]\ttrain's binary_logloss: 0.299788\n",
      "[164]\ttrain's binary_logloss: 0.299011\n",
      "[165]\ttrain's binary_logloss: 0.298209\n",
      "[166]\ttrain's binary_logloss: 0.297688\n",
      "[167]\ttrain's binary_logloss: 0.296928\n",
      "[168]\ttrain's binary_logloss: 0.296486\n",
      "[169]\ttrain's binary_logloss: 0.295689\n",
      "[170]\ttrain's binary_logloss: 0.295135\n",
      "[171]\ttrain's binary_logloss: 0.293992\n",
      "[172]\ttrain's binary_logloss: 0.293065\n",
      "[173]\ttrain's binary_logloss: 0.292238\n",
      "[174]\ttrain's binary_logloss: 0.291605\n",
      "[175]\ttrain's binary_logloss: 0.290909\n",
      "[176]\ttrain's binary_logloss: 0.290163\n",
      "[177]\ttrain's binary_logloss: 0.289679\n",
      "[178]\ttrain's binary_logloss: 0.288876\n",
      "[179]\ttrain's binary_logloss: 0.287826\n",
      "[180]\ttrain's binary_logloss: 0.286768\n",
      "[181]\ttrain's binary_logloss: 0.2861\n",
      "[182]\ttrain's binary_logloss: 0.285568\n",
      "[183]\ttrain's binary_logloss: 0.285031\n",
      "[184]\ttrain's binary_logloss: 0.284179\n",
      "[185]\ttrain's binary_logloss: 0.28348\n",
      "[186]\ttrain's binary_logloss: 0.282782\n",
      "[187]\ttrain's binary_logloss: 0.282188\n",
      "[188]\ttrain's binary_logloss: 0.281734\n",
      "[189]\ttrain's binary_logloss: 0.28121\n",
      "[190]\ttrain's binary_logloss: 0.280441\n",
      "[191]\ttrain's binary_logloss: 0.279909\n",
      "[192]\ttrain's binary_logloss: 0.27899\n",
      "[193]\ttrain's binary_logloss: 0.278616\n",
      "[194]\ttrain's binary_logloss: 0.278\n",
      "[195]\ttrain's binary_logloss: 0.277302\n",
      "[196]\ttrain's binary_logloss: 0.276416\n",
      "[197]\ttrain's binary_logloss: 0.275802\n",
      "[198]\ttrain's binary_logloss: 0.275207\n",
      "[199]\ttrain's binary_logloss: 0.274815\n",
      "[200]\ttrain's binary_logloss: 0.274167\n",
      "[201]\ttrain's binary_logloss: 0.273716\n",
      "[202]\ttrain's binary_logloss: 0.272815\n",
      "[203]\ttrain's binary_logloss: 0.272177\n",
      "[204]\ttrain's binary_logloss: 0.271436\n",
      "[205]\ttrain's binary_logloss: 0.270776\n",
      "[206]\ttrain's binary_logloss: 0.270229\n",
      "[207]\ttrain's binary_logloss: 0.269779\n",
      "[208]\ttrain's binary_logloss: 0.269004\n",
      "[209]\ttrain's binary_logloss: 0.267872\n",
      "[210]\ttrain's binary_logloss: 0.267196\n",
      "[211]\ttrain's binary_logloss: 0.266571\n",
      "[212]\ttrain's binary_logloss: 0.26598\n",
      "[213]\ttrain's binary_logloss: 0.265654\n",
      "[214]\ttrain's binary_logloss: 0.264831\n",
      "[215]\ttrain's binary_logloss: 0.263983\n",
      "[216]\ttrain's binary_logloss: 0.262875\n",
      "[217]\ttrain's binary_logloss: 0.26229\n",
      "[218]\ttrain's binary_logloss: 0.26172\n",
      "[219]\ttrain's binary_logloss: 0.260831\n",
      "[220]\ttrain's binary_logloss: 0.260221\n",
      "[221]\ttrain's binary_logloss: 0.259489\n",
      "[222]\ttrain's binary_logloss: 0.258778\n",
      "[223]\ttrain's binary_logloss: 0.25811\n",
      "[224]\ttrain's binary_logloss: 0.257694\n",
      "[225]\ttrain's binary_logloss: 0.257083\n",
      "[226]\ttrain's binary_logloss: 0.256652\n",
      "[227]\ttrain's binary_logloss: 0.255637\n",
      "[228]\ttrain's binary_logloss: 0.255275\n",
      "[229]\ttrain's binary_logloss: 0.25436\n",
      "[230]\ttrain's binary_logloss: 0.253792\n",
      "[231]\ttrain's binary_logloss: 0.253338\n",
      "[232]\ttrain's binary_logloss: 0.252984\n",
      "[233]\ttrain's binary_logloss: 0.252331\n",
      "[234]\ttrain's binary_logloss: 0.251858\n",
      "[235]\ttrain's binary_logloss: 0.251312\n",
      "[236]\ttrain's binary_logloss: 0.250489\n",
      "[237]\ttrain's binary_logloss: 0.250099\n",
      "[238]\ttrain's binary_logloss: 0.249802\n",
      "[239]\ttrain's binary_logloss: 0.249211\n",
      "[240]\ttrain's binary_logloss: 0.24873\n",
      "[241]\ttrain's binary_logloss: 0.248368\n",
      "[242]\ttrain's binary_logloss: 0.247962\n",
      "[243]\ttrain's binary_logloss: 0.247223\n",
      "[244]\ttrain's binary_logloss: 0.246523\n",
      "[245]\ttrain's binary_logloss: 0.245704\n",
      "[246]\ttrain's binary_logloss: 0.245339\n",
      "[247]\ttrain's binary_logloss: 0.244785\n",
      "[248]\ttrain's binary_logloss: 0.244489\n",
      "[249]\ttrain's binary_logloss: 0.244123\n",
      "[250]\ttrain's binary_logloss: 0.243491\n",
      "[251]\ttrain's binary_logloss: 0.242877\n",
      "[252]\ttrain's binary_logloss: 0.24253\n",
      "[253]\ttrain's binary_logloss: 0.242084\n",
      "[254]\ttrain's binary_logloss: 0.241631\n",
      "[255]\ttrain's binary_logloss: 0.241128\n",
      "[256]\ttrain's binary_logloss: 0.240535\n",
      "[257]\ttrain's binary_logloss: 0.240056\n",
      "[258]\ttrain's binary_logloss: 0.23977\n",
      "[259]\ttrain's binary_logloss: 0.239386\n",
      "[260]\ttrain's binary_logloss: 0.238696\n",
      "[261]\ttrain's binary_logloss: 0.238307\n",
      "[262]\ttrain's binary_logloss: 0.237724\n",
      "[263]\ttrain's binary_logloss: 0.23714\n",
      "[264]\ttrain's binary_logloss: 0.236582\n",
      "[265]\ttrain's binary_logloss: 0.236232\n",
      "[266]\ttrain's binary_logloss: 0.235868\n",
      "[267]\ttrain's binary_logloss: 0.235129\n",
      "[268]\ttrain's binary_logloss: 0.234585\n",
      "[269]\ttrain's binary_logloss: 0.23423\n",
      "[270]\ttrain's binary_logloss: 0.233736\n",
      "[271]\ttrain's binary_logloss: 0.233189\n",
      "[272]\ttrain's binary_logloss: 0.232941\n",
      "[273]\ttrain's binary_logloss: 0.23242\n",
      "[274]\ttrain's binary_logloss: 0.231679\n",
      "[275]\ttrain's binary_logloss: 0.231218\n",
      "[276]\ttrain's binary_logloss: 0.23099\n",
      "[277]\ttrain's binary_logloss: 0.230563\n",
      "[278]\ttrain's binary_logloss: 0.229942\n",
      "[279]\ttrain's binary_logloss: 0.229532\n",
      "[280]\ttrain's binary_logloss: 0.22913\n",
      "[281]\ttrain's binary_logloss: 0.228747\n",
      "[282]\ttrain's binary_logloss: 0.227907\n",
      "[283]\ttrain's binary_logloss: 0.227236\n",
      "[284]\ttrain's binary_logloss: 0.226918\n",
      "[285]\ttrain's binary_logloss: 0.226609\n",
      "[286]\ttrain's binary_logloss: 0.226241\n",
      "[287]\ttrain's binary_logloss: 0.2259\n",
      "[288]\ttrain's binary_logloss: 0.225565\n",
      "[289]\ttrain's binary_logloss: 0.225198\n",
      "[290]\ttrain's binary_logloss: 0.224945\n",
      "[291]\ttrain's binary_logloss: 0.224465\n",
      "[292]\ttrain's binary_logloss: 0.224152\n",
      "[293]\ttrain's binary_logloss: 0.223747\n",
      "[294]\ttrain's binary_logloss: 0.223332\n",
      "[295]\ttrain's binary_logloss: 0.223046\n",
      "[296]\ttrain's binary_logloss: 0.222285\n",
      "[297]\ttrain's binary_logloss: 0.221907\n",
      "[298]\ttrain's binary_logloss: 0.221567\n",
      "[299]\ttrain's binary_logloss: 0.221273\n",
      "[300]\ttrain's binary_logloss: 0.220611\n",
      "[301]\ttrain's binary_logloss: 0.220213\n",
      "[302]\ttrain's binary_logloss: 0.21992\n",
      "[303]\ttrain's binary_logloss: 0.219641\n",
      "[304]\ttrain's binary_logloss: 0.219161\n",
      "[305]\ttrain's binary_logloss: 0.218723\n",
      "[306]\ttrain's binary_logloss: 0.218309\n",
      "[307]\ttrain's binary_logloss: 0.21755\n",
      "[308]\ttrain's binary_logloss: 0.217223\n",
      "[309]\ttrain's binary_logloss: 0.216722\n",
      "[310]\ttrain's binary_logloss: 0.216242\n",
      "[311]\ttrain's binary_logloss: 0.216004\n",
      "[312]\ttrain's binary_logloss: 0.215234\n",
      "[313]\ttrain's binary_logloss: 0.214731\n",
      "[314]\ttrain's binary_logloss: 0.214299\n",
      "[315]\ttrain's binary_logloss: 0.213988\n",
      "[316]\ttrain's binary_logloss: 0.213743\n",
      "[317]\ttrain's binary_logloss: 0.21342\n",
      "[318]\ttrain's binary_logloss: 0.212993\n",
      "[319]\ttrain's binary_logloss: 0.212576\n",
      "[320]\ttrain's binary_logloss: 0.21198\n",
      "[321]\ttrain's binary_logloss: 0.211424\n",
      "[322]\ttrain's binary_logloss: 0.21098\n",
      "[323]\ttrain's binary_logloss: 0.210717\n",
      "[324]\ttrain's binary_logloss: 0.210308\n",
      "[325]\ttrain's binary_logloss: 0.209841\n",
      "[326]\ttrain's binary_logloss: 0.208946\n",
      "[327]\ttrain's binary_logloss: 0.208284\n",
      "[328]\ttrain's binary_logloss: 0.207906\n",
      "[329]\ttrain's binary_logloss: 0.207541\n",
      "[330]\ttrain's binary_logloss: 0.207287\n",
      "[331]\ttrain's binary_logloss: 0.206782\n",
      "[332]\ttrain's binary_logloss: 0.206542\n",
      "[333]\ttrain's binary_logloss: 0.205731\n",
      "[334]\ttrain's binary_logloss: 0.20523\n",
      "[335]\ttrain's binary_logloss: 0.204782\n",
      "[336]\ttrain's binary_logloss: 0.204562\n",
      "[337]\ttrain's binary_logloss: 0.204267\n",
      "[338]\ttrain's binary_logloss: 0.204085\n",
      "[339]\ttrain's binary_logloss: 0.203701\n",
      "[340]\ttrain's binary_logloss: 0.203224\n",
      "[341]\ttrain's binary_logloss: 0.202829\n",
      "[342]\ttrain's binary_logloss: 0.202252\n",
      "[343]\ttrain's binary_logloss: 0.201751\n",
      "[344]\ttrain's binary_logloss: 0.201267\n",
      "[345]\ttrain's binary_logloss: 0.200805\n",
      "[346]\ttrain's binary_logloss: 0.200549\n",
      "[347]\ttrain's binary_logloss: 0.200051\n",
      "[348]\ttrain's binary_logloss: 0.199563\n",
      "[349]\ttrain's binary_logloss: 0.199131\n",
      "[350]\ttrain's binary_logloss: 0.198731\n",
      "[351]\ttrain's binary_logloss: 0.1983\n",
      "[352]\ttrain's binary_logloss: 0.197941\n",
      "[353]\ttrain's binary_logloss: 0.197673\n",
      "[354]\ttrain's binary_logloss: 0.197497\n",
      "[355]\ttrain's binary_logloss: 0.197346\n",
      "[356]\ttrain's binary_logloss: 0.196909\n",
      "[357]\ttrain's binary_logloss: 0.196737\n",
      "[358]\ttrain's binary_logloss: 0.196233\n",
      "[359]\ttrain's binary_logloss: 0.195819\n",
      "[360]\ttrain's binary_logloss: 0.195374\n",
      "[361]\ttrain's binary_logloss: 0.194856\n",
      "[362]\ttrain's binary_logloss: 0.194501\n",
      "[363]\ttrain's binary_logloss: 0.194192\n",
      "[364]\ttrain's binary_logloss: 0.193896\n",
      "[365]\ttrain's binary_logloss: 0.193524\n",
      "[366]\ttrain's binary_logloss: 0.193074\n",
      "[367]\ttrain's binary_logloss: 0.192726\n",
      "[368]\ttrain's binary_logloss: 0.192346\n",
      "[369]\ttrain's binary_logloss: 0.19207\n",
      "[370]\ttrain's binary_logloss: 0.191551\n",
      "[371]\ttrain's binary_logloss: 0.19121\n",
      "[372]\ttrain's binary_logloss: 0.190668\n",
      "[373]\ttrain's binary_logloss: 0.190357\n",
      "[374]\ttrain's binary_logloss: 0.189708\n",
      "[375]\ttrain's binary_logloss: 0.189166\n",
      "[376]\ttrain's binary_logloss: 0.188481\n",
      "[377]\ttrain's binary_logloss: 0.187923\n",
      "[378]\ttrain's binary_logloss: 0.187387\n",
      "[379]\ttrain's binary_logloss: 0.186829\n",
      "[380]\ttrain's binary_logloss: 0.186359\n",
      "[381]\ttrain's binary_logloss: 0.186049\n",
      "[382]\ttrain's binary_logloss: 0.185431\n",
      "[383]\ttrain's binary_logloss: 0.184966\n",
      "[384]\ttrain's binary_logloss: 0.184586\n",
      "[385]\ttrain's binary_logloss: 0.183982\n",
      "[386]\ttrain's binary_logloss: 0.183568\n",
      "[387]\ttrain's binary_logloss: 0.183413\n",
      "[388]\ttrain's binary_logloss: 0.182946\n",
      "[389]\ttrain's binary_logloss: 0.182525\n",
      "[390]\ttrain's binary_logloss: 0.181952\n",
      "[391]\ttrain's binary_logloss: 0.181528\n",
      "[392]\ttrain's binary_logloss: 0.18083\n",
      "[393]\ttrain's binary_logloss: 0.180543\n",
      "[394]\ttrain's binary_logloss: 0.180241\n",
      "[395]\ttrain's binary_logloss: 0.179704\n",
      "[396]\ttrain's binary_logloss: 0.179356\n",
      "[397]\ttrain's binary_logloss: 0.179073\n",
      "[398]\ttrain's binary_logloss: 0.178589\n",
      "[399]\ttrain's binary_logloss: 0.178339\n",
      "[400]\ttrain's binary_logloss: 0.17809\n",
      "[401]\ttrain's binary_logloss: 0.177719\n",
      "[402]\ttrain's binary_logloss: 0.177188\n",
      "[403]\ttrain's binary_logloss: 0.176908\n",
      "[404]\ttrain's binary_logloss: 0.176348\n",
      "[405]\ttrain's binary_logloss: 0.176101\n",
      "[406]\ttrain's binary_logloss: 0.175761\n",
      "[407]\ttrain's binary_logloss: 0.175526\n",
      "[408]\ttrain's binary_logloss: 0.175253\n",
      "[409]\ttrain's binary_logloss: 0.174833\n",
      "[410]\ttrain's binary_logloss: 0.174486\n",
      "[411]\ttrain's binary_logloss: 0.174289\n",
      "[412]\ttrain's binary_logloss: 0.173642\n",
      "[413]\ttrain's binary_logloss: 0.173361\n",
      "[414]\ttrain's binary_logloss: 0.172989\n",
      "[415]\ttrain's binary_logloss: 0.172507\n",
      "[416]\ttrain's binary_logloss: 0.17226\n",
      "[417]\ttrain's binary_logloss: 0.171865\n",
      "[418]\ttrain's binary_logloss: 0.171421\n",
      "[419]\ttrain's binary_logloss: 0.171136\n",
      "[420]\ttrain's binary_logloss: 0.170918\n",
      "[421]\ttrain's binary_logloss: 0.170276\n",
      "[422]\ttrain's binary_logloss: 0.169918\n",
      "[423]\ttrain's binary_logloss: 0.169643\n",
      "[424]\ttrain's binary_logloss: 0.169293\n",
      "[425]\ttrain's binary_logloss: 0.169112\n",
      "[426]\ttrain's binary_logloss: 0.16862\n",
      "[427]\ttrain's binary_logloss: 0.168273\n",
      "[428]\ttrain's binary_logloss: 0.167871\n",
      "[429]\ttrain's binary_logloss: 0.167623\n",
      "[430]\ttrain's binary_logloss: 0.167426\n",
      "[431]\ttrain's binary_logloss: 0.166944\n",
      "[432]\ttrain's binary_logloss: 0.166616\n",
      "[433]\ttrain's binary_logloss: 0.166257\n",
      "[434]\ttrain's binary_logloss: 0.166075\n",
      "[435]\ttrain's binary_logloss: 0.165558\n",
      "[436]\ttrain's binary_logloss: 0.165281\n",
      "[437]\ttrain's binary_logloss: 0.165056\n",
      "[438]\ttrain's binary_logloss: 0.164855\n",
      "[439]\ttrain's binary_logloss: 0.164418\n",
      "[440]\ttrain's binary_logloss: 0.163917\n",
      "[441]\ttrain's binary_logloss: 0.163484\n",
      "[442]\ttrain's binary_logloss: 0.163367\n",
      "[443]\ttrain's binary_logloss: 0.163146\n",
      "[444]\ttrain's binary_logloss: 0.162918\n",
      "[445]\ttrain's binary_logloss: 0.1626\n",
      "[446]\ttrain's binary_logloss: 0.162193\n",
      "[447]\ttrain's binary_logloss: 0.16195\n",
      "[448]\ttrain's binary_logloss: 0.161755\n",
      "[449]\ttrain's binary_logloss: 0.16139\n",
      "[450]\ttrain's binary_logloss: 0.16113\n",
      "[451]\ttrain's binary_logloss: 0.160798\n",
      "[452]\ttrain's binary_logloss: 0.160367\n",
      "[453]\ttrain's binary_logloss: 0.160173\n",
      "[454]\ttrain's binary_logloss: 0.160004\n",
      "[455]\ttrain's binary_logloss: 0.159851\n",
      "[456]\ttrain's binary_logloss: 0.15963\n",
      "[457]\ttrain's binary_logloss: 0.159342\n",
      "[458]\ttrain's binary_logloss: 0.158956\n",
      "[459]\ttrain's binary_logloss: 0.158747\n",
      "[460]\ttrain's binary_logloss: 0.158549\n",
      "[461]\ttrain's binary_logloss: 0.158198\n",
      "[462]\ttrain's binary_logloss: 0.157527\n",
      "[463]\ttrain's binary_logloss: 0.157263\n",
      "[464]\ttrain's binary_logloss: 0.157004\n",
      "[465]\ttrain's binary_logloss: 0.156493\n",
      "[466]\ttrain's binary_logloss: 0.156155\n",
      "[467]\ttrain's binary_logloss: 0.156\n",
      "[468]\ttrain's binary_logloss: 0.155591\n",
      "[469]\ttrain's binary_logloss: 0.154938\n",
      "[470]\ttrain's binary_logloss: 0.154755\n",
      "[471]\ttrain's binary_logloss: 0.154591\n",
      "[472]\ttrain's binary_logloss: 0.154373\n",
      "[473]\ttrain's binary_logloss: 0.154156\n",
      "[474]\ttrain's binary_logloss: 0.153797\n",
      "[475]\ttrain's binary_logloss: 0.153479\n",
      "[476]\ttrain's binary_logloss: 0.153004\n",
      "[477]\ttrain's binary_logloss: 0.152814\n",
      "[478]\ttrain's binary_logloss: 0.152484\n",
      "[479]\ttrain's binary_logloss: 0.152381\n",
      "[480]\ttrain's binary_logloss: 0.15209\n",
      "[481]\ttrain's binary_logloss: 0.151521\n",
      "[482]\ttrain's binary_logloss: 0.151195\n",
      "[483]\ttrain's binary_logloss: 0.150919\n",
      "[484]\ttrain's binary_logloss: 0.150498\n",
      "[485]\ttrain's binary_logloss: 0.150235\n",
      "[486]\ttrain's binary_logloss: 0.15008\n",
      "[487]\ttrain's binary_logloss: 0.149875\n",
      "[488]\ttrain's binary_logloss: 0.1497\n",
      "[489]\ttrain's binary_logloss: 0.149427\n",
      "[490]\ttrain's binary_logloss: 0.148995\n",
      "[491]\ttrain's binary_logloss: 0.148707\n",
      "[492]\ttrain's binary_logloss: 0.148535\n",
      "[493]\ttrain's binary_logloss: 0.148291\n",
      "[494]\ttrain's binary_logloss: 0.148023\n",
      "[495]\ttrain's binary_logloss: 0.1476\n",
      "[496]\ttrain's binary_logloss: 0.147413\n",
      "[497]\ttrain's binary_logloss: 0.147097\n",
      "[498]\ttrain's binary_logloss: 0.146752\n",
      "[499]\ttrain's binary_logloss: 0.146375\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "[0]\ttest-logloss:0.59573\n",
      "[1]\ttest-logloss:0.58371\n",
      "[2]\ttest-logloss:0.57642\n",
      "[3]\ttest-logloss:0.58736\n",
      "[4]\ttest-logloss:0.58414\n",
      "[5]\ttest-logloss:0.58967\n",
      "[6]\ttest-logloss:0.59291\n",
      "[7]\ttest-logloss:0.59738\n",
      "[8]\ttest-logloss:0.59849\n",
      "[9]\ttest-logloss:0.59946\n",
      "[10]\ttest-logloss:0.60594\n",
      "[11]\ttest-logloss:0.60589\n",
      "[12]\ttest-logloss:0.60974\n",
      "[13]\ttest-logloss:0.60995\n",
      "[14]\ttest-logloss:0.61244\n",
      "[15]\ttest-logloss:0.61994\n",
      "[16]\ttest-logloss:0.62884\n",
      "[17]\ttest-logloss:0.63393\n",
      "[18]\ttest-logloss:0.63189\n",
      "[19]\ttest-logloss:0.62428\n",
      "[20]\ttest-logloss:0.63861\n",
      "[21]\ttest-logloss:0.63952\n",
      "X_trainの形状： (646, 24)  y_trainの形状： (646,)  X_testの形状： (278, 24)  y_testの形状： (278,)\n",
      "[1]\ttrain's binary_logloss: 0.662906\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttrain's binary_logloss: 0.638297\n",
      "[3]\ttrain's binary_logloss: 0.617479\n",
      "[4]\ttrain's binary_logloss: 0.600501\n",
      "[5]\ttrain's binary_logloss: 0.585878\n",
      "[6]\ttrain's binary_logloss: 0.573603\n",
      "[7]\ttrain's binary_logloss: 0.562965\n",
      "[8]\ttrain's binary_logloss: 0.553485\n",
      "[9]\ttrain's binary_logloss: 0.545568\n",
      "[10]\ttrain's binary_logloss: 0.538341\n",
      "[11]\ttrain's binary_logloss: 0.53218\n",
      "[12]\ttrain's binary_logloss: 0.526888\n",
      "[13]\ttrain's binary_logloss: 0.521507\n",
      "[14]\ttrain's binary_logloss: 0.516283\n",
      "[15]\ttrain's binary_logloss: 0.511686\n",
      "[16]\ttrain's binary_logloss: 0.507458\n",
      "[17]\ttrain's binary_logloss: 0.502668\n",
      "[18]\ttrain's binary_logloss: 0.498687\n",
      "[19]\ttrain's binary_logloss: 0.494656\n",
      "[20]\ttrain's binary_logloss: 0.491561\n",
      "[21]\ttrain's binary_logloss: 0.488351\n",
      "[22]\ttrain's binary_logloss: 0.485573\n",
      "[23]\ttrain's binary_logloss: 0.482171\n",
      "[24]\ttrain's binary_logloss: 0.479149\n",
      "[25]\ttrain's binary_logloss: 0.476664\n",
      "[26]\ttrain's binary_logloss: 0.473929\n",
      "[27]\ttrain's binary_logloss: 0.471448\n",
      "[28]\ttrain's binary_logloss: 0.469294\n",
      "[29]\ttrain's binary_logloss: 0.466646\n",
      "[30]\ttrain's binary_logloss: 0.463765\n",
      "[31]\ttrain's binary_logloss: 0.461489\n",
      "[32]\ttrain's binary_logloss: 0.45924\n",
      "[33]\ttrain's binary_logloss: 0.456848\n",
      "[34]\ttrain's binary_logloss: 0.454888\n",
      "[35]\ttrain's binary_logloss: 0.452506\n",
      "[36]\ttrain's binary_logloss: 0.450764\n",
      "[37]\ttrain's binary_logloss: 0.448826\n",
      "[38]\ttrain's binary_logloss: 0.446645\n",
      "[39]\ttrain's binary_logloss: 0.444878\n",
      "[40]\ttrain's binary_logloss: 0.44312\n",
      "[41]\ttrain's binary_logloss: 0.441225\n",
      "[42]\ttrain's binary_logloss: 0.43862\n",
      "[43]\ttrain's binary_logloss: 0.43714\n",
      "[44]\ttrain's binary_logloss: 0.435454\n",
      "[45]\ttrain's binary_logloss: 0.433442\n",
      "[46]\ttrain's binary_logloss: 0.431905\n",
      "[47]\ttrain's binary_logloss: 0.430126\n",
      "[48]\ttrain's binary_logloss: 0.428234\n",
      "[49]\ttrain's binary_logloss: 0.42696\n",
      "[50]\ttrain's binary_logloss: 0.424765\n",
      "[51]\ttrain's binary_logloss: 0.423088\n",
      "[52]\ttrain's binary_logloss: 0.421902\n",
      "[53]\ttrain's binary_logloss: 0.420318\n",
      "[54]\ttrain's binary_logloss: 0.418909\n",
      "[55]\ttrain's binary_logloss: 0.417007\n",
      "[56]\ttrain's binary_logloss: 0.415208\n",
      "[57]\ttrain's binary_logloss: 0.413514\n",
      "[58]\ttrain's binary_logloss: 0.412293\n",
      "[59]\ttrain's binary_logloss: 0.411102\n",
      "[60]\ttrain's binary_logloss: 0.40967\n",
      "[61]\ttrain's binary_logloss: 0.407243\n",
      "[62]\ttrain's binary_logloss: 0.40599\n",
      "[63]\ttrain's binary_logloss: 0.404919\n",
      "[64]\ttrain's binary_logloss: 0.403409\n",
      "[65]\ttrain's binary_logloss: 0.402214\n",
      "[66]\ttrain's binary_logloss: 0.400646\n",
      "[67]\ttrain's binary_logloss: 0.398702\n",
      "[68]\ttrain's binary_logloss: 0.397395\n",
      "[69]\ttrain's binary_logloss: 0.395586\n",
      "[70]\ttrain's binary_logloss: 0.393765\n",
      "[71]\ttrain's binary_logloss: 0.392805\n",
      "[72]\ttrain's binary_logloss: 0.391712\n",
      "[73]\ttrain's binary_logloss: 0.390657\n",
      "[74]\ttrain's binary_logloss: 0.388989\n",
      "[75]\ttrain's binary_logloss: 0.38764\n",
      "[76]\ttrain's binary_logloss: 0.386751\n",
      "[77]\ttrain's binary_logloss: 0.384699\n",
      "[78]\ttrain's binary_logloss: 0.382528\n",
      "[79]\ttrain's binary_logloss: 0.381192\n",
      "[80]\ttrain's binary_logloss: 0.380259\n",
      "[81]\ttrain's binary_logloss: 0.378934\n",
      "[82]\ttrain's binary_logloss: 0.377976\n",
      "[83]\ttrain's binary_logloss: 0.376874\n",
      "[84]\ttrain's binary_logloss: 0.375969\n",
      "[85]\ttrain's binary_logloss: 0.374852\n",
      "[86]\ttrain's binary_logloss: 0.373135\n",
      "[87]\ttrain's binary_logloss: 0.371574\n",
      "[88]\ttrain's binary_logloss: 0.370593\n",
      "[89]\ttrain's binary_logloss: 0.369757\n",
      "[90]\ttrain's binary_logloss: 0.368328\n",
      "[91]\ttrain's binary_logloss: 0.367325\n",
      "[92]\ttrain's binary_logloss: 0.36639\n",
      "[93]\ttrain's binary_logloss: 0.365162\n",
      "[94]\ttrain's binary_logloss: 0.364408\n",
      "[95]\ttrain's binary_logloss: 0.362858\n",
      "[96]\ttrain's binary_logloss: 0.360926\n",
      "[97]\ttrain's binary_logloss: 0.35941\n",
      "[98]\ttrain's binary_logloss: 0.358207\n",
      "[99]\ttrain's binary_logloss: 0.357537\n",
      "[100]\ttrain's binary_logloss: 0.356465\n",
      "[101]\ttrain's binary_logloss: 0.355643\n",
      "[102]\ttrain's binary_logloss: 0.354476\n",
      "[103]\ttrain's binary_logloss: 0.353127\n",
      "[104]\ttrain's binary_logloss: 0.352091\n",
      "[105]\ttrain's binary_logloss: 0.350762\n",
      "[106]\ttrain's binary_logloss: 0.349704\n",
      "[107]\ttrain's binary_logloss: 0.348859\n",
      "[108]\ttrain's binary_logloss: 0.347836\n",
      "[109]\ttrain's binary_logloss: 0.346703\n",
      "[110]\ttrain's binary_logloss: 0.345726\n",
      "[111]\ttrain's binary_logloss: 0.344929\n",
      "[112]\ttrain's binary_logloss: 0.344232\n",
      "[113]\ttrain's binary_logloss: 0.343464\n",
      "[114]\ttrain's binary_logloss: 0.342828\n",
      "[115]\ttrain's binary_logloss: 0.341282\n",
      "[116]\ttrain's binary_logloss: 0.339423\n",
      "[117]\ttrain's binary_logloss: 0.338747\n",
      "[118]\ttrain's binary_logloss: 0.337414\n",
      "[119]\ttrain's binary_logloss: 0.336814\n",
      "[120]\ttrain's binary_logloss: 0.335958\n",
      "[121]\ttrain's binary_logloss: 0.335146\n",
      "[122]\ttrain's binary_logloss: 0.333571\n",
      "[123]\ttrain's binary_logloss: 0.332564\n",
      "[124]\ttrain's binary_logloss: 0.331984\n",
      "[125]\ttrain's binary_logloss: 0.331224\n",
      "[126]\ttrain's binary_logloss: 0.33044\n",
      "[127]\ttrain's binary_logloss: 0.32974\n",
      "[128]\ttrain's binary_logloss: 0.328766\n",
      "[129]\ttrain's binary_logloss: 0.327988\n",
      "[130]\ttrain's binary_logloss: 0.327226\n",
      "[131]\ttrain's binary_logloss: 0.326293\n",
      "[132]\ttrain's binary_logloss: 0.325219\n",
      "[133]\ttrain's binary_logloss: 0.323711\n",
      "[134]\ttrain's binary_logloss: 0.323081\n",
      "[135]\ttrain's binary_logloss: 0.321718\n",
      "[136]\ttrain's binary_logloss: 0.321142\n",
      "[137]\ttrain's binary_logloss: 0.320328\n",
      "[138]\ttrain's binary_logloss: 0.319378\n",
      "[139]\ttrain's binary_logloss: 0.318822\n",
      "[140]\ttrain's binary_logloss: 0.317859\n",
      "[141]\ttrain's binary_logloss: 0.31729\n",
      "[142]\ttrain's binary_logloss: 0.316314\n",
      "[143]\ttrain's binary_logloss: 0.315594\n",
      "[144]\ttrain's binary_logloss: 0.314675\n",
      "[145]\ttrain's binary_logloss: 0.313575\n",
      "[146]\ttrain's binary_logloss: 0.312904\n",
      "[147]\ttrain's binary_logloss: 0.31207\n",
      "[148]\ttrain's binary_logloss: 0.311461\n",
      "[149]\ttrain's binary_logloss: 0.310867\n",
      "[150]\ttrain's binary_logloss: 0.309872\n",
      "[151]\ttrain's binary_logloss: 0.309071\n",
      "[152]\ttrain's binary_logloss: 0.308102\n",
      "[153]\ttrain's binary_logloss: 0.307219\n",
      "[154]\ttrain's binary_logloss: 0.306427\n",
      "[155]\ttrain's binary_logloss: 0.305771\n",
      "[156]\ttrain's binary_logloss: 0.304692\n",
      "[157]\ttrain's binary_logloss: 0.303829\n",
      "[158]\ttrain's binary_logloss: 0.302958\n",
      "[159]\ttrain's binary_logloss: 0.302515\n",
      "[160]\ttrain's binary_logloss: 0.301781\n",
      "[161]\ttrain's binary_logloss: 0.301218\n",
      "[162]\ttrain's binary_logloss: 0.30076\n",
      "[163]\ttrain's binary_logloss: 0.299788\n",
      "[164]\ttrain's binary_logloss: 0.299011\n",
      "[165]\ttrain's binary_logloss: 0.298209\n",
      "[166]\ttrain's binary_logloss: 0.297688\n",
      "[167]\ttrain's binary_logloss: 0.296928\n",
      "[168]\ttrain's binary_logloss: 0.296486\n",
      "[169]\ttrain's binary_logloss: 0.295689\n",
      "[170]\ttrain's binary_logloss: 0.295135\n",
      "[171]\ttrain's binary_logloss: 0.293992\n",
      "[172]\ttrain's binary_logloss: 0.293065\n",
      "[173]\ttrain's binary_logloss: 0.292238\n",
      "[174]\ttrain's binary_logloss: 0.291605\n",
      "[175]\ttrain's binary_logloss: 0.290909\n",
      "[176]\ttrain's binary_logloss: 0.290163\n",
      "[177]\ttrain's binary_logloss: 0.289679\n",
      "[178]\ttrain's binary_logloss: 0.288876\n",
      "[179]\ttrain's binary_logloss: 0.287826\n",
      "[180]\ttrain's binary_logloss: 0.286768\n",
      "[181]\ttrain's binary_logloss: 0.2861\n",
      "[182]\ttrain's binary_logloss: 0.285568\n",
      "[183]\ttrain's binary_logloss: 0.285031\n",
      "[184]\ttrain's binary_logloss: 0.284179\n",
      "[185]\ttrain's binary_logloss: 0.28348\n",
      "[186]\ttrain's binary_logloss: 0.282782\n",
      "[187]\ttrain's binary_logloss: 0.282188\n",
      "[188]\ttrain's binary_logloss: 0.281734\n",
      "[189]\ttrain's binary_logloss: 0.28121\n",
      "[190]\ttrain's binary_logloss: 0.280441\n",
      "[191]\ttrain's binary_logloss: 0.279909\n",
      "[192]\ttrain's binary_logloss: 0.27899\n",
      "[193]\ttrain's binary_logloss: 0.278616\n",
      "[194]\ttrain's binary_logloss: 0.278\n",
      "[195]\ttrain's binary_logloss: 0.277302\n",
      "[196]\ttrain's binary_logloss: 0.276416\n",
      "[197]\ttrain's binary_logloss: 0.275802\n",
      "[198]\ttrain's binary_logloss: 0.275207\n",
      "[199]\ttrain's binary_logloss: 0.274815\n",
      "[200]\ttrain's binary_logloss: 0.274167\n",
      "[201]\ttrain's binary_logloss: 0.273716\n",
      "[202]\ttrain's binary_logloss: 0.272815\n",
      "[203]\ttrain's binary_logloss: 0.272177\n",
      "[204]\ttrain's binary_logloss: 0.271436\n",
      "[205]\ttrain's binary_logloss: 0.270776\n",
      "[206]\ttrain's binary_logloss: 0.270229\n",
      "[207]\ttrain's binary_logloss: 0.269779\n",
      "[208]\ttrain's binary_logloss: 0.269004\n",
      "[209]\ttrain's binary_logloss: 0.267872\n",
      "[210]\ttrain's binary_logloss: 0.267196\n",
      "[211]\ttrain's binary_logloss: 0.266571\n",
      "[212]\ttrain's binary_logloss: 0.26598\n",
      "[213]\ttrain's binary_logloss: 0.265654\n",
      "[214]\ttrain's binary_logloss: 0.264831\n",
      "[215]\ttrain's binary_logloss: 0.263983\n",
      "[216]\ttrain's binary_logloss: 0.262875\n",
      "[217]\ttrain's binary_logloss: 0.26229\n",
      "[218]\ttrain's binary_logloss: 0.26172\n",
      "[219]\ttrain's binary_logloss: 0.260831\n",
      "[220]\ttrain's binary_logloss: 0.260221\n",
      "[221]\ttrain's binary_logloss: 0.259489\n",
      "[222]\ttrain's binary_logloss: 0.258778\n",
      "[223]\ttrain's binary_logloss: 0.25811\n",
      "[224]\ttrain's binary_logloss: 0.257694\n",
      "[225]\ttrain's binary_logloss: 0.257083\n",
      "[226]\ttrain's binary_logloss: 0.256652\n",
      "[227]\ttrain's binary_logloss: 0.255637\n",
      "[228]\ttrain's binary_logloss: 0.255275\n",
      "[229]\ttrain's binary_logloss: 0.25436\n",
      "[230]\ttrain's binary_logloss: 0.253792\n",
      "[231]\ttrain's binary_logloss: 0.253338\n",
      "[232]\ttrain's binary_logloss: 0.252984\n",
      "[233]\ttrain's binary_logloss: 0.252331\n",
      "[234]\ttrain's binary_logloss: 0.251858\n",
      "[235]\ttrain's binary_logloss: 0.251312\n",
      "[236]\ttrain's binary_logloss: 0.250489\n",
      "[237]\ttrain's binary_logloss: 0.250099\n",
      "[238]\ttrain's binary_logloss: 0.249802\n",
      "[239]\ttrain's binary_logloss: 0.249211\n",
      "[240]\ttrain's binary_logloss: 0.24873\n",
      "[241]\ttrain's binary_logloss: 0.248368\n",
      "[242]\ttrain's binary_logloss: 0.247962\n",
      "[243]\ttrain's binary_logloss: 0.247223\n",
      "[244]\ttrain's binary_logloss: 0.246523\n",
      "[245]\ttrain's binary_logloss: 0.245704\n",
      "[246]\ttrain's binary_logloss: 0.245339\n",
      "[247]\ttrain's binary_logloss: 0.244785\n",
      "[248]\ttrain's binary_logloss: 0.244489\n",
      "[249]\ttrain's binary_logloss: 0.244123\n",
      "[250]\ttrain's binary_logloss: 0.243491\n",
      "[251]\ttrain's binary_logloss: 0.242877\n",
      "[252]\ttrain's binary_logloss: 0.24253\n",
      "[253]\ttrain's binary_logloss: 0.242084\n",
      "[254]\ttrain's binary_logloss: 0.241631\n",
      "[255]\ttrain's binary_logloss: 0.241128\n",
      "[256]\ttrain's binary_logloss: 0.240535\n",
      "[257]\ttrain's binary_logloss: 0.240056\n",
      "[258]\ttrain's binary_logloss: 0.23977\n",
      "[259]\ttrain's binary_logloss: 0.239386\n",
      "[260]\ttrain's binary_logloss: 0.238696\n",
      "[261]\ttrain's binary_logloss: 0.238307\n",
      "[262]\ttrain's binary_logloss: 0.237724\n",
      "[263]\ttrain's binary_logloss: 0.23714\n",
      "[264]\ttrain's binary_logloss: 0.236582\n",
      "[265]\ttrain's binary_logloss: 0.236232\n",
      "[266]\ttrain's binary_logloss: 0.235868\n",
      "[267]\ttrain's binary_logloss: 0.235129\n",
      "[268]\ttrain's binary_logloss: 0.234585\n",
      "[269]\ttrain's binary_logloss: 0.23423\n",
      "[270]\ttrain's binary_logloss: 0.233736\n",
      "[271]\ttrain's binary_logloss: 0.233189\n",
      "[272]\ttrain's binary_logloss: 0.232941\n",
      "[273]\ttrain's binary_logloss: 0.23242\n",
      "[274]\ttrain's binary_logloss: 0.231679\n",
      "[275]\ttrain's binary_logloss: 0.231218\n",
      "[276]\ttrain's binary_logloss: 0.23099\n",
      "[277]\ttrain's binary_logloss: 0.230563\n",
      "[278]\ttrain's binary_logloss: 0.229942\n",
      "[279]\ttrain's binary_logloss: 0.229532\n",
      "[280]\ttrain's binary_logloss: 0.22913\n",
      "[281]\ttrain's binary_logloss: 0.228747\n",
      "[282]\ttrain's binary_logloss: 0.227907\n",
      "[283]\ttrain's binary_logloss: 0.227236\n",
      "[284]\ttrain's binary_logloss: 0.226918\n",
      "[285]\ttrain's binary_logloss: 0.226609\n",
      "[286]\ttrain's binary_logloss: 0.226241\n",
      "[287]\ttrain's binary_logloss: 0.2259\n",
      "[288]\ttrain's binary_logloss: 0.225565\n",
      "[289]\ttrain's binary_logloss: 0.225198\n",
      "[290]\ttrain's binary_logloss: 0.224945\n",
      "[291]\ttrain's binary_logloss: 0.224465\n",
      "[292]\ttrain's binary_logloss: 0.224152\n",
      "[293]\ttrain's binary_logloss: 0.223747\n",
      "[294]\ttrain's binary_logloss: 0.223332\n",
      "[295]\ttrain's binary_logloss: 0.223046\n",
      "[296]\ttrain's binary_logloss: 0.222285\n",
      "[297]\ttrain's binary_logloss: 0.221907\n",
      "[298]\ttrain's binary_logloss: 0.221567\n",
      "[299]\ttrain's binary_logloss: 0.221273\n",
      "[300]\ttrain's binary_logloss: 0.220611\n",
      "[301]\ttrain's binary_logloss: 0.220213\n",
      "[302]\ttrain's binary_logloss: 0.21992\n",
      "[303]\ttrain's binary_logloss: 0.219641\n",
      "[304]\ttrain's binary_logloss: 0.219161\n",
      "[305]\ttrain's binary_logloss: 0.218723\n",
      "[306]\ttrain's binary_logloss: 0.218309\n",
      "[307]\ttrain's binary_logloss: 0.21755\n",
      "[308]\ttrain's binary_logloss: 0.217223\n",
      "[309]\ttrain's binary_logloss: 0.216722\n",
      "[310]\ttrain's binary_logloss: 0.216242\n",
      "[311]\ttrain's binary_logloss: 0.216004\n",
      "[312]\ttrain's binary_logloss: 0.215234\n",
      "[313]\ttrain's binary_logloss: 0.214731\n",
      "[314]\ttrain's binary_logloss: 0.214299\n",
      "[315]\ttrain's binary_logloss: 0.213988\n",
      "[316]\ttrain's binary_logloss: 0.213743\n",
      "[317]\ttrain's binary_logloss: 0.21342\n",
      "[318]\ttrain's binary_logloss: 0.212993\n",
      "[319]\ttrain's binary_logloss: 0.212576\n",
      "[320]\ttrain's binary_logloss: 0.21198\n",
      "[321]\ttrain's binary_logloss: 0.211424\n",
      "[322]\ttrain's binary_logloss: 0.21098\n",
      "[323]\ttrain's binary_logloss: 0.210717\n",
      "[324]\ttrain's binary_logloss: 0.210308\n",
      "[325]\ttrain's binary_logloss: 0.209841\n",
      "[326]\ttrain's binary_logloss: 0.208946\n",
      "[327]\ttrain's binary_logloss: 0.208284\n",
      "[328]\ttrain's binary_logloss: 0.207906\n",
      "[329]\ttrain's binary_logloss: 0.207541\n",
      "[330]\ttrain's binary_logloss: 0.207287\n",
      "[331]\ttrain's binary_logloss: 0.206782\n",
      "[332]\ttrain's binary_logloss: 0.206542\n",
      "[333]\ttrain's binary_logloss: 0.205731\n",
      "[334]\ttrain's binary_logloss: 0.20523\n",
      "[335]\ttrain's binary_logloss: 0.204782\n",
      "[336]\ttrain's binary_logloss: 0.204562\n",
      "[337]\ttrain's binary_logloss: 0.204267\n",
      "[338]\ttrain's binary_logloss: 0.204085\n",
      "[339]\ttrain's binary_logloss: 0.203701\n",
      "[340]\ttrain's binary_logloss: 0.203224\n",
      "[341]\ttrain's binary_logloss: 0.202829\n",
      "[342]\ttrain's binary_logloss: 0.202252\n",
      "[343]\ttrain's binary_logloss: 0.201751\n",
      "[344]\ttrain's binary_logloss: 0.201267\n",
      "[345]\ttrain's binary_logloss: 0.200805\n",
      "[346]\ttrain's binary_logloss: 0.200549\n",
      "[347]\ttrain's binary_logloss: 0.200051\n",
      "[348]\ttrain's binary_logloss: 0.199563\n",
      "[349]\ttrain's binary_logloss: 0.199131\n",
      "[350]\ttrain's binary_logloss: 0.198731\n",
      "[351]\ttrain's binary_logloss: 0.1983\n",
      "[352]\ttrain's binary_logloss: 0.197941\n",
      "[353]\ttrain's binary_logloss: 0.197673\n",
      "[354]\ttrain's binary_logloss: 0.197497\n",
      "[355]\ttrain's binary_logloss: 0.197346\n",
      "[356]\ttrain's binary_logloss: 0.196909\n",
      "[357]\ttrain's binary_logloss: 0.196737\n",
      "[358]\ttrain's binary_logloss: 0.196233\n",
      "[359]\ttrain's binary_logloss: 0.195819\n",
      "[360]\ttrain's binary_logloss: 0.195374\n",
      "[361]\ttrain's binary_logloss: 0.194856\n",
      "[362]\ttrain's binary_logloss: 0.194501\n",
      "[363]\ttrain's binary_logloss: 0.194192\n",
      "[364]\ttrain's binary_logloss: 0.193896\n",
      "[365]\ttrain's binary_logloss: 0.193524\n",
      "[366]\ttrain's binary_logloss: 0.193074\n",
      "[367]\ttrain's binary_logloss: 0.192726\n",
      "[368]\ttrain's binary_logloss: 0.192346\n",
      "[369]\ttrain's binary_logloss: 0.19207\n",
      "[370]\ttrain's binary_logloss: 0.191551\n",
      "[371]\ttrain's binary_logloss: 0.19121\n",
      "[372]\ttrain's binary_logloss: 0.190668\n",
      "[373]\ttrain's binary_logloss: 0.190357\n",
      "[374]\ttrain's binary_logloss: 0.189708\n",
      "[375]\ttrain's binary_logloss: 0.189166\n",
      "[376]\ttrain's binary_logloss: 0.188481\n",
      "[377]\ttrain's binary_logloss: 0.187923\n",
      "[378]\ttrain's binary_logloss: 0.187387\n",
      "[379]\ttrain's binary_logloss: 0.186829\n",
      "[380]\ttrain's binary_logloss: 0.186359\n",
      "[381]\ttrain's binary_logloss: 0.186049\n",
      "[382]\ttrain's binary_logloss: 0.185431\n",
      "[383]\ttrain's binary_logloss: 0.184966\n",
      "[384]\ttrain's binary_logloss: 0.184586\n",
      "[385]\ttrain's binary_logloss: 0.183982\n",
      "[386]\ttrain's binary_logloss: 0.183568\n",
      "[387]\ttrain's binary_logloss: 0.183413\n",
      "[388]\ttrain's binary_logloss: 0.182946\n",
      "[389]\ttrain's binary_logloss: 0.182525\n",
      "[390]\ttrain's binary_logloss: 0.181952\n",
      "[391]\ttrain's binary_logloss: 0.181528\n",
      "[392]\ttrain's binary_logloss: 0.18083\n",
      "[393]\ttrain's binary_logloss: 0.180543\n",
      "[394]\ttrain's binary_logloss: 0.180241\n",
      "[395]\ttrain's binary_logloss: 0.179704\n",
      "[396]\ttrain's binary_logloss: 0.179356\n",
      "[397]\ttrain's binary_logloss: 0.179073\n",
      "[398]\ttrain's binary_logloss: 0.178589\n",
      "[399]\ttrain's binary_logloss: 0.178339\n",
      "[400]\ttrain's binary_logloss: 0.17809\n",
      "[401]\ttrain's binary_logloss: 0.177719\n",
      "[402]\ttrain's binary_logloss: 0.177188\n",
      "[403]\ttrain's binary_logloss: 0.176908\n",
      "[404]\ttrain's binary_logloss: 0.176348\n",
      "[405]\ttrain's binary_logloss: 0.176101\n",
      "[406]\ttrain's binary_logloss: 0.175761\n",
      "[407]\ttrain's binary_logloss: 0.175526\n",
      "[408]\ttrain's binary_logloss: 0.175253\n",
      "[409]\ttrain's binary_logloss: 0.174833\n",
      "[410]\ttrain's binary_logloss: 0.174486\n",
      "[411]\ttrain's binary_logloss: 0.174289\n",
      "[412]\ttrain's binary_logloss: 0.173642\n",
      "[413]\ttrain's binary_logloss: 0.173361\n",
      "[414]\ttrain's binary_logloss: 0.172989\n",
      "[415]\ttrain's binary_logloss: 0.172507\n",
      "[416]\ttrain's binary_logloss: 0.17226\n",
      "[417]\ttrain's binary_logloss: 0.171865\n",
      "[418]\ttrain's binary_logloss: 0.171421\n",
      "[419]\ttrain's binary_logloss: 0.171136\n",
      "[420]\ttrain's binary_logloss: 0.170918\n",
      "[421]\ttrain's binary_logloss: 0.170276\n",
      "[422]\ttrain's binary_logloss: 0.169918\n",
      "[423]\ttrain's binary_logloss: 0.169643\n",
      "[424]\ttrain's binary_logloss: 0.169293\n",
      "[425]\ttrain's binary_logloss: 0.169112\n",
      "[426]\ttrain's binary_logloss: 0.16862\n",
      "[427]\ttrain's binary_logloss: 0.168273\n",
      "[428]\ttrain's binary_logloss: 0.167871\n",
      "[429]\ttrain's binary_logloss: 0.167623\n",
      "[430]\ttrain's binary_logloss: 0.167426\n",
      "[431]\ttrain's binary_logloss: 0.166944\n",
      "[432]\ttrain's binary_logloss: 0.166616\n",
      "[433]\ttrain's binary_logloss: 0.166257\n",
      "[434]\ttrain's binary_logloss: 0.166075\n",
      "[435]\ttrain's binary_logloss: 0.165558\n",
      "[436]\ttrain's binary_logloss: 0.165281\n",
      "[437]\ttrain's binary_logloss: 0.165056\n",
      "[438]\ttrain's binary_logloss: 0.164855\n",
      "[439]\ttrain's binary_logloss: 0.164418\n",
      "[440]\ttrain's binary_logloss: 0.163917\n",
      "[441]\ttrain's binary_logloss: 0.163484\n",
      "[442]\ttrain's binary_logloss: 0.163367\n",
      "[443]\ttrain's binary_logloss: 0.163146\n",
      "[444]\ttrain's binary_logloss: 0.162918\n",
      "[445]\ttrain's binary_logloss: 0.1626\n",
      "[446]\ttrain's binary_logloss: 0.162193\n",
      "[447]\ttrain's binary_logloss: 0.16195\n",
      "[448]\ttrain's binary_logloss: 0.161755\n",
      "[449]\ttrain's binary_logloss: 0.16139\n",
      "[450]\ttrain's binary_logloss: 0.16113\n",
      "[451]\ttrain's binary_logloss: 0.160798\n",
      "[452]\ttrain's binary_logloss: 0.160367\n",
      "[453]\ttrain's binary_logloss: 0.160173\n",
      "[454]\ttrain's binary_logloss: 0.160004\n",
      "[455]\ttrain's binary_logloss: 0.159851\n",
      "[456]\ttrain's binary_logloss: 0.15963\n",
      "[457]\ttrain's binary_logloss: 0.159342\n",
      "[458]\ttrain's binary_logloss: 0.158956\n",
      "[459]\ttrain's binary_logloss: 0.158747\n",
      "[460]\ttrain's binary_logloss: 0.158549\n",
      "[461]\ttrain's binary_logloss: 0.158198\n",
      "[462]\ttrain's binary_logloss: 0.157527\n",
      "[463]\ttrain's binary_logloss: 0.157263\n",
      "[464]\ttrain's binary_logloss: 0.157004\n",
      "[465]\ttrain's binary_logloss: 0.156493\n",
      "[466]\ttrain's binary_logloss: 0.156155\n",
      "[467]\ttrain's binary_logloss: 0.156\n",
      "[468]\ttrain's binary_logloss: 0.155591\n",
      "[469]\ttrain's binary_logloss: 0.154938\n",
      "[470]\ttrain's binary_logloss: 0.154755\n",
      "[471]\ttrain's binary_logloss: 0.154591\n",
      "[472]\ttrain's binary_logloss: 0.154373\n",
      "[473]\ttrain's binary_logloss: 0.154156\n",
      "[474]\ttrain's binary_logloss: 0.153797\n",
      "[475]\ttrain's binary_logloss: 0.153479\n",
      "[476]\ttrain's binary_logloss: 0.153004\n",
      "[477]\ttrain's binary_logloss: 0.152814\n",
      "[478]\ttrain's binary_logloss: 0.152484\n",
      "[479]\ttrain's binary_logloss: 0.152381\n",
      "[480]\ttrain's binary_logloss: 0.15209\n",
      "[481]\ttrain's binary_logloss: 0.151521\n",
      "[482]\ttrain's binary_logloss: 0.151195\n",
      "[483]\ttrain's binary_logloss: 0.150919\n",
      "[484]\ttrain's binary_logloss: 0.150498\n",
      "[485]\ttrain's binary_logloss: 0.150235\n",
      "[486]\ttrain's binary_logloss: 0.15008\n",
      "[487]\ttrain's binary_logloss: 0.149875\n",
      "[488]\ttrain's binary_logloss: 0.1497\n",
      "[489]\ttrain's binary_logloss: 0.149427\n",
      "[490]\ttrain's binary_logloss: 0.148995\n",
      "[491]\ttrain's binary_logloss: 0.148707\n",
      "[492]\ttrain's binary_logloss: 0.148535\n",
      "[493]\ttrain's binary_logloss: 0.148291\n",
      "[494]\ttrain's binary_logloss: 0.148023\n",
      "[495]\ttrain's binary_logloss: 0.1476\n",
      "[496]\ttrain's binary_logloss: 0.147413\n",
      "[497]\ttrain's binary_logloss: 0.147097\n",
      "[498]\ttrain's binary_logloss: 0.146752\n",
      "[499]\ttrain's binary_logloss: 0.146375\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's binary_logloss: 0.146175\n",
      "[0]\ttest-logloss:0.59573\n",
      "[1]\ttest-logloss:0.58371\n",
      "[2]\ttest-logloss:0.57642\n",
      "[3]\ttest-logloss:0.58736\n",
      "[4]\ttest-logloss:0.58414\n",
      "[5]\ttest-logloss:0.58967\n",
      "[6]\ttest-logloss:0.59291\n",
      "[7]\ttest-logloss:0.59738\n",
      "[8]\ttest-logloss:0.59849\n",
      "[9]\ttest-logloss:0.59946\n",
      "[10]\ttest-logloss:0.60594\n",
      "[11]\ttest-logloss:0.60589\n",
      "[12]\ttest-logloss:0.60974\n",
      "[13]\ttest-logloss:0.60995\n",
      "[14]\ttest-logloss:0.61244\n",
      "[15]\ttest-logloss:0.61994\n",
      "[16]\ttest-logloss:0.62884\n",
      "[17]\ttest-logloss:0.63393\n",
      "[18]\ttest-logloss:0.63189\n",
      "[19]\ttest-logloss:0.62428\n",
      "[20]\ttest-logloss:0.63861\n",
      "[21]\ttest-logloss:0.63952\n",
      "[22]\ttest-logloss:0.63235\n",
      "LightGBM accuracy = 0.71\n",
      "LightGBM F1-score = 0.71\n",
      "LightGBM Precision = 0.70\n",
      "XGboost accuracy = 0.68\n",
      "XGboost F1-score = 0.69\n",
      "XGboost Precision = 0.68\n",
      "Logistic Regression accuracy = 0.68\n",
      "Logistic Regression F1-score = 0.67\n",
      "Logistic Regression Precision = 0.69\n"
     ]
    }
   ],
   "source": [
    "# ライブラリのインポート\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb  #lightGBMを入れる\n",
    "import xgboost as xgb  #XGboostを入れる\n",
    "from sklearn.linear_model import LogisticRegression  # ロジスティック回帰を入れる\n",
    "\n",
    "import shap\n",
    "\n",
    "# データの読み込み\n",
    "df = pd.read_excel('lightGBM_data_standard.xlsx')\n",
    "df_lr = pd.read_excel('補完データ_test07.xlsx') #　ロジスティック回帰のデータ読み込み\n",
    "\n",
    "# カテゴリ変数のデータ型を変換\n",
    "cat_cols = ['FBS', 'HbA1c', 'US', 'HbA1c_NGSP']\n",
    "df[cat_cols] = df[cat_cols].astype(str)\n",
    "df_lr[cat_cols] = df_lr[cat_cols].astype(str)\n",
    "\n",
    "\n",
    "# ラベルエンコーディングを実行\n",
    "le = LabelEncoder()\n",
    "df[cat_cols] = df[cat_cols].apply(le.fit_transform)\n",
    "df_lr[cat_cols] = df_lr[cat_cols].apply(le.fit_transform)\n",
    "\n",
    "\n",
    "# 特徴量とターゲットに分割\n",
    "X = df.drop('T2db', axis=1)\n",
    "y = df['T2db']\n",
    "\n",
    "X_lr = df_lr.drop('T2db', axis=1)\n",
    "y_lr = df_lr['T2db']\n",
    "\n",
    "# 特定の列を削除\n",
    "df = df.drop(['TG', 'HDL', 'LDL', 'GOT', 'GPT', 'γ_GT', 'Ht', 'Hb', 'RBC', 'chewing', 'Medication1_Blood Pressure', 'Time of blood collection _after meal', 'Medication2_Blood Sugar', 'Eating style3_midnight snack', 'One-year weight change', 'HbA1c', 'FBS', 'US', 'HbA1c_NGSP'], axis=1)\n",
    "df_lr = df_lr.drop(['TG', 'HDL', 'LDL', 'GOT', 'GPT', 'γ_GT', 'Ht', 'Hb', 'RBC', 'chewing', 'Medication1_Blood Pressure', 'Time of blood collection _after meal', 'Medication2_Blood Sugar', 'Eating style3_midnight snack', 'One-year weight change', 'HbA1c', 'FBS', 'US', 'HbA1c_NGSP'], axis=1)\n",
    "\n",
    "# 削除した結果を反映した特徴量を再作成\n",
    "X = df.drop('T2db', axis=1)\n",
    "X_lr = df_lr.drop('T2db', axis=1)\n",
    "\n",
    "# アンダーサンプリング\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "X_resampled_lr, y_resampled_lr = rus.fit_resample(X_lr, y_lr)\n",
    "\n",
    "# バギングによるモデルの学習と評価\n",
    "# lightGBM\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []  # 適合率を格納するリスト\n",
    "confusion_matrices = []\n",
    "\n",
    "# XGboost\n",
    "accuracy_scores_xgb = []\n",
    "f1_scores_xgb = []\n",
    "precision_scores_xgb = []  # 適合率を格納するリスト\n",
    "confusion_matrices_xgb = []\n",
    "\n",
    "# ロジスティック回帰\n",
    "accuracy_scores_lr = []\n",
    "f1_scores_lr = []\n",
    "precision_scores_lr = []  # 適合率を格納するリスト\n",
    "confusion_matrices_lr = []\n",
    "auc_scores_lr = []\n",
    "\n",
    "n_estimators = 10  # バギングの回数\n",
    "\n",
    "for _ in range(n_estimators):\n",
    "    # 学習データとテストデータに分割\n",
    "    X_train_not, X_test_not, y_train_not, y_test_not = train_test_split(X_resampled, y_resampled, test_size=0.3, shuffle=True, stratify=y_resampled, random_state=0)\n",
    "    print('X_trainの形状：', X_train.shape, ' y_trainの形状：', y_train.shape, ' X_testの形状：', X_test.shape, ' y_testの形状：', y_test.shape)\n",
    "    \n",
    "    # 学習データとテストデータに分割（ロジスティック回帰）\n",
    "    X_train_lr, X_test_lr, y_train_lr, y_test_lr = train_test_split(X_resampled_lr, y_resampled_lr, test_size=0.3, shuffle=True, stratify=y_resampled, random_state=0)\n",
    "\n",
    "    # LightGBM用のデータセットを作成\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "\n",
    "    # xgboost用のデータセットを作成\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    # ハイパーパラメータの設定\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'num_leaves': 5,\n",
    "        'seed': 0,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "\n",
    "    params_xgb = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'max_depth': 2,\n",
    "        'learning_rate': 0.8,\n",
    "        'base_score': 0.5,\n",
    "        'min_split_loss': 0,\n",
    "        'reg_lambda': 0,\n",
    "        'reg_alpha': 0,\n",
    "        'seed': 0,\n",
    "    }\n",
    "\n",
    "    # LightGBMモデルの学習\n",
    "    model = lgb.train(params,\n",
    "                      lgb_train,\n",
    "                      num_boost_round=500,\n",
    "                      valid_sets=[lgb_train],\n",
    "                      valid_names=['train'],\n",
    "                      early_stopping_rounds=20)\n",
    "\n",
    "    # xgboostモデルの学習\n",
    "    model_xgb = xgb.train(params_xgb,\n",
    "                          dtrain,\n",
    "                          num_boost_round=500,\n",
    "                          early_stopping_rounds=20,\n",
    "                          evals=[(dtest, 'test')])\n",
    "    \n",
    "    # ロジスティック回帰の学習\n",
    "    model_lr = LogisticRegression()\n",
    "    model_lr.fit(X_train_lr, y_train_lr)\n",
    "    \n",
    "\n",
    "    # テストデータの予測と評価(lightGBM)\n",
    "    y_test_pred_proba = model.predict(X_test)  # ラベル1の確率\n",
    "    y_test_pred = np.round(y_test_pred_proba)  # 確率をラベル0 or 1に変換\n",
    "    ac_score = accuracy_score(y_test, y_test_pred)\n",
    "    f1 = f1_score(y_test, y_test_pred)\n",
    "    precision = precision_score(y_test, y_test_pred)  # 適合率の計算\n",
    "\n",
    "    # 混同行列(lightGBM)\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 20})\n",
    "    plt.xlabel('pred')\n",
    "    plt.ylabel('label')\n",
    "    plt.savefig('confusion_matrix.png', dpi=300)\n",
    "    plt.close()\n",
    "    accuracy_scores.append(ac_score)\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)  # 適合率\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "    # XGboostモデルのテストデータの予測と評価\n",
    "    y_test_pred_proba_xgb = model_xgb.predict(dtest)  # ラベル1の確率\n",
    "    y_test_pred_xgb = np.round(y_test_pred_proba_xgb)  # 確率をラベル0 or 1に変換\n",
    "    ac_score_xgb = accuracy_score(y_test, y_test_pred_xgb)\n",
    "    f1_xgb = f1_score(y_test, y_test_pred_xgb)\n",
    "    precision_xgb = precision_score(y_test, y_test_pred_xgb)  # 適合率の計算\n",
    "    \n",
    "    # 混同行列(XGboost)\n",
    "    cm_xgb = confusion_matrix(y_test, y_test_pred_xgb)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 20})\n",
    "    plt.xlabel('pred')\n",
    "    plt.ylabel('label')\n",
    "    plt.savefig('confusion_matrix_xgb.png', dpi=300)\n",
    "    plt.close()\n",
    "    accuracy_scores_xgb.append(ac_score_xgb)\n",
    "    f1_scores_xgb.append(f1_xgb)\n",
    "    precision_scores_xgb.append(precision_xgb)  # 適合率\n",
    "    confusion_matrices_xgb.append(cm_xgb)\n",
    "    \n",
    "    \n",
    "    #ロジスティック回帰による予測と評価\n",
    "    y_test_pred_proba_lr = model.predict(X_test_lr)  # ラベル1の確率\n",
    "    y_test_pred_lr = np.round(y_test_pred_proba_lr)  # 確率をラベル0 or 1に変換\n",
    "    ac_score_lr = accuracy_score(y_test_lr, y_test_pred_lr)\n",
    "    f1_lr = f1_score(y_test_lr, y_test_pred_lr)\n",
    "    precision_lr = precision_score(y_test_lr, y_test_pred_lr)  # 適合率の計算\n",
    "\n",
    "    # 混同行列(ロジスティック回帰)\n",
    "    cm_lr = confusion_matrix(y_test_lr, y_test_pred_lr)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 20})\n",
    "    plt.xlabel('pred')\n",
    "    plt.ylabel('label')\n",
    "    plt.savefig('confusion_matrix_lr.png', dpi=300)\n",
    "    plt.close()\n",
    "    accuracy_scores_lr.append(ac_score_lr)\n",
    "    f1_scores_lr.append(f1_lr)\n",
    "    precision_scores_lr.append(precision_lr)  # 適合率\n",
    "    confusion_matrices_lr.append(cm_lr)\n",
    "    \n",
    "\n",
    "# 結果の表示\n",
    "print('LightGBM accuracy = %.2f' % np.mean(accuracy_scores))\n",
    "print('LightGBM F1-score = %.2f' % np.mean(f1_scores))\n",
    "print('LightGBM Precision = %.2f' % np.mean(precision_scores))\n",
    "# print('LightGBM AUC = %.2f' % np.mean(auc_scores))\n",
    "\n",
    "print('XGboost accuracy = %.2f' % np.mean(accuracy_scores_xgb))\n",
    "print('XGboost F1-score = %.2f' % np.mean(f1_scores_xgb))\n",
    "print('XGboost Precision = %.2f' % np.mean(precision_scores_xgb))\n",
    "# print('XGboost AUC = %.2f' % np.mean(auc_scores_xgb))\n",
    "\n",
    "print('Logistic Regression accuracy = %.2f' % np.mean(accuracy_scores_lr))\n",
    "print('Logistic Regression F1-score = %.2f' % np.mean(f1_scores_lr))\n",
    "print('Logistic Regression Precision = %.2f' % np.mean(precision_scores_lr))\n",
    "# print('Logistic Regression AUC = %.2f' % np.mean(auc_scores_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21797d01-2f3f-4df6-82e3-424100cb3257",
   "metadata": {},
   "source": [
    "## ロジスティック回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0063bc0f-032e-455a-ba04-801c45e7f666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ライブラリをインポート\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データの読み込み\n",
    "df = pd.read_excel('lightGBM_data_standard.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a593d1d-c5c2-4f92-9e38-6b4421582754",
   "metadata": {},
   "source": [
    "## ROC曲線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acc70968-3c59-473e-8e64-59aa1328a459",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM AUCスコア = 0.868\n",
      "XGboost AUCスコア = 0.869\n",
      "Logistic AUCスコア = 0.723\n"
     ]
    }
   ],
   "source": [
    "#ライブラリをインポート\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, roc_curve, roc_auc_score\n",
    "\n",
    "# テストデータの予測確率を取得\n",
    "y_test_pred_proba_light = model.predict(X_test)\n",
    "y_test_pred_proba_xgb = model_xgb.predict(dtest)  # dtestはXGboost用のデータセット\n",
    "y_test_pred_proba_lr = model_lr.predict(X_test_lr) \n",
    "\n",
    "\n",
    "# AUCスコアを計算\n",
    "auc_score_light = roc_auc_score(y_test, y_test_pred_proba_light)\n",
    "auc_score_xgb = roc_auc_score(y_test, y_test_pred_proba_xgb)\n",
    "auc_score_lr = roc_auc_score(y_test_lr, y_test_pred_proba_lr)\n",
    "\n",
    "\n",
    "\n",
    "# AUC曲線をプロット\n",
    "# lightGBMの描写\n",
    "fpr_light, tpr_light, _ = roc_curve(y_test, y_test_pred_proba_light)\n",
    "plt.plot(fpr_light, tpr_light, label='LightGBM (AUC = {:.3f})'.format(auc_score_light))\n",
    "\n",
    "# XGboostの描写\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_test_pred_proba_xgb)\n",
    "plt.plot(fpr_xgb, tpr_xgb, label='XGboost (AUC = {:.3f})'.format(auc_score_xgb))\n",
    "\n",
    "# ロジスティック回帰の描写\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test_lr, y_test_pred_proba_lr)\n",
    "plt.plot(fpr_lr, tpr_lr, label='Logistic (AUC = {:.3f})'.format(auc_score_lr))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend()\n",
    "\n",
    "# 保存と表示\n",
    "plt.savefig('roc_curve_notboold.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# AUCスコアを表示\n",
    "print('LightGBM AUCスコア = {:.3f}'.format(auc_score_light))\n",
    "print('XGboost AUCスコア = {:.3f}'.format(auc_score_xgb))\n",
    "print('Logistic AUCスコア = {:.3f}'.format(auc_score_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98a329d-deb7-40a1-a248-6df96aad308a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
